<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Avidemux-svn-commit] r6238 - in	branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale:	. x86
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/avidemux-svn-commit/2010-May/index.html" >
   <LINK REL="made" HREF="mailto:avidemux-svn-commit%40lists.berlios.de?Subject=Re%3A%20%5BAvidemux-svn-commit%5D%20r6238%20-%20in%0A%09branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale%3A%0A%09.%20x86&In-Reply-To=%3C201005260526.o4Q5Qnsc029171%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="003433.html">
   <LINK REL="Next"  HREF="003435.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Avidemux-svn-commit] r6238 - in	branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale:	. x86</H1>
    <B>mean at BerliOS</B> 
    <A HREF="mailto:avidemux-svn-commit%40lists.berlios.de?Subject=Re%3A%20%5BAvidemux-svn-commit%5D%20r6238%20-%20in%0A%09branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale%3A%0A%09.%20x86&In-Reply-To=%3C201005260526.o4Q5Qnsc029171%40sheep.berlios.de%3E"
       TITLE="[Avidemux-svn-commit] r6238 - in	branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale:	. x86">mean at mail.berlios.de
       </A><BR>
    <I>Wed May 26 07:26:49 CEST 2010</I>
    <P><UL>
        <LI>Previous message: <A HREF="003433.html">[Avidemux-svn-commit] r6237 -	branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/patches
</A></li>
        <LI>Next message: <A HREF="003435.html">[Avidemux-svn-commit] r6239 - in	branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg: .	ffmpeg_config
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#3434">[ date ]</a>
              <a href="thread.html#3434">[ thread ]</a>
              <a href="subject.html#3434">[ subject ]</a>
              <a href="author.html#3434">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: mean
Date: 2010-05-26 07:26:46 +0200 (Wed, 26 May 2010)
New Revision: 6238

Added:
   branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/utils.c
Modified:
   branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/ADM_mp.cpp
   branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/CMakeLists.txt
   branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/colorspace-test.c
   branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/rgb2rgb.c
   branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/rgb2rgb.h
   branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/rgb2rgb_template.c
   branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/swscale.c
   branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/swscale.h
   branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/swscale_internal.h
   branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/swscale_template.c
   branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/x86/yuv2rgb_mmx.c
   branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/x86/yuv2rgb_template.c
   branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/yuv2rgb.c
Log:
[swscale] Merge

Modified: branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/ADM_mp.cpp
===================================================================
--- branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/ADM_mp.cpp	2010-05-26 05:26:42 UTC (rev 6237)
+++ branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/ADM_mp.cpp	2010-05-26 05:26:46 UTC (rev 6238)
@@ -18,12 +18,12 @@
 #include &lt;string.h&gt;
 #include &lt;math.h&gt;
 
-#include &quot;config.h&quot;
+#include &quot;ADM_lavcodec.h&quot;
+#include &quot;ADM_mangle.h&quot;
 #include &quot;fourcc.h&quot;
 
 
 extern &quot;C&quot; {
-#include &quot;ADM_ffmpeg/libavcodec/avcodec.h&quot;
 #include &quot;ADM_ffmpeg/libavutil/avutil.h&quot;
 #include &quot;ADM_ffmpeg/libswscale/swscale.h&quot;
 }

Modified: branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/CMakeLists.txt
===================================================================
--- branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/CMakeLists.txt	2010-05-26 05:26:42 UTC (rev 6237)
+++ branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/CMakeLists.txt	2010-05-26 05:26:46 UTC (rev 6238)
@@ -1,6 +1,6 @@
 SET(ADM_LIB ADM_libswscale6)
 SET(${ADM_LIB}_SRCS 
-        swscale.c yuv2rgb.c rgb2rgb.c ADM_mp.cpp swscale_avoption.c
+        swscale.c yuv2rgb.c rgb2rgb.c ADM_mp.cpp swscale_avoption.c utils.c
 )
 
 IF(ADM_CPU_X86)

Modified: branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/colorspace-test.c
===================================================================
--- branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/colorspace-test.c	2010-05-26 05:26:42 UTC (rev 6237)
+++ branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/colorspace-test.c	2010-05-26 05:26:46 UTC (rev 6238)
@@ -66,6 +66,9 @@
     int failedNum=0;
     int passedNum=0;
 
+    if (!srcBuffer || !dstBuffer)
+        return -1;
+
     av_log(NULL, AV_LOG_INFO, &quot;memory corruption test ...\n&quot;);
     args_parse(argc, argv);
     av_log(NULL, AV_LOG_INFO, &quot;CPU capabilities forced to %x\n&quot;, cpu_caps);

Modified: branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/rgb2rgb.c
===================================================================
--- branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/rgb2rgb.c	2010-05-26 05:26:42 UTC (rev 6237)
+++ branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/rgb2rgb.c	2010-05-26 05:26:46 UTC (rev 6238)
@@ -74,7 +74,7 @@
                     long lumStride, long chromStride, long srcStride);
 void (*planar2x)(const uint8_t *src, uint8_t *dst, long width, long height,
                  long srcStride, long dstStride);
-void (*interleaveBytes)(uint8_t *src1, uint8_t *src2, uint8_t *dst,
+void (*interleaveBytes)(const uint8_t *src1, const uint8_t *src2, uint8_t *dst,
                         long width, long height, long src1Stride,
                         long src2Stride, long dstStride);
 void (*vu9_to_vu12)(const uint8_t *src1, const uint8_t *src2,
@@ -274,16 +274,16 @@
     long i;
     long num_pixels = src_size &gt;&gt; 2;
     for (i=0; i&lt;num_pixels; i++) {
-        #if HAVE_BIGENDIAN
-            /* RGB32 (= A,B,G,R) -&gt; BGR24 (= B,G,R) */
-            dst[3*i + 0] = src[4*i + 1];
-            dst[3*i + 1] = src[4*i + 2];
-            dst[3*i + 2] = src[4*i + 3];
-        #else
-            dst[3*i + 0] = src[4*i + 2];
-            dst[3*i + 1] = src[4*i + 1];
-            dst[3*i + 2] = src[4*i + 0];
-        #endif
+#if HAVE_BIGENDIAN
+        /* RGB32 (= A,B,G,R) -&gt; BGR24 (= B,G,R) */
+        dst[3*i + 0] = src[4*i + 1];
+        dst[3*i + 1] = src[4*i + 2];
+        dst[3*i + 2] = src[4*i + 3];
+#else
+        dst[3*i + 0] = src[4*i + 2];
+        dst[3*i + 1] = src[4*i + 1];
+        dst[3*i + 2] = src[4*i + 0];
+#endif
     }
 }
 
@@ -291,18 +291,18 @@
 {
     long i;
     for (i=0; 3*i&lt;src_size; i++) {
-        #if HAVE_BIGENDIAN
-            /* RGB24 (= R,G,B) -&gt; BGR32 (= A,R,G,B) */
-            dst[4*i + 0] = 255;
-            dst[4*i + 1] = src[3*i + 0];
-            dst[4*i + 2] = src[3*i + 1];
-            dst[4*i + 3] = src[3*i + 2];
-        #else
-            dst[4*i + 0] = src[3*i + 2];
-            dst[4*i + 1] = src[3*i + 1];
-            dst[4*i + 2] = src[3*i + 0];
-            dst[4*i + 3] = 255;
-        #endif
+#if HAVE_BIGENDIAN
+        /* RGB24 (= R,G,B) -&gt; BGR32 (= A,R,G,B) */
+        dst[4*i + 0] = 255;
+        dst[4*i + 1] = src[3*i + 0];
+        dst[4*i + 2] = src[3*i + 1];
+        dst[4*i + 3] = src[3*i + 2];
+#else
+        dst[4*i + 0] = src[3*i + 2];
+        dst[4*i + 1] = src[3*i + 1];
+        dst[4*i + 2] = src[3*i + 0];
+        dst[4*i + 3] = 255;
+#endif
     }
 }
 
@@ -315,17 +315,17 @@
     while (s &lt; end) {
         register uint16_t bgr;
         bgr = *s++;
-        #if HAVE_BIGENDIAN
-            *d++ = 255;
-            *d++ = (bgr&amp;0x1F)&lt;&lt;3;
-            *d++ = (bgr&amp;0x7E0)&gt;&gt;3;
-            *d++ = (bgr&amp;0xF800)&gt;&gt;8;
-        #else
-            *d++ = (bgr&amp;0xF800)&gt;&gt;8;
-            *d++ = (bgr&amp;0x7E0)&gt;&gt;3;
-            *d++ = (bgr&amp;0x1F)&lt;&lt;3;
-            *d++ = 255;
-        #endif
+#if HAVE_BIGENDIAN
+        *d++ = 255;
+        *d++ = (bgr&amp;0x1F)&lt;&lt;3;
+        *d++ = (bgr&amp;0x7E0)&gt;&gt;3;
+        *d++ = (bgr&amp;0xF800)&gt;&gt;8;
+#else
+        *d++ = (bgr&amp;0xF800)&gt;&gt;8;
+        *d++ = (bgr&amp;0x7E0)&gt;&gt;3;
+        *d++ = (bgr&amp;0x1F)&lt;&lt;3;
+        *d++ = 255;
+#endif
     }
 }
 
@@ -375,17 +375,17 @@
     while (s &lt; end) {
         register uint16_t bgr;
         bgr = *s++;
-        #if HAVE_BIGENDIAN
-            *d++ = 255;
-            *d++ = (bgr&amp;0x1F)&lt;&lt;3;
-            *d++ = (bgr&amp;0x3E0)&gt;&gt;2;
-            *d++ = (bgr&amp;0x7C00)&gt;&gt;7;
-        #else
-            *d++ = (bgr&amp;0x7C00)&gt;&gt;7;
-            *d++ = (bgr&amp;0x3E0)&gt;&gt;2;
-            *d++ = (bgr&amp;0x1F)&lt;&lt;3;
-            *d++ = 255;
-        #endif
+#if HAVE_BIGENDIAN
+        *d++ = 255;
+        *d++ = (bgr&amp;0x1F)&lt;&lt;3;
+        *d++ = (bgr&amp;0x3E0)&gt;&gt;2;
+        *d++ = (bgr&amp;0x7C00)&gt;&gt;7;
+#else
+        *d++ = (bgr&amp;0x7C00)&gt;&gt;7;
+        *d++ = (bgr&amp;0x3E0)&gt;&gt;2;
+        *d++ = (bgr&amp;0x1F)&lt;&lt;3;
+        *d++ = 255;
+#endif
     }
 }
 
@@ -442,3 +442,23 @@
         dst[i] = ((b&lt;&lt;1)&amp;0x07) | ((g&amp;0x07)&lt;&lt;3) | ((r&amp;0x03)&lt;&lt;6);
     }
 }
+
+#define DEFINE_SHUFFLE_BYTES(a, b, c, d)                                \
+void shuffle_bytes_##a##b##c##d(const uint8_t *src, uint8_t *dst, long src_size) \
+{                                                                       \
+    long i;                                                             \
+                                                                        \
+    for (i = 0; i &lt; src_size; i+=4) {                                   \
+        dst[i + 0] = src[i + a];                                        \
+        dst[i + 1] = src[i + b];                                        \
+        dst[i + 2] = src[i + c];                                        \
+        dst[i + 3] = src[i + d];                                        \
+    }                                                                   \
+}
+
+DEFINE_SHUFFLE_BYTES(0, 3, 2, 1);
+DEFINE_SHUFFLE_BYTES(1, 2, 3, 0);
+DEFINE_SHUFFLE_BYTES(2, 1, 0, 3);
+DEFINE_SHUFFLE_BYTES(3, 0, 1, 2);
+DEFINE_SHUFFLE_BYTES(3, 2, 1, 0);
+

Modified: branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/rgb2rgb.h
===================================================================
--- branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/rgb2rgb.h	2010-05-26 05:26:42 UTC (rev 6237)
+++ branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/rgb2rgb.h	2010-05-26 05:26:46 UTC (rev 6238)
@@ -60,6 +60,11 @@
 void rgb15tobgr15(const uint8_t *src, uint8_t *dst, long src_size);
 void bgr8torgb8  (const uint8_t *src, uint8_t *dst, long src_size);
 
+void shuffle_bytes_0321(const uint8_t *src, uint8_t *dst, long src_size);
+void shuffle_bytes_1230(const uint8_t *src, uint8_t *dst, long src_size);
+void shuffle_bytes_2103(const uint8_t *src, uint8_t *dst, long src_size);
+void shuffle_bytes_3012(const uint8_t *src, uint8_t *dst, long src_size);
+void shuffle_bytes_3210(const uint8_t *src, uint8_t *dst, long src_size);
 
 void palette8topacked32(const uint8_t *src, uint8_t *dst, long num_pixels, const uint8_t *palette);
 void palette8topacked24(const uint8_t *src, uint8_t *dst, long num_pixels, const uint8_t *palette);
@@ -126,7 +131,7 @@
 extern void (*planar2x)(const uint8_t *src, uint8_t *dst, long width, long height,
                         long srcStride, long dstStride);
 
-extern void (*interleaveBytes)(uint8_t *src1, uint8_t *src2, uint8_t *dst,
+extern void (*interleaveBytes)(const uint8_t *src1, const uint8_t *src2, uint8_t *dst,
                                long width, long height, long src1Stride,
                                long src2Stride, long dstStride);
 

Modified: branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/rgb2rgb_template.c
===================================================================
--- branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/rgb2rgb_template.c	2010-05-26 05:26:42 UTC (rev 6237)
+++ branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/rgb2rgb_template.c	2010-05-26 05:26:46 UTC (rev 6238)
@@ -34,7 +34,6 @@
 #undef EMMS
 #undef SFENCE
 #undef MMREG_SIZE
-#undef PREFETCHW
 #undef PAVGB
 
 #if HAVE_SSE2
@@ -45,15 +44,12 @@
 
 #if HAVE_AMD3DNOW
 #define PREFETCH  &quot;prefetch&quot;
-#define PREFETCHW &quot;prefetchw&quot;
 #define PAVGB     &quot;pavgusb&quot;
 #elif HAVE_MMX2
 #define PREFETCH &quot;prefetchnta&quot;
-#define PREFETCHW &quot;prefetcht0&quot;
 #define PAVGB     &quot;pavgb&quot;
 #else
 #define PREFETCH  &quot; # nop&quot;
-#define PREFETCHW &quot; # nop&quot;
 #endif
 
 #if HAVE_AMD3DNOW
@@ -76,11 +72,11 @@
     uint8_t *dest = dst;
     const uint8_t *s = src;
     const uint8_t *end;
-    #if HAVE_MMX
+#if HAVE_MMX
     const uint8_t *mm_end;
-    #endif
+#endif
     end = s + src_size;
-    #if HAVE_MMX
+#if HAVE_MMX
     __asm__ volatile(PREFETCH&quot;    %0&quot;::&quot;m&quot;(*s):&quot;memory&quot;);
     mm_end = end - 23;
     __asm__ volatile(&quot;movq        %0, %%mm7&quot;::&quot;m&quot;(mask32a):&quot;memory&quot;);
@@ -111,21 +107,21 @@
     }
     __asm__ volatile(SFENCE:::&quot;memory&quot;);
     __asm__ volatile(EMMS:::&quot;memory&quot;);
-    #endif
+#endif
     while (s &lt; end) {
-    #if HAVE_BIGENDIAN
+#if HAVE_BIGENDIAN
         /* RGB24 (= R,G,B) -&gt; RGB32 (= A,B,G,R) */
         *dest++ = 255;
         *dest++ = s[2];
         *dest++ = s[1];
         *dest++ = s[0];
         s+=3;
-    #else
+#else
         *dest++ = *s++;
         *dest++ = *s++;
         *dest++ = *s++;
         *dest++ = 255;
-    #endif
+#endif
     }
 }
 
@@ -1436,7 +1432,7 @@
     const x86_reg chromWidth= width&gt;&gt;1;
     for (y=0; y&lt;height; y++) {
 #if HAVE_MMX
-//FIXME handle 2 lines at once (fewer prefetches, reuse some chroma, but very likely memory-limited anyway)
+        //FIXME handle 2 lines at once (fewer prefetches, reuse some chroma, but very likely memory-limited anyway)
         __asm__ volatile(
             &quot;xor                 %%&quot;REG_a&quot;, %%&quot;REG_a&quot;   \n\t&quot;
             ASMALIGN(4)
@@ -1586,7 +1582,7 @@
     const x86_reg chromWidth= width&gt;&gt;1;
     for (y=0; y&lt;height; y++) {
 #if HAVE_MMX
-//FIXME handle 2 lines at once (fewer prefetches, reuse some chroma, but very likely memory-limited anyway)
+        //FIXME handle 2 lines at once (fewer prefetches, reuse some chroma, but very likely memory-limited anyway)
         __asm__ volatile(
             &quot;xor                %%&quot;REG_a&quot;, %%&quot;REG_a&quot;    \n\t&quot;
             ASMALIGN(4)
@@ -2356,7 +2352,7 @@
     }
 }
 
-static void RENAME(interleaveBytes)(uint8_t *src1, uint8_t *src2, uint8_t *dest,
+static void RENAME(interleaveBytes)(const uint8_t *src1, const uint8_t *src2, uint8_t *dest,
                              long width, long height, long src1Stride,
                              long src2Stride, long dstStride)
 {

Modified: branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/swscale.c
===================================================================
--- branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/swscale.c	2010-05-26 05:26:42 UTC (rev 6237)
+++ branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/swscale.c	2010-05-26 05:26:46 UTC (rev 6238)
@@ -54,35 +54,21 @@
   BGR24 -&gt; YV12
 */
 
-#define _SVID_SOURCE //needed for MAP_ANONYMOUS
 #include &lt;inttypes.h&gt;
 #include &lt;string.h&gt;
 #include &lt;math.h&gt;
 #include &lt;stdio.h&gt;
 #include &quot;config.h&quot;
 #include &lt;assert.h&gt;
-#if HAVE_SYS_MMAN_H
-#include &lt;sys/mman.h&gt;
-#if defined(MAP_ANON) &amp;&amp; !defined(MAP_ANONYMOUS)
-#define MAP_ANONYMOUS MAP_ANON
-#endif
-#endif
-#if HAVE_VIRTUALALLOC
-#define WIN32_LEAN_AND_MEAN
-#include &lt;windows.h&gt;
-#endif
 #include &quot;swscale.h&quot;
 #include &quot;swscale_internal.h&quot;
 #include &quot;rgb2rgb.h&quot;
 #include &quot;libavutil/intreadwrite.h&quot;
 #include &quot;libavutil/x86_cpu.h&quot;
+#include &quot;libavutil/avutil.h&quot;
 #include &quot;libavutil/bswap.h&quot;
+#include &quot;libavutil/pixdesc.h&quot;
 
-unsigned swscale_version(void)
-{
-    return LIBSWSCALE_VERSION_INT;
-}
-
 #undef MOVNTQ
 #undef PAVGB
 
@@ -94,92 +80,19 @@
 
 #define FAST_BGR2YV12 // use 7 bit coefficients instead of 15 bit
 
-#define RET 0xC3 //near return opcode for x86
-
 #ifdef M_PI
 #define PI M_PI
 #else
 #define PI 3.14159265358979323846
 #endif
 
-#define isSupportedIn(x)    (       \
-           (x)==PIX_FMT_YUV420P     \
-        || (x)==PIX_FMT_YUVA420P    \
-        || (x)==PIX_FMT_YUYV422     \
-        || (x)==PIX_FMT_UYVY422     \
-        || (x)==PIX_FMT_RGB48BE     \
-        || (x)==PIX_FMT_RGB48LE     \
-        || (x)==PIX_FMT_RGB32       \
-        || (x)==PIX_FMT_RGB32_1     \
-        || (x)==PIX_FMT_BGR24       \
-        || (x)==PIX_FMT_BGR565      \
-        || (x)==PIX_FMT_BGR555      \
-        || (x)==PIX_FMT_BGR32       \
-        || (x)==PIX_FMT_BGR32_1     \
-        || (x)==PIX_FMT_RGB24       \
-        || (x)==PIX_FMT_RGB565      \
-        || (x)==PIX_FMT_RGB555      \
-        || (x)==PIX_FMT_GRAY8       \
-        || (x)==PIX_FMT_YUV410P     \
-        || (x)==PIX_FMT_YUV440P     \
-        || (x)==PIX_FMT_GRAY16BE    \
-        || (x)==PIX_FMT_GRAY16LE    \
-        || (x)==PIX_FMT_YUV444P     \
-        || (x)==PIX_FMT_YUV422P     \
-        || (x)==PIX_FMT_YUV411P     \
-        || (x)==PIX_FMT_PAL8        \
-        || (x)==PIX_FMT_BGR8        \
-        || (x)==PIX_FMT_RGB8        \
-        || (x)==PIX_FMT_BGR4_BYTE   \
-        || (x)==PIX_FMT_RGB4_BYTE   \
-        || (x)==PIX_FMT_YUV440P     \
-        || (x)==PIX_FMT_MONOWHITE   \
-        || (x)==PIX_FMT_MONOBLACK   \
-        || (x)==PIX_FMT_YUV420PLE   \
-        || (x)==PIX_FMT_YUV422PLE   \
-        || (x)==PIX_FMT_YUV444PLE   \
-        || (x)==PIX_FMT_YUV420PBE   \
-        || (x)==PIX_FMT_YUV422PBE   \
-        || (x)==PIX_FMT_YUV444PBE   \
-    )
-#define isSupportedOut(x)   (       \
-           (x)==PIX_FMT_YUV420P     \
-        || (x)==PIX_FMT_YUVA420P    \
-        || (x)==PIX_FMT_YUYV422     \
-        || (x)==PIX_FMT_UYVY422     \
-        || (x)==PIX_FMT_YUV444P     \
-        || (x)==PIX_FMT_YUV422P     \
-        || (x)==PIX_FMT_YUV411P     \
-        || isRGB(x)                 \
-        || isBGR(x)                 \
-        || (x)==PIX_FMT_NV12        \
-        || (x)==PIX_FMT_NV21        \
-        || (x)==PIX_FMT_GRAY16BE    \
-        || (x)==PIX_FMT_GRAY16LE    \
-        || (x)==PIX_FMT_GRAY8       \
-        || (x)==PIX_FMT_YUV410P     \
-        || (x)==PIX_FMT_YUV440P     \
-        || (x)==PIX_FMT_YUV420PLE   \
-        || (x)==PIX_FMT_YUV422PLE   \
-        || (x)==PIX_FMT_YUV444PLE   \
-        || (x)==PIX_FMT_YUV420PBE   \
-        || (x)==PIX_FMT_YUV422PBE   \
-        || (x)==PIX_FMT_YUV444PBE   \
-    )
 #define isPacked(x)         (       \
            (x)==PIX_FMT_PAL8        \
         || (x)==PIX_FMT_YUYV422     \
         || (x)==PIX_FMT_UYVY422     \
-        || isRGB(x)                 \
-        || isBGR(x)                 \
+        || isAnyRGB(x)              \
     )
-#define usePal(x)           (       \
-           (x)==PIX_FMT_PAL8        \
-        || (x)==PIX_FMT_BGR4_BYTE   \
-        || (x)==PIX_FMT_RGB4_BYTE   \
-        || (x)==PIX_FMT_BGR8        \
-        || (x)==PIX_FMT_RGB8        \
-    )
+#define usePal(x) (av_pix_fmt_descriptors[x].flags &amp; PIX_FMT_PAL)
 
 #define RGB2YUV_SHIFT 15
 #define BY ( (int)(0.114*219/255*(1&lt;&lt;RGB2YUV_SHIFT)+0.5))
@@ -192,8 +105,6 @@
 #define RV ( (int)(0.500*224/255*(1&lt;&lt;RGB2YUV_SHIFT)+0.5))
 #define RU (-(int)(0.169*224/255*(1&lt;&lt;RGB2YUV_SHIFT)+0.5))
 
-extern const int32_t ff_yuv2rgb_coeffs[8][4];
-
 static const double rgb2yuv_table[8][9]={
     {0.7152, 0.0722, 0.2126, -0.386, 0.5, -0.115, -0.454, -0.046, 0.5},
     {0.7152, 0.0722, 0.2126, -0.386, 0.5, -0.115, -0.454, -0.046, 0.5},
@@ -230,11 +141,11 @@
 DECLARE_ASM_CONST(8, uint64_t, bm11111000)=0xFFFFFFFFFF000000LL;
 DECLARE_ASM_CONST(8, uint64_t, bm01010101)=0x00FF00FF00FF00FFLL;
 
-const DECLARE_ALIGNED(8, uint64_t, ff_dither4[2]) = {
+const DECLARE_ALIGNED(8, uint64_t, ff_dither4)[2] = {
         0x0103010301030103LL,
         0x0200020002000200LL,};
 
-const DECLARE_ALIGNED(8, uint64_t, ff_dither8[2]) = {
+const DECLARE_ALIGNED(8, uint64_t, ff_dither8)[2] = {
         0x0602060206020602LL,
         0x0004000400040004LL,};
 
@@ -268,7 +179,7 @@
 DECLARE_ASM_CONST(8, uint64_t, ff_rgb24toY2Coeff) = 0x0C88408700000C88ULL;
 DECLARE_ASM_CONST(8, uint64_t, ff_bgr24toYOffset) = 0x0008400000084000ULL;
 
-DECLARE_ASM_CONST(8, uint64_t, ff_bgr24toUV[2][4]) = {
+DECLARE_ASM_CONST(8, uint64_t, ff_bgr24toUV)[2][4] = {
     {0x38380000DAC83838ULL, 0xECFFDAC80000ECFFULL, 0xF6E40000D0E3F6E4ULL, 0x3838D0E300003838ULL},
     {0xECFF0000DAC8ECFFULL, 0x3838DAC800003838ULL, 0x38380000D0E33838ULL, 0xF6E4D0E30000F6E4ULL},
 };
@@ -277,22 +188,17 @@
 
 #endif /* ARCH_X86 &amp;&amp; CONFIG_GPL */
 
-// clipping helper table for C implementations:
-static unsigned char clip_table[768];
-
-static SwsVector *sws_getConvVec(SwsVector *a, SwsVector *b);
-
-DECLARE_ALIGNED(8, static const uint8_t, dither_2x2_4[2][8])={
+DECLARE_ALIGNED(8, static const uint8_t, dither_2x2_4)[2][8]={
 {  1,   3,   1,   3,   1,   3,   1,   3, },
 {  2,   0,   2,   0,   2,   0,   2,   0, },
 };
 
-DECLARE_ALIGNED(8, static const uint8_t, dither_2x2_8[2][8])={
+DECLARE_ALIGNED(8, static const uint8_t, dither_2x2_8)[2][8]={
 {  6,   2,   6,   2,   6,   2,   6,   2, },
 {  0,   4,   0,   4,   0,   4,   0,   4, },
 };
 
-DECLARE_ALIGNED(8, const uint8_t, dither_8x8_32[8][8])={
+DECLARE_ALIGNED(8, const uint8_t, dither_8x8_32)[8][8]={
 { 17,   9,  23,  15,  16,   8,  22,  14, },
 {  5,  29,   3,  27,   4,  28,   2,  26, },
 { 21,  13,  19,  11,  20,  12,  18,  10, },
@@ -303,7 +209,7 @@
 {  1,  25,   7,  31,   0,  24,   6,  30, },
 };
 
-DECLARE_ALIGNED(8, const uint8_t, dither_8x8_73[8][8])={
+DECLARE_ALIGNED(8, const uint8_t, dither_8x8_73)[8][8]={
 {  0,  55,  14,  68,   3,  58,  17,  72, },
 { 37,  18,  50,  32,  40,  22,  54,  35, },
 {  9,  64,   5,  59,  13,  67,   8,  63, },
@@ -315,7 +221,7 @@
 };
 
 #if 1
-DECLARE_ALIGNED(8, const uint8_t, dither_8x8_220[8][8])={
+DECLARE_ALIGNED(8, const uint8_t, dither_8x8_220)[8][8]={
 {117,  62, 158, 103, 113,  58, 155, 100, },
 { 34, 199,  21, 186,  31, 196,  17, 182, },
 {144,  89, 131,  76, 141,  86, 127,  72, },
@@ -327,7 +233,7 @@
 };
 #elif 1
 // tries to correct a gamma of 1.5
-DECLARE_ALIGNED(8, const uint8_t, dither_8x8_220[8][8])={
+DECLARE_ALIGNED(8, const uint8_t, dither_8x8_220)[8][8]={
 {  0, 143,  18, 200,   2, 156,  25, 215, },
 { 78,  28, 125,  64,  89,  36, 138,  74, },
 { 10, 180,   3, 161,  16, 195,   8, 175, },
@@ -339,7 +245,7 @@
 };
 #elif 1
 // tries to correct a gamma of 2.0
-DECLARE_ALIGNED(8, const uint8_t, dither_8x8_220[8][8])={
+DECLARE_ALIGNED(8, const uint8_t, dither_8x8_220)[8][8]={
 {  0, 124,   8, 193,   0, 140,  12, 213, },
 { 55,  14, 104,  42,  66,  19, 119,  52, },
 {  3, 168,   1, 145,   6, 187,   3, 162, },
@@ -351,7 +257,7 @@
 };
 #else
 // tries to correct a gamma of 2.5
-DECLARE_ALIGNED(8, const uint8_t, dither_8x8_220[8][8])={
+DECLARE_ALIGNED(8, const uint8_t, dither_8x8_220)[8][8]={
 {  0, 107,   3, 187,   0, 125,   6, 212, },
 { 39,   7,  86,  28,  49,  11, 102,  36, },
 {  1, 158,   0, 131,   3, 180,   1, 151, },
@@ -363,118 +269,6 @@
 };
 #endif
 
-const char *sws_format_name(enum PixelFormat format)
-{
-    switch (format) {
-    case PIX_FMT_YUV420P:
-        return &quot;yuv420p&quot;;
-    case PIX_FMT_YUVA420P:
-        return &quot;yuva420p&quot;;
-    case PIX_FMT_YUYV422:
-        return &quot;yuyv422&quot;;
-    case PIX_FMT_RGB24:
-        return &quot;rgb24&quot;;
-    case PIX_FMT_BGR24:
-        return &quot;bgr24&quot;;
-    case PIX_FMT_YUV422P:
-        return &quot;yuv422p&quot;;
-    case PIX_FMT_YUV444P:
-        return &quot;yuv444p&quot;;
-    case PIX_FMT_RGB32:
-        return &quot;rgb32&quot;;
-    case PIX_FMT_YUV410P:
-        return &quot;yuv410p&quot;;
-    case PIX_FMT_YUV411P:
-        return &quot;yuv411p&quot;;
-    case PIX_FMT_RGB565:
-        return &quot;rgb565&quot;;
-    case PIX_FMT_RGB555:
-        return &quot;rgb555&quot;;
-    case PIX_FMT_GRAY16BE:
-        return &quot;gray16be&quot;;
-    case PIX_FMT_GRAY16LE:
-        return &quot;gray16le&quot;;
-    case PIX_FMT_GRAY8:
-        return &quot;gray8&quot;;
-    case PIX_FMT_MONOWHITE:
-        return &quot;mono white&quot;;
-    case PIX_FMT_MONOBLACK:
-        return &quot;mono black&quot;;
-    case PIX_FMT_PAL8:
-        return &quot;Palette&quot;;
-    case PIX_FMT_YUVJ420P:
-        return &quot;yuvj420p&quot;;
-    case PIX_FMT_YUVJ422P:
-        return &quot;yuvj422p&quot;;
-    case PIX_FMT_YUVJ444P:
-        return &quot;yuvj444p&quot;;
-    case PIX_FMT_XVMC_MPEG2_MC:
-        return &quot;xvmc_mpeg2_mc&quot;;
-    case PIX_FMT_XVMC_MPEG2_IDCT:
-        return &quot;xvmc_mpeg2_idct&quot;;
-    case PIX_FMT_UYVY422:
-        return &quot;uyvy422&quot;;
-    case PIX_FMT_UYYVYY411:
-        return &quot;uyyvyy411&quot;;
-    case PIX_FMT_RGB32_1:
-        return &quot;rgb32x&quot;;
-    case PIX_FMT_BGR32_1:
-        return &quot;bgr32x&quot;;
-    case PIX_FMT_BGR32:
-        return &quot;bgr32&quot;;
-    case PIX_FMT_BGR565:
-        return &quot;bgr565&quot;;
-    case PIX_FMT_BGR555:
-        return &quot;bgr555&quot;;
-    case PIX_FMT_BGR8:
-        return &quot;bgr8&quot;;
-    case PIX_FMT_BGR4:
-        return &quot;bgr4&quot;;
-    case PIX_FMT_BGR4_BYTE:
-        return &quot;bgr4 byte&quot;;
-    case PIX_FMT_RGB8:
-        return &quot;rgb8&quot;;
-    case PIX_FMT_RGB4:
-        return &quot;rgb4&quot;;
-    case PIX_FMT_RGB4_BYTE:
-        return &quot;rgb4 byte&quot;;
-    case PIX_FMT_RGB48BE:
-        return &quot;rgb48be&quot;;
-    case PIX_FMT_RGB48LE:
-        return &quot;rgb48le&quot;;
-    case PIX_FMT_NV12:
-        return &quot;nv12&quot;;
-    case PIX_FMT_NV21:
-        return &quot;nv21&quot;;
-    case PIX_FMT_YUV440P:
-        return &quot;yuv440p&quot;;
-    case PIX_FMT_VDPAU_H264:
-        return &quot;vdpau_h264&quot;;
-    case PIX_FMT_VDPAU_MPEG1:
-        return &quot;vdpau_mpeg1&quot;;
-    case PIX_FMT_VDPAU_MPEG2:
-        return &quot;vdpau_mpeg2&quot;;
-    case PIX_FMT_VDPAU_WMV3:
-        return &quot;vdpau_wmv3&quot;;
-    case PIX_FMT_VDPAU_VC1:
-        return &quot;vdpau_vc1&quot;;
-    case PIX_FMT_YUV420PLE:
-        return &quot;yuv420ple&quot;;
-    case PIX_FMT_YUV422PLE:
-        return &quot;yuv422ple&quot;;
-    case PIX_FMT_YUV444PLE:
-        return &quot;yuv444ple&quot;;
-    case PIX_FMT_YUV420PBE:
-        return &quot;yuv420pbe&quot;;
-    case PIX_FMT_YUV422PBE:
-        return &quot;yuv422pbe&quot;;
-    case PIX_FMT_YUV444PBE:
-        return &quot;yuv444pbe&quot;;
-    default:
-        return &quot;Unknown format&quot;;
-    }
-}
-
 static av_always_inline void yuv2yuvX16inC_template(const int16_t *lumFilter, const int16_t **lumSrc, int lumFilterSize,
                                                     const int16_t *chrFilter, const int16_t **chrSrc, int chrFilterSize,
                                                     const int16_t **alpSrc, uint16_t *dest, uint16_t *uDest, uint16_t *vDest, uint16_t *aDest,
@@ -674,7 +468,7 @@
             }\
             A1&gt;&gt;=19;\
             A2&gt;&gt;=19;\
-        }\
+        }
 
 #define YSCALE_YUV_2_PACKEDX_C(type,alpha) \
         YSCALE_YUV_2_PACKEDX_NOCLIP_C(type,alpha)\
@@ -719,7 +513,7 @@
             A &gt;&gt;=19;\
             if (A&amp;256)\
                 A = av_clip_uint8(A);\
-        }\
+        }
 
 #define YSCALE_YUV_2_RGBX_FULL_C(rnd,alpha) \
     YSCALE_YUV_2_PACKEDX_FULL_C(rnd&gt;&gt;3,alpha)\
@@ -736,9 +530,8 @@
             else if (G&lt;0)G=0;   \
             if (B&gt;=(256&lt;&lt;22))   B=(256&lt;&lt;22)-1; \
             else if (B&lt;0)B=0;   \
-        }\
+        }
 
-
 #define YSCALE_YUV_2_GRAY16_C \
     for (i=0; i&lt;(dstW&gt;&gt;1); i++) {\
         int j;\
@@ -766,7 +559,7 @@
     YSCALE_YUV_2_PACKEDX_C(type,alpha)  /* FIXME fix tables so that clipping is not needed and then use _NOCLIP*/\
     r = (type *)c-&gt;table_rV[V];   \
     g = (type *)(c-&gt;table_gU[U] + c-&gt;table_gV[V]); \
-    b = (type *)c-&gt;table_bU[U];   \
+    b = (type *)c-&gt;table_bU[U];
 
 #define YSCALE_YUV_2_PACKED2_C(type,alpha)   \
     for (i=0; i&lt;(dstW&gt;&gt;1); i++) { \
@@ -780,19 +573,19 @@
         if (alpha) {\
             A1= (abuf0[i2  ]*yalpha1+abuf1[i2  ]*yalpha)&gt;&gt;19;         \
             A2= (abuf0[i2+1]*yalpha1+abuf1[i2+1]*yalpha)&gt;&gt;19;         \
-        }\
+        }
 
 #define YSCALE_YUV_2_GRAY16_2_C   \
     for (i=0; i&lt;(dstW&gt;&gt;1); i++) { \
         const int i2= 2*i;       \
         int Y1= (buf0[i2  ]*yalpha1+buf1[i2  ]*yalpha)&gt;&gt;11;           \
-        int Y2= (buf0[i2+1]*yalpha1+buf1[i2+1]*yalpha)&gt;&gt;11;           \
+        int Y2= (buf0[i2+1]*yalpha1+buf1[i2+1]*yalpha)&gt;&gt;11;
 
 #define YSCALE_YUV_2_RGB2_C(type,alpha) \
     YSCALE_YUV_2_PACKED2_C(type,alpha)\
     r = (type *)c-&gt;table_rV[V];\
     g = (type *)(c-&gt;table_gU[U] + c-&gt;table_gV[V]);\
-    b = (type *)c-&gt;table_bU[U];\
+    b = (type *)c-&gt;table_bU[U];
 
 #define YSCALE_YUV_2_PACKED1_C(type,alpha) \
     for (i=0; i&lt;(dstW&gt;&gt;1); i++) {\
@@ -806,19 +599,19 @@
         if (alpha) {\
             A1= abuf0[i2  ]&gt;&gt;7;\
             A2= abuf0[i2+1]&gt;&gt;7;\
-        }\
+        }
 
 #define YSCALE_YUV_2_GRAY16_1_C \
     for (i=0; i&lt;(dstW&gt;&gt;1); i++) {\
         const int i2= 2*i;\
         int Y1= buf0[i2  ]&lt;&lt;1;\
-        int Y2= buf0[i2+1]&lt;&lt;1;\
+        int Y2= buf0[i2+1]&lt;&lt;1;
 
 #define YSCALE_YUV_2_RGB1_C(type,alpha) \
     YSCALE_YUV_2_PACKED1_C(type,alpha)\
     r = (type *)c-&gt;table_rV[V];\
     g = (type *)(c-&gt;table_gU[U] + c-&gt;table_gV[V]);\
-    b = (type *)c-&gt;table_bU[U];\
+    b = (type *)c-&gt;table_bU[U];
 
 #define YSCALE_YUV_2_PACKED1B_C(type,alpha) \
     for (i=0; i&lt;(dstW&gt;&gt;1); i++) {\
@@ -832,13 +625,13 @@
         if (alpha) {\
             A1= abuf0[i2  ]&gt;&gt;7;\
             A2= abuf0[i2+1]&gt;&gt;7;\
-        }\
+        }
 
 #define YSCALE_YUV_2_RGB1B_C(type,alpha) \
     YSCALE_YUV_2_PACKED1B_C(type,alpha)\
     r = (type *)c-&gt;table_rV[V];\
     g = (type *)(c-&gt;table_gU[U] + c-&gt;table_gV[V]);\
-    b = (type *)c-&gt;table_bU[U];\
+    b = (type *)c-&gt;table_bU[U];
 
 #define YSCALE_YUV_2_MONO2_C \
     const uint8_t * const d128=dither_8x8_220[y&amp;7];\
@@ -855,9 +648,8 @@
         acc+= acc + g[((buf0[i+7]*yalpha1+buf1[i+7]*yalpha)&gt;&gt;19) + d128[7]];\
         ((uint8_t*)dest)[0]= c-&gt;dstFormat == PIX_FMT_MONOBLACK ? acc : ~acc;\
         dest++;\
-    }\
+    }
 
-
 #define YSCALE_YUV_2_MONOX_C \
     const uint8_t * const d128=dither_8x8_220[y&amp;7];\
     uint8_t *g= c-&gt;table_gU[128] + c-&gt;table_gV[128];\
@@ -887,7 +679,6 @@
         }\
     }
 
-
 #define YSCALE_YUV_2_ANYRGB_C(func, func2, func_g16, func_monoblack)\
     switch(c-&gt;dstFormat) {\
     case PIX_FMT_RGB48BE:\
@@ -1075,9 +866,8 @@
             ((uint8_t*)dest)[2*i2+3]= Y2&gt;&gt;8;\
         }                \
         break;\
-    }\
+    }
 
-
 static inline void yuv2packedXinC(SwsContext *c, const int16_t *lumFilter, const int16_t **lumSrc, int lumFilterSize,
                                   const int16_t *chrFilter, const int16_t **chrSrc, int chrFilterSize,
                                   const int16_t **alpSrc, uint8_t *dest, int dstW, int y)
@@ -1091,7 +881,7 @@
                                     const int16_t **alpSrc, uint8_t *dest, int dstW, int y)
 {
     int i;
-    int step= fmt_depth(c-&gt;dstFormat)/8;
+    int step= c-&gt;dstFormatBpp/8;
     int aidx= 3;
 
     switch(c-&gt;dstFormat) {
@@ -1180,7 +970,8 @@
     }
 }
 
-static inline void rgb48ToY(uint8_t *dst, const uint8_t *src, int width)
+static inline void rgb48ToY(uint8_t *dst, const uint8_t *src, int width,
+                            uint32_t *unused)
 {
     int i;
     for (i = 0; i &lt; width; i++) {
@@ -1193,7 +984,8 @@
 }
 
 static inline void rgb48ToUV(uint8_t *dstU, uint8_t *dstV,
-                             uint8_t *src1, uint8_t *src2, int width)
+                             const uint8_t *src1, const uint8_t *src2,
+                             int width, uint32_t *unused)
 {
     int i;
     assert(src1==src2);
@@ -1208,7 +1000,8 @@
 }
 
 static inline void rgb48ToUV_half(uint8_t *dstU, uint8_t *dstV,
-                                  uint8_t *src1, uint8_t *src2, int width)
+                                  const uint8_t *src1, const uint8_t *src2,
+                                  int width, uint32_t *unused)
 {
     int i;
     assert(src1==src2);
@@ -1332,7 +1125,6 @@
     }
 }
 
-
 //Note: we have C, MMX, MMX2, 3DNOW versions, there is no 3DNOW+MMX2 one
 //Plain C versions
 #if ((!HAVE_MMX || !CONFIG_GPL) &amp;&amp; !HAVE_ALTIVEC) || CONFIG_RUNTIME_CPUDETECT
@@ -1421,521 +1213,8 @@
 
 #endif //ARCH_X86
 
-static double getSplineCoeff(double a, double b, double c, double d, double dist)
+SwsFunc ff_getSwsFunc(SwsContext *c)
 {
-//    printf(&quot;%f %f %f %f %f\n&quot;, a,b,c,d,dist);
-    if (dist&lt;=1.0) return ((d*dist + c)*dist + b)*dist +a;
-    else           return getSplineCoeff(        0.0,
-                                          b+ 2.0*c + 3.0*d,
-                                                 c + 3.0*d,
-                                         -b- 3.0*c - 6.0*d,
-                                         dist-1.0);
-}
-
-static inline int initFilter(int16_t **outFilter, int16_t **filterPos, int *outFilterSize, int xInc,
-                             int srcW, int dstW, int filterAlign, int one, int flags,
-                             SwsVector *srcFilter, SwsVector *dstFilter, double param[2])
-{
-    int i;
-    int filterSize;
-    int filter2Size;
-    int minFilterSize;
-    int64_t *filter=NULL;
-    int64_t *filter2=NULL;
-    const int64_t fone= 1LL&lt;&lt;54;
-    int ret= -1;
-#if ARCH_X86
-    if (flags &amp; SWS_CPU_CAPS_MMX)
-        __asm__ volatile(&quot;emms\n\t&quot;::: &quot;memory&quot;); //FIXME this should not be required but it IS (even for non-MMX versions)
-#endif
-
-    // NOTE: the +1 is for the MMX scaler which reads over the end
-    *filterPos = av_malloc((dstW+1)*sizeof(int16_t));
-
-    if (FFABS(xInc - 0x10000) &lt;10) { // unscaled
-        int i;
-        filterSize= 1;
-        filter= av_mallocz(dstW*sizeof(*filter)*filterSize);
-
-        for (i=0; i&lt;dstW; i++) {
-            filter[i*filterSize]= fone;
-            (*filterPos)[i]=i;
-        }
-
-    } else if (flags&amp;SWS_POINT) { // lame looking point sampling mode
-        int i;
-        int xDstInSrc;
-        filterSize= 1;
-        filter= av_malloc(dstW*sizeof(*filter)*filterSize);
-
-        xDstInSrc= xInc/2 - 0x8000;
-        for (i=0; i&lt;dstW; i++) {
-            int xx= (xDstInSrc - ((filterSize-1)&lt;&lt;15) + (1&lt;&lt;15))&gt;&gt;16;
-
-            (*filterPos)[i]= xx;
-            filter[i]= fone;
-            xDstInSrc+= xInc;
-        }
-    } else if ((xInc &lt;= (1&lt;&lt;16) &amp;&amp; (flags&amp;SWS_AREA)) || (flags&amp;SWS_FAST_BILINEAR)) { // bilinear upscale
-        int i;
-        int xDstInSrc;
-        filterSize= 2;
-        filter= av_malloc(dstW*sizeof(*filter)*filterSize);
-
-        xDstInSrc= xInc/2 - 0x8000;
-        for (i=0; i&lt;dstW; i++) {
-            int xx= (xDstInSrc - ((filterSize-1)&lt;&lt;15) + (1&lt;&lt;15))&gt;&gt;16;
-            int j;
-
-            (*filterPos)[i]= xx;
-            //bilinear upscale / linear interpolate / area averaging
-            for (j=0; j&lt;filterSize; j++) {
-                int64_t coeff= fone - FFABS((xx&lt;&lt;16) - xDstInSrc)*(fone&gt;&gt;16);
-                if (coeff&lt;0) coeff=0;
-                filter[i*filterSize + j]= coeff;
-                xx++;
-            }
-            xDstInSrc+= xInc;
-        }
-    } else {
-        int xDstInSrc;
-        int sizeFactor;
-
-        if      (flags&amp;SWS_BICUBIC)      sizeFactor=  4;
-        else if (flags&amp;SWS_X)            sizeFactor=  8;
-        else if (flags&amp;SWS_AREA)         sizeFactor=  1; //downscale only, for upscale it is bilinear
-        else if (flags&amp;SWS_GAUSS)        sizeFactor=  8;   // infinite ;)
-        else if (flags&amp;SWS_LANCZOS)      sizeFactor= param[0] != SWS_PARAM_DEFAULT ? ceil(2*param[0]) : 6;
-        else if (flags&amp;SWS_SINC)         sizeFactor= 20; // infinite ;)
-        else if (flags&amp;SWS_SPLINE)       sizeFactor= 20;  // infinite ;)
-        else if (flags&amp;SWS_BILINEAR)     sizeFactor=  2;
-        else {
-            sizeFactor= 0; //GCC warning killer
-            assert(0);
-        }
-
-        if (xInc &lt;= 1&lt;&lt;16)      filterSize= 1 + sizeFactor; // upscale
-        else                    filterSize= 1 + (sizeFactor*srcW + dstW - 1)/ dstW;
-
-        if (filterSize &gt; srcW-2) filterSize=srcW-2;
-
-        filter= av_malloc(dstW*sizeof(*filter)*filterSize);
-
-        xDstInSrc= xInc - 0x10000;
-        for (i=0; i&lt;dstW; i++) {
-            int xx= (xDstInSrc - ((filterSize-2)&lt;&lt;16)) / (1&lt;&lt;17);
-            int j;
-            (*filterPos)[i]= xx;
-            for (j=0; j&lt;filterSize; j++) {
-                int64_t d= ((int64_t)FFABS((xx&lt;&lt;17) - xDstInSrc))&lt;&lt;13;
-                double floatd;
-                int64_t coeff;
-
-                if (xInc &gt; 1&lt;&lt;16)
-                    d= d*dstW/srcW;
-                floatd= d * (1.0/(1&lt;&lt;30));
-
-                if (flags &amp; SWS_BICUBIC) {
-                    int64_t B= (param[0] != SWS_PARAM_DEFAULT ? param[0] :   0) * (1&lt;&lt;24);
-                    int64_t C= (param[1] != SWS_PARAM_DEFAULT ? param[1] : 0.6) * (1&lt;&lt;24);
-                    int64_t dd = ( d*d)&gt;&gt;30;
-                    int64_t ddd= (dd*d)&gt;&gt;30;
-
-                    if      (d &lt; 1LL&lt;&lt;30)
-                        coeff = (12*(1&lt;&lt;24)-9*B-6*C)*ddd + (-18*(1&lt;&lt;24)+12*B+6*C)*dd + (6*(1&lt;&lt;24)-2*B)*(1&lt;&lt;30);
-                    else if (d &lt; 1LL&lt;&lt;31)
-                        coeff = (-B-6*C)*ddd + (6*B+30*C)*dd + (-12*B-48*C)*d + (8*B+24*C)*(1&lt;&lt;30);
-                    else
-                        coeff=0.0;
-                    coeff *= fone&gt;&gt;(30+24);
-                }
-/*                else if (flags &amp; SWS_X) {
-                    double p= param ? param*0.01 : 0.3;
-                    coeff = d ? sin(d*PI)/(d*PI) : 1.0;
-                    coeff*= pow(2.0, - p*d*d);
-                }*/
-                else if (flags &amp; SWS_X) {
-                    double A= param[0] != SWS_PARAM_DEFAULT ? param[0] : 1.0;
-                    double c;
-
-                    if (floatd&lt;1.0)
-                        c = cos(floatd*PI);
-                    else
-                        c=-1.0;
-                    if (c&lt;0.0)      c= -pow(-c, A);
-                    else            c=  pow( c, A);
-                    coeff= (c*0.5 + 0.5)*fone;
-                } else if (flags &amp; SWS_AREA) {
-                    int64_t d2= d - (1&lt;&lt;29);
-                    if      (d2*xInc &lt; -(1LL&lt;&lt;(29+16))) coeff= 1.0 * (1LL&lt;&lt;(30+16));
-                    else if (d2*xInc &lt;  (1LL&lt;&lt;(29+16))) coeff= -d2*xInc + (1LL&lt;&lt;(29+16));
-                    else coeff=0.0;
-                    coeff *= fone&gt;&gt;(30+16);
-                } else if (flags &amp; SWS_GAUSS) {
-                    double p= param[0] != SWS_PARAM_DEFAULT ? param[0] : 3.0;
-                    coeff = (pow(2.0, - p*floatd*floatd))*fone;
-                } else if (flags &amp; SWS_SINC) {
-                    coeff = (d ? sin(floatd*PI)/(floatd*PI) : 1.0)*fone;
-                } else if (flags &amp; SWS_LANCZOS) {
-                    double p= param[0] != SWS_PARAM_DEFAULT ? param[0] : 3.0;
-                    coeff = (d ? sin(floatd*PI)*sin(floatd*PI/p)/(floatd*floatd*PI*PI/p) : 1.0)*fone;
-                    if (floatd&gt;p) coeff=0;
-                } else if (flags &amp; SWS_BILINEAR) {
-                    coeff= (1&lt;&lt;30) - d;
-                    if (coeff&lt;0) coeff=0;
-                    coeff *= fone &gt;&gt; 30;
-                } else if (flags &amp; SWS_SPLINE) {
-                    double p=-2.196152422706632;
-                    coeff = getSplineCoeff(1.0, 0.0, p, -p-1.0, floatd) * fone;
-                } else {
-                    coeff= 0.0; //GCC warning killer
-                    assert(0);
-                }
-
-                filter[i*filterSize + j]= coeff;
-                xx++;
-            }
-            xDstInSrc+= 2*xInc;
-        }
-    }
-
-    /* apply src &amp; dst Filter to filter -&gt; filter2
-       av_free(filter);
-    */
-    assert(filterSize&gt;0);
-    filter2Size= filterSize;
-    if (srcFilter) filter2Size+= srcFilter-&gt;length - 1;
-    if (dstFilter) filter2Size+= dstFilter-&gt;length - 1;
-    assert(filter2Size&gt;0);
-    filter2= av_mallocz(filter2Size*dstW*sizeof(*filter2));
-
-    for (i=0; i&lt;dstW; i++) {
-        int j, k;
-
-        if(srcFilter) {
-            for (k=0; k&lt;srcFilter-&gt;length; k++) {
-                for (j=0; j&lt;filterSize; j++)
-                    filter2[i*filter2Size + k + j] += srcFilter-&gt;coeff[k]*filter[i*filterSize + j];
-            }
-        } else {
-            for (j=0; j&lt;filterSize; j++)
-                filter2[i*filter2Size + j]= filter[i*filterSize + j];
-        }
-        //FIXME dstFilter
-
-        (*filterPos)[i]+= (filterSize-1)/2 - (filter2Size-1)/2;
-    }
-    av_freep(&amp;filter);
-
-    /* try to reduce the filter-size (step1 find size and shift left) */
-    // Assume it is near normalized (*0.5 or *2.0 is OK but * 0.001 is not).
-    minFilterSize= 0;
-    for (i=dstW-1; i&gt;=0; i--) {
-        int min= filter2Size;
-        int j;
-        int64_t cutOff=0.0;
-
-        /* get rid off near zero elements on the left by shifting left */
-        for (j=0; j&lt;filter2Size; j++) {
-            int k;
-            cutOff += FFABS(filter2[i*filter2Size]);
-
-            if (cutOff &gt; SWS_MAX_REDUCE_CUTOFF*fone) break;
-
-            /* preserve monotonicity because the core can't handle the filter otherwise */
-            if (i&lt;dstW-1 &amp;&amp; (*filterPos)[i] &gt;= (*filterPos)[i+1]) break;
-
-            // move filter coefficients left
-            for (k=1; k&lt;filter2Size; k++)
-                filter2[i*filter2Size + k - 1]= filter2[i*filter2Size + k];
-            filter2[i*filter2Size + k - 1]= 0;
-            (*filterPos)[i]++;
-        }
-
-        cutOff=0;
-        /* count near zeros on the right */
-        for (j=filter2Size-1; j&gt;0; j--) {
-            cutOff += FFABS(filter2[i*filter2Size + j]);
-
-            if (cutOff &gt; SWS_MAX_REDUCE_CUTOFF*fone) break;
-            min--;
-        }
-
-        if (min&gt;minFilterSize) minFilterSize= min;
-    }
-
-    if (flags &amp; SWS_CPU_CAPS_ALTIVEC) {
-        // we can handle the special case 4,
-        // so we don't want to go to the full 8
-        if (minFilterSize &lt; 5)
-            filterAlign = 4;
-
-        // We really don't want to waste our time
-        // doing useless computation, so fall back on
-        // the scalar C code for very small filters.
-        // Vectorizing is worth it only if you have a
-        // decent-sized vector.
-        if (minFilterSize &lt; 3)
-            filterAlign = 1;
-    }
-
-    if (flags &amp; SWS_CPU_CAPS_MMX) {
-        // special case for unscaled vertical filtering
-        if (minFilterSize == 1 &amp;&amp; filterAlign == 2)
-            filterAlign= 1;
-    }
-
-    assert(minFilterSize &gt; 0);
-    filterSize= (minFilterSize +(filterAlign-1)) &amp; (~(filterAlign-1));
-    assert(filterSize &gt; 0);
-    filter= av_malloc(filterSize*dstW*sizeof(*filter));
-    if (filterSize &gt;= MAX_FILTER_SIZE*16/((flags&amp;SWS_ACCURATE_RND) ? APCK_SIZE : 16) || !filter)
-        goto error;
-    *outFilterSize= filterSize;
-
-    if (flags&amp;SWS_PRINT_INFO)
-        av_log(NULL, AV_LOG_VERBOSE, &quot;SwScaler: reducing / aligning filtersize %d -&gt; %d\n&quot;, filter2Size, filterSize);
-    /* try to reduce the filter-size (step2 reduce it) */
-    for (i=0; i&lt;dstW; i++) {
-        int j;
-
-        for (j=0; j&lt;filterSize; j++) {
-            if (j&gt;=filter2Size) filter[i*filterSize + j]= 0;
-            else               filter[i*filterSize + j]= filter2[i*filter2Size + j];
-            if((flags &amp; SWS_BITEXACT) &amp;&amp; j&gt;=minFilterSize)
-                filter[i*filterSize + j]= 0;
-        }
-    }
-
-
-    //FIXME try to align filterPos if possible
-
-    //fix borders
-    for (i=0; i&lt;dstW; i++) {
-        int j;
-        if ((*filterPos)[i] &lt; 0) {
-            // move filter coefficients left to compensate for filterPos
-            for (j=1; j&lt;filterSize; j++) {
-                int left= FFMAX(j + (*filterPos)[i], 0);
-                filter[i*filterSize + left] += filter[i*filterSize + j];
-                filter[i*filterSize + j]=0;
-            }
-            (*filterPos)[i]= 0;
-        }
-
-        if ((*filterPos)[i] + filterSize &gt; srcW) {
-            int shift= (*filterPos)[i] + filterSize - srcW;
-            // move filter coefficients right to compensate for filterPos
-            for (j=filterSize-2; j&gt;=0; j--) {
-                int right= FFMIN(j + shift, filterSize-1);
-                filter[i*filterSize +right] += filter[i*filterSize +j];
-                filter[i*filterSize +j]=0;
-            }
-            (*filterPos)[i]= srcW - filterSize;
-        }
-    }
-
-    // Note the +1 is for the MMX scaler which reads over the end
-    /* align at 16 for AltiVec (needed by hScale_altivec_real) */
-    *outFilter= av_mallocz(*outFilterSize*(dstW+1)*sizeof(int16_t));
-
-    /* normalize &amp; store in outFilter */
-    for (i=0; i&lt;dstW; i++) {
-        int j;
-        int64_t error=0;
-        int64_t sum=0;
-
-        for (j=0; j&lt;filterSize; j++) {
-            sum+= filter[i*filterSize + j];
-        }
-        sum= (sum + one/2)/ one;
-        for (j=0; j&lt;*outFilterSize; j++) {
-            int64_t v= filter[i*filterSize + j] + error;
-            int intV= ROUNDED_DIV(v, sum);
-            (*outFilter)[i*(*outFilterSize) + j]= intV;
-            error= v - intV*sum;
-        }
-    }
-
-    (*filterPos)[dstW]= (*filterPos)[dstW-1]; // the MMX scaler will read over the end
-    for (i=0; i&lt;*outFilterSize; i++) {
-        int j= dstW*(*outFilterSize);
-        (*outFilter)[j + i]= (*outFilter)[j + i - (*outFilterSize)];
-    }
-
-    ret=0;
-error:
-    av_free(filter);
-    av_free(filter2);
-    return ret;
-}
-
-#ifdef COMPILE_MMX2
-static int initMMX2HScaler(int dstW, int xInc, uint8_t *filterCode, int16_t *filter, int32_t *filterPos, int numSplits)
-{
-    uint8_t *fragmentA;
-    x86_reg imm8OfPShufW1A;
-    x86_reg imm8OfPShufW2A;
-    x86_reg fragmentLengthA;
-    uint8_t *fragmentB;
-    x86_reg imm8OfPShufW1B;
-    x86_reg imm8OfPShufW2B;
-    x86_reg fragmentLengthB;
-    int fragmentPos;
-
-    int xpos, i;
-
-    // create an optimized horizontal scaling routine
-
-    //code fragment
-
-    __asm__ volatile(
-        &quot;jmp                         9f                 \n\t&quot;
-    // Begin
-        &quot;0:                                             \n\t&quot;
-        &quot;movq    (%%&quot;REG_d&quot;, %%&quot;REG_a&quot;), %%mm3          \n\t&quot;
-        &quot;movd    (%%&quot;REG_c&quot;, %%&quot;REG_S&quot;), %%mm0          \n\t&quot;
-        &quot;movd   1(%%&quot;REG_c&quot;, %%&quot;REG_S&quot;), %%mm1          \n\t&quot;
-        &quot;punpcklbw                %%mm7, %%mm1          \n\t&quot;
-        &quot;punpcklbw                %%mm7, %%mm0          \n\t&quot;
-        &quot;pshufw                   $0xFF, %%mm1, %%mm1   \n\t&quot;
-        &quot;1:                                             \n\t&quot;
-        &quot;pshufw                   $0xFF, %%mm0, %%mm0   \n\t&quot;
-        &quot;2:                                             \n\t&quot;
-        &quot;psubw                    %%mm1, %%mm0          \n\t&quot;
-        &quot;movl   8(%%&quot;REG_b&quot;, %%&quot;REG_a&quot;), %%esi          \n\t&quot;
-        &quot;pmullw                   %%mm3, %%mm0          \n\t&quot;
-        &quot;psllw                       $7, %%mm1          \n\t&quot;
-        &quot;paddw                    %%mm1, %%mm0          \n\t&quot;
-
-        &quot;movq                     %%mm0, (%%&quot;REG_D&quot;, %%&quot;REG_a&quot;) \n\t&quot;
-
-        &quot;add                         $8, %%&quot;REG_a&quot;      \n\t&quot;
-    // End
-        &quot;9:                                             \n\t&quot;
-//        &quot;int $3                                         \n\t&quot;
-        &quot;lea                 &quot; LOCAL_MANGLE(0b) &quot;, %0   \n\t&quot;
-        &quot;lea                 &quot; LOCAL_MANGLE(1b) &quot;, %1   \n\t&quot;
-        &quot;lea                 &quot; LOCAL_MANGLE(2b) &quot;, %2   \n\t&quot;
-        &quot;dec                         %1                 \n\t&quot;
-        &quot;dec                         %2                 \n\t&quot;
-        &quot;sub                         %0, %1             \n\t&quot;
-        &quot;sub                         %0, %2             \n\t&quot;
-        &quot;lea                 &quot; LOCAL_MANGLE(9b) &quot;, %3   \n\t&quot;
-        &quot;sub                         %0, %3             \n\t&quot;
-
-
-        :&quot;=r&quot; (fragmentA), &quot;=r&quot; (imm8OfPShufW1A), &quot;=r&quot; (imm8OfPShufW2A),
-        &quot;=r&quot; (fragmentLengthA)
-    );
-
-    __asm__ volatile(
-        &quot;jmp                         9f                 \n\t&quot;
-    // Begin
-        &quot;0:                                             \n\t&quot;
-        &quot;movq    (%%&quot;REG_d&quot;, %%&quot;REG_a&quot;), %%mm3          \n\t&quot;
-        &quot;movd    (%%&quot;REG_c&quot;, %%&quot;REG_S&quot;), %%mm0          \n\t&quot;
-        &quot;punpcklbw                %%mm7, %%mm0          \n\t&quot;
-        &quot;pshufw                   $0xFF, %%mm0, %%mm1   \n\t&quot;
-        &quot;1:                                             \n\t&quot;
-        &quot;pshufw                   $0xFF, %%mm0, %%mm0   \n\t&quot;
-        &quot;2:                                             \n\t&quot;
-        &quot;psubw                    %%mm1, %%mm0          \n\t&quot;
-        &quot;movl   8(%%&quot;REG_b&quot;, %%&quot;REG_a&quot;), %%esi          \n\t&quot;
-        &quot;pmullw                   %%mm3, %%mm0          \n\t&quot;
-        &quot;psllw                       $7, %%mm1          \n\t&quot;
-        &quot;paddw                    %%mm1, %%mm0          \n\t&quot;
-
-        &quot;movq                     %%mm0, (%%&quot;REG_D&quot;, %%&quot;REG_a&quot;) \n\t&quot;
-
-        &quot;add                         $8, %%&quot;REG_a&quot;      \n\t&quot;
-    // End
-        &quot;9:                                             \n\t&quot;
-//        &quot;int                       $3                   \n\t&quot;
-        &quot;lea                 &quot; LOCAL_MANGLE(0b) &quot;, %0   \n\t&quot;
-        &quot;lea                 &quot; LOCAL_MANGLE(1b) &quot;, %1   \n\t&quot;
-        &quot;lea                 &quot; LOCAL_MANGLE(2b) &quot;, %2   \n\t&quot;
-        &quot;dec                         %1                 \n\t&quot;
-        &quot;dec                         %2                 \n\t&quot;
-        &quot;sub                         %0, %1             \n\t&quot;
-        &quot;sub                         %0, %2             \n\t&quot;
-        &quot;lea                 &quot; LOCAL_MANGLE(9b) &quot;, %3   \n\t&quot;
-        &quot;sub                         %0, %3             \n\t&quot;
-
-
-        :&quot;=r&quot; (fragmentB), &quot;=r&quot; (imm8OfPShufW1B), &quot;=r&quot; (imm8OfPShufW2B),
-        &quot;=r&quot; (fragmentLengthB)
-    );
-
-    xpos= 0; //lumXInc/2 - 0x8000; // difference between pixel centers
-    fragmentPos=0;
-
-    for (i=0; i&lt;dstW/numSplits; i++) {
-        int xx=xpos&gt;&gt;16;
-
-        if ((i&amp;3) == 0) {
-            int a=0;
-            int b=((xpos+xInc)&gt;&gt;16) - xx;
-            int c=((xpos+xInc*2)&gt;&gt;16) - xx;
-            int d=((xpos+xInc*3)&gt;&gt;16) - xx;
-            int inc                = (d+1&lt;4);
-            uint8_t *fragment      = (d+1&lt;4) ? fragmentB       : fragmentA;
-            x86_reg imm8OfPShufW1  = (d+1&lt;4) ? imm8OfPShufW1B  : imm8OfPShufW1A;
-            x86_reg imm8OfPShufW2  = (d+1&lt;4) ? imm8OfPShufW2B  : imm8OfPShufW2A;
-            x86_reg fragmentLength = (d+1&lt;4) ? fragmentLengthB : fragmentLengthA;
-            int maxShift= 3-(d+inc);
-            int shift=0;
-
-            if (filterCode) {
-                filter[i  ] = (( xpos         &amp; 0xFFFF) ^ 0xFFFF)&gt;&gt;9;
-                filter[i+1] = (((xpos+xInc  ) &amp; 0xFFFF) ^ 0xFFFF)&gt;&gt;9;
-                filter[i+2] = (((xpos+xInc*2) &amp; 0xFFFF) ^ 0xFFFF)&gt;&gt;9;
-                filter[i+3] = (((xpos+xInc*3) &amp; 0xFFFF) ^ 0xFFFF)&gt;&gt;9;
-                filterPos[i/2]= xx;
-
-                memcpy(filterCode + fragmentPos, fragment, fragmentLength);
-
-                filterCode[fragmentPos + imm8OfPShufW1]=
-                    (a+inc) | ((b+inc)&lt;&lt;2) | ((c+inc)&lt;&lt;4) | ((d+inc)&lt;&lt;6);
-                filterCode[fragmentPos + imm8OfPShufW2]=
-                    a | (b&lt;&lt;2) | (c&lt;&lt;4) | (d&lt;&lt;6);
-
-                if (i+4-inc&gt;=dstW) shift=maxShift; //avoid overread
-                else if ((filterPos[i/2]&amp;3) &lt;= maxShift) shift=filterPos[i/2]&amp;3; //Align
-
-                if (shift &amp;&amp; i&gt;=shift) {
-                    filterCode[fragmentPos + imm8OfPShufW1]+= 0x55*shift;
-                    filterCode[fragmentPos + imm8OfPShufW2]+= 0x55*shift;
-                    filterPos[i/2]-=shift;
-                }
-            }
-
-            fragmentPos+= fragmentLength;
-
-            if (filterCode)
-                filterCode[fragmentPos]= RET;
-        }
-        xpos+=xInc;
-    }
-    if (filterCode)
-        filterPos[((i/2)+1)&amp;(~1)]= xpos&gt;&gt;16; // needed to jump to the next part
-
-    return fragmentPos + 1;
-}
-#endif /* COMPILE_MMX2 */
-
-static void globalInit(void)
-{
-    // generating tables:
-    int i;
-    for (i=0; i&lt;768; i++) {
-        int c= av_clip_uint8(i-256);
-        clip_table[i]=c;
-    }
-}
-
-static SwsFunc getSwsFunc(SwsContext *c)
-{
 #if CONFIG_RUNTIME_CPUDETECT
     int flags = c-&gt;flags;
 
@@ -1988,7 +1267,7 @@
 #endif //!CONFIG_RUNTIME_CPUDETECT
 }
 
-static int PlanarToNV12Wrapper(SwsContext *c, uint8_t* src[], int srcStride[], int srcSliceY,
+static int planarToNv12Wrapper(SwsContext *c, const uint8_t* src[], int srcStride[], int srcSliceY,
                                int srcSliceH, uint8_t* dstParam[], int dstStride[])
 {
     uint8_t *dst=dstParam[0] + dstStride[0]*srcSliceY;
@@ -2014,7 +1293,7 @@
     return srcSliceH;
 }
 
-static int PlanarToYuy2Wrapper(SwsContext *c, uint8_t* src[], int srcStride[], int srcSliceY,
+static int planarToYuy2Wrapper(SwsContext *c, const uint8_t* src[], int srcStride[], int srcSliceY,
                                int srcSliceH, uint8_t* dstParam[], int dstStride[])
 {
     uint8_t *dst=dstParam[0] + dstStride[0]*srcSliceY;
@@ -2024,7 +1303,7 @@
     return srcSliceH;
 }
 
-static int PlanarToUyvyWrapper(SwsContext *c, uint8_t* src[], int srcStride[], int srcSliceY,
+static int planarToUyvyWrapper(SwsContext *c, const uint8_t* src[], int srcStride[], int srcSliceY,
                                int srcSliceH, uint8_t* dstParam[], int dstStride[])
 {
     uint8_t *dst=dstParam[0] + dstStride[0]*srcSliceY;
@@ -2034,7 +1313,7 @@
     return srcSliceH;
 }
 
-static int YUV422PToYuy2Wrapper(SwsContext *c, uint8_t* src[], int srcStride[], int srcSliceY,
+static int yuv422pToYuy2Wrapper(SwsContext *c, const uint8_t* src[], int srcStride[], int srcSliceY,
                                 int srcSliceH, uint8_t* dstParam[], int dstStride[])
 {
     uint8_t *dst=dstParam[0] + dstStride[0]*srcSliceY;
@@ -2044,7 +1323,7 @@
     return srcSliceH;
 }
 
-static int YUV422PToUyvyWrapper(SwsContext *c, uint8_t* src[], int srcStride[], int srcSliceY,
+static int yuv422pToUyvyWrapper(SwsContext *c, const uint8_t* src[], int srcStride[], int srcSliceY,
                                 int srcSliceH, uint8_t* dstParam[], int dstStride[])
 {
     uint8_t *dst=dstParam[0] + dstStride[0]*srcSliceY;
@@ -2054,7 +1333,7 @@
     return srcSliceH;
 }
 
-static int YUYV2YUV420Wrapper(SwsContext *c, uint8_t* src[], int srcStride[], int srcSliceY,
+static int yuyvToYuv420Wrapper(SwsContext *c, const uint8_t* src[], int srcStride[], int srcSliceY,
                                int srcSliceH, uint8_t* dstParam[], int dstStride[])
 {
     uint8_t *ydst=dstParam[0] + dstStride[0]*srcSliceY;
@@ -2069,7 +1348,7 @@
     return srcSliceH;
 }
 
-static int YUYV2YUV422Wrapper(SwsContext *c, uint8_t* src[], int srcStride[], int srcSliceY,
+static int yuyvToYuv422Wrapper(SwsContext *c, const uint8_t* src[], int srcStride[], int srcSliceY,
                                int srcSliceH, uint8_t* dstParam[], int dstStride[])
 {
     uint8_t *ydst=dstParam[0] + dstStride[0]*srcSliceY;
@@ -2081,7 +1360,7 @@
     return srcSliceH;
 }
 
-static int UYVY2YUV420Wrapper(SwsContext *c, uint8_t* src[], int srcStride[], int srcSliceY,
+static int uyvyToYuv420Wrapper(SwsContext *c, const uint8_t* src[], int srcStride[], int srcSliceY,
                                int srcSliceH, uint8_t* dstParam[], int dstStride[])
 {
     uint8_t *ydst=dstParam[0] + dstStride[0]*srcSliceY;
@@ -2096,7 +1375,7 @@
     return srcSliceH;
 }
 
-static int UYVY2YUV422Wrapper(SwsContext *c, uint8_t* src[], int srcStride[], int srcSliceY,
+static int uyvyToYuv422Wrapper(SwsContext *c, const uint8_t* src[], int srcStride[], int srcSliceY,
                                int srcSliceH, uint8_t* dstParam[], int dstStride[])
 {
     uint8_t *ydst=dstParam[0] + dstStride[0]*srcSliceY;
@@ -2108,8 +1387,8 @@
     return srcSliceH;
 }
 
-static int pal2rgbWrapper(SwsContext *c, uint8_t* src[], int srcStride[], int srcSliceY,
-                          int srcSliceH, uint8_t* dst[], int dstStride[])
+static int palToRgbWrapper(SwsContext *c, const uint8_t* src[], int srcStride[], int srcSliceY,
+                           int srcSliceH, uint8_t* dst[], int dstStride[])
 {
     const enum PixelFormat srcFormat= c-&gt;srcFormat;
     const enum PixelFormat dstFormat= c-&gt;dstFormat;
@@ -2117,48 +1396,71 @@
                  const uint8_t *palette)=NULL;
     int i;
     uint8_t *dstPtr= dst[0] + dstStride[0]*srcSliceY;
-    uint8_t *srcPtr= src[0];
+    const uint8_t *srcPtr= src[0];
 
-    if (!usePal(srcFormat))
+    if (usePal(srcFormat)) {
+        switch (dstFormat) {
+        case PIX_FMT_RGB32  : conv = palette8topacked32; break;
+        case PIX_FMT_BGR32  : conv = palette8topacked32; break;
+        case PIX_FMT_BGR32_1: conv = palette8topacked32; break;
+        case PIX_FMT_RGB32_1: conv = palette8topacked32; break;
+        case PIX_FMT_RGB24  : conv = palette8topacked24; break;
+        case PIX_FMT_BGR24  : conv = palette8topacked24; break;
+        }
+    }
+
+    if (!conv)
         av_log(c, AV_LOG_ERROR, &quot;internal error %s -&gt; %s converter\n&quot;,
                sws_format_name(srcFormat), sws_format_name(dstFormat));
-
-    switch(dstFormat) {
-    case PIX_FMT_RGB32  : conv = palette8topacked32; break;
-    case PIX_FMT_BGR32  : conv = palette8topacked32; break;
-    case PIX_FMT_BGR32_1: conv = palette8topacked32; break;
-    case PIX_FMT_RGB32_1: conv = palette8topacked32; break;
-    case PIX_FMT_RGB24  : conv = palette8topacked24; break;
-    case PIX_FMT_BGR24  : conv = palette8topacked24; break;
-    default: av_log(c, AV_LOG_ERROR, &quot;internal error %s -&gt; %s converter\n&quot;,
-                    sws_format_name(srcFormat), sws_format_name(dstFormat)); break;
+    else {
+        for (i=0; i&lt;srcSliceH; i++) {
+            conv(srcPtr, dstPtr, c-&gt;srcW, (uint8_t *) c-&gt;pal_rgb);
+            srcPtr+= srcStride[0];
+            dstPtr+= dstStride[0];
+        }
     }
 
-
-    for (i=0; i&lt;srcSliceH; i++) {
-        conv(srcPtr, dstPtr, c-&gt;srcW, (uint8_t *) c-&gt;pal_rgb);
-        srcPtr+= srcStride[0];
-        dstPtr+= dstStride[0];
-    }
-
     return srcSliceH;
 }
 
+#define isRGBA32(x) (            \
+           (x) == PIX_FMT_ARGB   \
+        || (x) == PIX_FMT_RGBA   \
+        || (x) == PIX_FMT_BGRA   \
+        || (x) == PIX_FMT_ABGR   \
+        )
+
 /* {RGB,BGR}{15,16,24,32,32_1} -&gt; {RGB,BGR}{15,16,24,32} */
-static int rgb2rgbWrapper(SwsContext *c, uint8_t* src[], int srcStride[], int srcSliceY,
-                          int srcSliceH, uint8_t* dst[], int dstStride[])
+static int rgbToRgbWrapper(SwsContext *c, const uint8_t* src[], int srcStride[], int srcSliceY,
+                           int srcSliceH, uint8_t* dst[], int dstStride[])
 {
     const enum PixelFormat srcFormat= c-&gt;srcFormat;
     const enum PixelFormat dstFormat= c-&gt;dstFormat;
-    const int srcBpp= (fmt_depth(srcFormat) + 7) &gt;&gt; 3;
-    const int dstBpp= (fmt_depth(dstFormat) + 7) &gt;&gt; 3;
-    const int srcId= fmt_depth(srcFormat) &gt;&gt; 2; /* 1:0, 4:1, 8:2, 15:3, 16:4, 24:6, 32:8 */
-    const int dstId= fmt_depth(dstFormat) &gt;&gt; 2;
+    const int srcBpp= (c-&gt;srcFormatBpp + 7) &gt;&gt; 3;
+    const int dstBpp= (c-&gt;dstFormatBpp + 7) &gt;&gt; 3;
+    const int srcId= c-&gt;srcFormatBpp &gt;&gt; 2; /* 1:0, 4:1, 8:2, 15:3, 16:4, 24:6, 32:8 */
+    const int dstId= c-&gt;dstFormatBpp &gt;&gt; 2;
     void (*conv)(const uint8_t *src, uint8_t *dst, long src_size)=NULL;
 
+#define CONV_IS(src, dst) (srcFormat == PIX_FMT_##src &amp;&amp; dstFormat == PIX_FMT_##dst)
+
+    if (isRGBA32(srcFormat) &amp;&amp; isRGBA32(dstFormat)) {
+        if (     CONV_IS(ABGR, RGBA)
+              || CONV_IS(ARGB, BGRA)
+              || CONV_IS(BGRA, ARGB)
+              || CONV_IS(RGBA, ABGR)) conv = shuffle_bytes_3210;
+        else if (CONV_IS(ABGR, ARGB)
+              || CONV_IS(ARGB, ABGR)) conv = shuffle_bytes_0321;
+        else if (CONV_IS(ABGR, BGRA)
+              || CONV_IS(ARGB, RGBA)) conv = shuffle_bytes_1230;
+        else if (CONV_IS(BGRA, RGBA)
+              || CONV_IS(RGBA, BGRA)) conv = shuffle_bytes_2103;
+        else if (CONV_IS(BGRA, ABGR)
+              || CONV_IS(RGBA, ARGB)) conv = shuffle_bytes_3012;
+    } else
     /* BGR -&gt; BGR */
-    if (  (isBGR(srcFormat) &amp;&amp; isBGR(dstFormat))
-       || (isRGB(srcFormat) &amp;&amp; isRGB(dstFormat))) {
+    if (  (isBGRinInt(srcFormat) &amp;&amp; isBGRinInt(dstFormat))
+       || (isRGBinInt(srcFormat) &amp;&amp; isRGBinInt(dstFormat))) {
         switch(srcId | (dstId&lt;&lt;4)) {
         case 0x34: conv= rgb16to15; break;
         case 0x36: conv= rgb24to15; break;
@@ -2172,11 +1474,9 @@
         case 0x83: conv= rgb15to32; break;
         case 0x84: conv= rgb16to32; break;
         case 0x86: conv= rgb24to32; break;
-        default: av_log(c, AV_LOG_ERROR, &quot;internal error %s -&gt; %s converter\n&quot;,
-                        sws_format_name(srcFormat), sws_format_name(dstFormat)); break;
         }
-    } else if (  (isBGR(srcFormat) &amp;&amp; isRGB(dstFormat))
-             || (isRGB(srcFormat) &amp;&amp; isBGR(dstFormat))) {
+    } else if (  (isBGRinInt(srcFormat) &amp;&amp; isRGBinInt(dstFormat))
+             || (isRGBinInt(srcFormat) &amp;&amp; isBGRinInt(dstFormat))) {
         switch(srcId | (dstId&lt;&lt;4)) {
         case 0x33: conv= rgb15tobgr15; break;
         case 0x34: conv= rgb16tobgr15; break;
@@ -2193,25 +1493,26 @@
         case 0x83: conv= rgb15tobgr32; break;
         case 0x84: conv= rgb16tobgr32; break;
         case 0x86: conv= rgb24tobgr32; break;
-        case 0x88: conv= rgb32tobgr32; break;
-        default: av_log(c, AV_LOG_ERROR, &quot;internal error %s -&gt; %s converter\n&quot;,
-                        sws_format_name(srcFormat), sws_format_name(dstFormat)); break;
         }
-    } else {
-        av_log(c, AV_LOG_ERROR, &quot;internal error %s -&gt; %s converter\n&quot;,
-               sws_format_name(srcFormat), sws_format_name(dstFormat));
     }
 
-    if(conv) {
-        uint8_t *srcPtr= src[0];
-        if(srcFormat == PIX_FMT_RGB32_1 || srcFormat == PIX_FMT_BGR32_1)
+    if (!conv) {
+        av_log(c, AV_LOG_ERROR, &quot;internal error %s -&gt; %s converter\n&quot;,
+               sws_format_name(srcFormat), sws_format_name(dstFormat));
+    } else {
+        const uint8_t *srcPtr= src[0];
+              uint8_t *dstPtr= dst[0];
+        if ((srcFormat == PIX_FMT_RGB32_1 || srcFormat == PIX_FMT_BGR32_1) &amp;&amp; !isRGBA32(dstFormat))
             srcPtr += ALT32_CORR;
 
+        if ((dstFormat == PIX_FMT_RGB32_1 || dstFormat == PIX_FMT_BGR32_1) &amp;&amp; !isRGBA32(srcFormat))
+            dstPtr += ALT32_CORR;
+
         if (dstStride[0]*srcBpp == srcStride[0]*dstBpp &amp;&amp; srcStride[0] &gt; 0)
-            conv(srcPtr, dst[0] + dstStride[0]*srcSliceY, srcSliceH*srcStride[0]);
+            conv(srcPtr, dstPtr + dstStride[0]*srcSliceY, srcSliceH*srcStride[0]);
         else {
             int i;
-            uint8_t *dstPtr= dst[0] + dstStride[0]*srcSliceY;
+            dstPtr += dstStride[0]*srcSliceY;
 
             for (i=0; i&lt;srcSliceH; i++) {
                 conv(srcPtr, dstPtr, c-&gt;srcW*srcBpp);
@@ -2223,10 +1524,9 @@
     return srcSliceH;
 }
 
-static int bgr24toyv12Wrapper(SwsContext *c, uint8_t* src[], int srcStride[], int srcSliceY,
+static int bgr24ToYv12Wrapper(SwsContext *c, const uint8_t* src[], int srcStride[], int srcSliceY,
                               int srcSliceH, uint8_t* dst[], int dstStride[])
 {
-
     rgb24toyv12(
         src[0],
         dst[0]+ srcSliceY    *dstStride[0],
@@ -2239,7 +1539,7 @@
     return srcSliceH;
 }
 
-static int yvu9toyv12Wrapper(SwsContext *c, uint8_t* src[], int srcStride[], int srcSliceY,
+static int yvu9ToYv12Wrapper(SwsContext *c, const uint8_t* src[], int srcStride[], int srcSliceY,
                              int srcSliceH, uint8_t* dst[], int dstStride[])
 {
     int i;
@@ -2248,7 +1548,7 @@
     if (srcStride[0]==dstStride[0] &amp;&amp; srcStride[0] &gt; 0)
         memcpy(dst[0]+ srcSliceY*dstStride[0], src[0], srcStride[0]*srcSliceH);
     else {
-        uint8_t *srcPtr= src[0];
+        const uint8_t *srcPtr= src[0];
         uint8_t *dstPtr= dst[0] + dstStride[0]*srcSliceY;
 
         for (i=0; i&lt;srcSliceH; i++) {
@@ -2275,14 +1575,14 @@
 }
 
 /* unscaled copy like stuff (assumes nearly identical formats) */
-static int packedCopy(SwsContext *c, uint8_t* src[], int srcStride[], int srcSliceY,
-                      int srcSliceH, uint8_t* dst[], int dstStride[])
+static int packedCopyWrapper(SwsContext *c, const uint8_t* src[], int srcStride[], int srcSliceY,
+                             int srcSliceH, uint8_t* dst[], int dstStride[])
 {
     if (dstStride[0]==srcStride[0] &amp;&amp; srcStride[0] &gt; 0)
         memcpy(dst[0] + dstStride[0]*srcSliceY, src[0], srcSliceH*dstStride[0]);
     else {
         int i;
-        uint8_t *srcPtr= src[0];
+        const uint8_t *srcPtr= src[0];
         uint8_t *dstPtr= dst[0] + dstStride[0]*srcSliceY;
         int length=0;
 
@@ -2300,15 +1600,15 @@
     return srcSliceH;
 }
 
-static int planarCopy(SwsContext *c, uint8_t* src[], int srcStride[], int srcSliceY,
-                      int srcSliceH, uint8_t* dst[], int dstStride[])
+static int planarCopyWrapper(SwsContext *c, const uint8_t* src[], int srcStride[], int srcSliceY,
+                             int srcSliceH, uint8_t* dst[], int dstStride[])
 {
     int plane, i, j;
     for (plane=0; plane&lt;4; plane++) {
         int length= (plane==0 || plane==3) ? c-&gt;srcW  : -((-c-&gt;srcW  )&gt;&gt;c-&gt;chrDstHSubSample);
         int y=      (plane==0 || plane==3) ? srcSliceY: -((-srcSliceY)&gt;&gt;c-&gt;chrDstVSubSample);
         int height= (plane==0 || plane==3) ? srcSliceH: -((-srcSliceH)&gt;&gt;c-&gt;chrDstVSubSample);
-        uint8_t *srcPtr= src[plane];
+        const uint8_t *srcPtr= src[plane];
         uint8_t *dstPtr= dst[plane] + dstStride[plane]*y;
 
         if (!dst[plane]) continue;
@@ -2340,7 +1640,7 @@
 
                 for (i=0; i&lt;height; i++) {
                     for (j=0; j&lt;length; j++)
-                        ((uint16_t*)dstPtr)[j] = bswap_16(((uint16_t*)srcPtr)[j]);
+                        ((uint16_t*)dstPtr)[j] = bswap_16(((const uint16_t*)srcPtr)[j]);
                     srcPtr+= srcStride[plane];
                     dstPtr+= dstStride[plane];
                 }
@@ -2360,182 +1660,9 @@
     return srcSliceH;
 }
 
-
-static void getSubSampleFactors(int *h, int *v, int format)
+int ff_hardcodedcpuflags(void)
 {
-    switch(format) {
-    case PIX_FMT_UYVY422:
-    case PIX_FMT_YUYV422:
-        *h=1;
-        *v=0;
-        break;
-    case PIX_FMT_YUV420P:
-    case PIX_FMT_YUV420PLE:
-    case PIX_FMT_YUV420PBE:
-    case PIX_FMT_YUVA420P:
-    case PIX_FMT_GRAY16BE:
-    case PIX_FMT_GRAY16LE:
-    case PIX_FMT_GRAY8: //FIXME remove after different subsamplings are fully implemented
-    case PIX_FMT_NV12:
-    case PIX_FMT_NV21:
-        *h=1;
-        *v=1;
-        break;
-    case PIX_FMT_YUV440P:
-        *h=0;
-        *v=1;
-        break;
-    case PIX_FMT_YUV410P:
-        *h=2;
-        *v=2;
-        break;
-    case PIX_FMT_YUV444P:
-    case PIX_FMT_YUV444PLE:
-    case PIX_FMT_YUV444PBE:
-        *h=0;
-        *v=0;
-        break;
-    case PIX_FMT_YUV422P:
-    case PIX_FMT_YUV422PLE:
-    case PIX_FMT_YUV422PBE:
-        *h=1;
-        *v=0;
-        break;
-    case PIX_FMT_YUV411P:
-        *h=2;
-        *v=0;
-        break;
-    default:
-        *h=0;
-        *v=0;
-        break;
-    }
-}
-
-static uint16_t roundToInt16(int64_t f)
-{
-    int r= (f + (1&lt;&lt;15))&gt;&gt;16;
-         if (r&lt;-0x7FFF) return 0x8000;
-    else if (r&gt; 0x7FFF) return 0x7FFF;
-    else                return r;
-}
-
-int sws_setColorspaceDetails(SwsContext *c, const int inv_table[4], int srcRange, const int table[4], int dstRange, int brightness, int contrast, int saturation)
-{
-    int64_t crv =  inv_table[0];
-    int64_t cbu =  inv_table[1];
-    int64_t cgu = -inv_table[2];
-    int64_t cgv = -inv_table[3];
-    int64_t cy  = 1&lt;&lt;16;
-    int64_t oy  = 0;
-
-    memcpy(c-&gt;srcColorspaceTable, inv_table, sizeof(int)*4);
-    memcpy(c-&gt;dstColorspaceTable,     table, sizeof(int)*4);
-
-    c-&gt;brightness= brightness;
-    c-&gt;contrast  = contrast;
-    c-&gt;saturation= saturation;
-    c-&gt;srcRange  = srcRange;
-    c-&gt;dstRange  = dstRange;
-    if (isYUV(c-&gt;dstFormat) || isGray(c-&gt;dstFormat)) return -1;
-
-    c-&gt;uOffset=   0x0400040004000400LL;
-    c-&gt;vOffset=   0x0400040004000400LL;
-
-    if (!srcRange) {
-        cy= (cy*255) / 219;
-        oy= 16&lt;&lt;16;
-    } else {
-        crv= (crv*224) / 255;
-        cbu= (cbu*224) / 255;
-        cgu= (cgu*224) / 255;
-        cgv= (cgv*224) / 255;
-    }
-
-    cy = (cy *contrast             )&gt;&gt;16;
-    crv= (crv*contrast * saturation)&gt;&gt;32;
-    cbu= (cbu*contrast * saturation)&gt;&gt;32;
-    cgu= (cgu*contrast * saturation)&gt;&gt;32;
-    cgv= (cgv*contrast * saturation)&gt;&gt;32;
-
-    oy -= 256*brightness;
-
-    c-&gt;yCoeff=    roundToInt16(cy *8192) * 0x0001000100010001ULL;
-    c-&gt;vrCoeff=   roundToInt16(crv*8192) * 0x0001000100010001ULL;
-    c-&gt;ubCoeff=   roundToInt16(cbu*8192) * 0x0001000100010001ULL;
-    c-&gt;vgCoeff=   roundToInt16(cgv*8192) * 0x0001000100010001ULL;
-    c-&gt;ugCoeff=   roundToInt16(cgu*8192) * 0x0001000100010001ULL;
-    c-&gt;yOffset=   roundToInt16(oy *   8) * 0x0001000100010001ULL;
-
-    c-&gt;yuv2rgb_y_coeff  = (int16_t)roundToInt16(cy &lt;&lt;13);
-    c-&gt;yuv2rgb_y_offset = (int16_t)roundToInt16(oy &lt;&lt; 9);
-    c-&gt;yuv2rgb_v2r_coeff= (int16_t)roundToInt16(crv&lt;&lt;13);
-    c-&gt;yuv2rgb_v2g_coeff= (int16_t)roundToInt16(cgv&lt;&lt;13);
-    c-&gt;yuv2rgb_u2g_coeff= (int16_t)roundToInt16(cgu&lt;&lt;13);
-    c-&gt;yuv2rgb_u2b_coeff= (int16_t)roundToInt16(cbu&lt;&lt;13);
-
-    ff_yuv2rgb_c_init_tables(c, inv_table, srcRange, brightness, contrast, saturation);
-    //FIXME factorize
-
-#ifdef COMPILE_ALTIVEC
-    if (c-&gt;flags &amp; SWS_CPU_CAPS_ALTIVEC)
-        ff_yuv2rgb_init_tables_altivec(c, inv_table, brightness, contrast, saturation);
-#endif
-    return 0;
-}
-
-int sws_getColorspaceDetails(SwsContext *c, int **inv_table, int *srcRange, int **table, int *dstRange, int *brightness, int *contrast, int *saturation)
-{
-    if (isYUV(c-&gt;dstFormat) || isGray(c-&gt;dstFormat)) return -1;
-
-    *inv_table = c-&gt;srcColorspaceTable;
-    *table     = c-&gt;dstColorspaceTable;
-    *srcRange  = c-&gt;srcRange;
-    *dstRange  = c-&gt;dstRange;
-    *brightness= c-&gt;brightness;
-    *contrast  = c-&gt;contrast;
-    *saturation= c-&gt;saturation;
-
-    return 0;
-}
-
-static int handle_jpeg(enum PixelFormat *format)
-{
-    switch (*format) {
-    case PIX_FMT_YUVJ420P:
-        *format = PIX_FMT_YUV420P;
-        return 1;
-    case PIX_FMT_YUVJ422P:
-        *format = PIX_FMT_YUV422P;
-        return 1;
-    case PIX_FMT_YUVJ444P:
-        *format = PIX_FMT_YUV444P;
-        return 1;
-    case PIX_FMT_YUVJ440P:
-        *format = PIX_FMT_YUV440P;
-        return 1;
-    default:
-        return 0;
-    }
-}
-
-SwsContext *sws_getContext(int srcW, int srcH, enum PixelFormat srcFormat, int dstW, int dstH, enum PixelFormat dstFormat, int flags,
-                           SwsFilter *srcFilter, SwsFilter *dstFilter, const double *param)
-{
-
-    SwsContext *c;
-    int i;
-    int usesVFilter, usesHFilter;
-    int unscaled, needsDither;
-    int srcRange, dstRange;
-    SwsFilter dummyFilter= {NULL, NULL, NULL, NULL};
-#if ARCH_X86
-    if (flags &amp; SWS_CPU_CAPS_MMX)
-        __asm__ volatile(&quot;emms\n\t&quot;::: &quot;memory&quot;);
-#endif
-
-#if !CONFIG_RUNTIME_CPUDETECT //ensure that the flags match the compiled variant if cpudetect is off
-    flags &amp;= ~(SWS_CPU_CAPS_MMX|SWS_CPU_CAPS_MMX2|SWS_CPU_CAPS_3DNOW|SWS_CPU_CAPS_ALTIVEC|SWS_CPU_CAPS_BFIN);
+    int flags = 0;
 #if   COMPILE_TEMPLATE_MMX2
     flags |= SWS_CPU_CAPS_MMX|SWS_CPU_CAPS_MMX2;
 #elif COMPILE_TEMPLATE_AMD3DNOW
@@ -2547,517 +1674,134 @@
 #elif ARCH_BFIN
     flags |= SWS_CPU_CAPS_BFIN;
 #endif
-#endif /* CONFIG_RUNTIME_CPUDETECT */
-    if (clip_table[512] != 255) globalInit();
-    if (!rgb15to16) sws_rgb2rgb_init(flags);
+    return flags;
+}
 
-    unscaled = (srcW == dstW &amp;&amp; srcH == dstH);
-    needsDither= (isBGR(dstFormat) || isRGB(dstFormat))
-        &amp;&amp; (fmt_depth(dstFormat))&lt;24
-        &amp;&amp; ((fmt_depth(dstFormat))&lt;(fmt_depth(srcFormat)) || (!(isRGB(srcFormat) || isBGR(srcFormat))));
+void ff_get_unscaled_swscale(SwsContext *c)
+{
+    const enum PixelFormat srcFormat = c-&gt;srcFormat;
+    const enum PixelFormat dstFormat = c-&gt;dstFormat;
+    const int flags = c-&gt;flags;
+    const int dstH = c-&gt;dstH;
+    int needsDither;
 
-    srcRange = handle_jpeg(&amp;srcFormat);
-    dstRange = handle_jpeg(&amp;dstFormat);
+    needsDither= isAnyRGB(dstFormat)
+        &amp;&amp;  c-&gt;dstFormatBpp &lt; 24
+        &amp;&amp; (c-&gt;dstFormatBpp &lt; c-&gt;srcFormatBpp || (!isAnyRGB(srcFormat)));
 
-    if (!isSupportedIn(srcFormat)) {
-        av_log(NULL, AV_LOG_ERROR, &quot;swScaler: %s is not supported as input pixel format\n&quot;, sws_format_name(srcFormat));
-        return NULL;
+    /* yv12_to_nv12 */
+    if ((srcFormat == PIX_FMT_YUV420P || srcFormat == PIX_FMT_YUVA420P) &amp;&amp; (dstFormat == PIX_FMT_NV12 || dstFormat == PIX_FMT_NV21)) {
+        c-&gt;swScale= planarToNv12Wrapper;
     }
-    if (!isSupportedOut(dstFormat)) {
-        av_log(NULL, AV_LOG_ERROR, &quot;swScaler: %s is not supported as output pixel format\n&quot;, sws_format_name(dstFormat));
-        return NULL;
+    /* yuv2bgr */
+    if ((srcFormat==PIX_FMT_YUV420P || srcFormat==PIX_FMT_YUV422P || srcFormat==PIX_FMT_YUVA420P) &amp;&amp; isAnyRGB(dstFormat)
+        &amp;&amp; !(flags &amp; SWS_ACCURATE_RND) &amp;&amp; !(dstH&amp;1)) {
+        c-&gt;swScale= ff_yuv2rgb_get_func_ptr(c);
     }
 
-    i= flags &amp; ( SWS_POINT
-                |SWS_AREA
-                |SWS_BILINEAR
-                |SWS_FAST_BILINEAR
-                |SWS_BICUBIC
-                |SWS_X
-                |SWS_GAUSS
-                |SWS_LANCZOS
-                |SWS_SINC
-                |SWS_SPLINE
-                |SWS_BICUBLIN);
-    if(!i || (i &amp; (i-1))) {
-        av_log(NULL, AV_LOG_ERROR, &quot;swScaler: Exactly one scaler algorithm must be chosen\n&quot;);
-        return NULL;
+    if (srcFormat==PIX_FMT_YUV410P &amp;&amp; (dstFormat==PIX_FMT_YUV420P || dstFormat==PIX_FMT_YUVA420P) &amp;&amp; !(flags &amp; SWS_BITEXACT)) {
+        c-&gt;swScale= yvu9ToYv12Wrapper;
     }
 
-    /* sanity check */
-    if (srcW&lt;4 || srcH&lt;1 || dstW&lt;8 || dstH&lt;1) { //FIXME check if these are enough and try to lowwer them after fixing the relevant parts of the code
-        av_log(NULL, AV_LOG_ERROR, &quot;swScaler: %dx%d -&gt; %dx%d is invalid scaling dimension\n&quot;,
-               srcW, srcH, dstW, dstH);
-        return NULL;
-    }
-    if(srcW &gt; VOFW || dstW &gt; VOFW) {
-        av_log(NULL, AV_LOG_ERROR, &quot;swScaler: Compile-time maximum width is &quot;AV_STRINGIFY(VOFW)&quot; change VOF/VOFW and recompile\n&quot;);
-        return NULL;
-    }
+    /* bgr24toYV12 */
+    if (srcFormat==PIX_FMT_BGR24 &amp;&amp; (dstFormat==PIX_FMT_YUV420P || dstFormat==PIX_FMT_YUVA420P) &amp;&amp; !(flags &amp; SWS_ACCURATE_RND))
+        c-&gt;swScale= bgr24ToYv12Wrapper;
 
-    if (!dstFilter) dstFilter= &dummyFilter;
-    if (!srcFilter) srcFilter= &dummyFilter;
+    /* RGB/BGR -&gt; RGB/BGR (no dither needed forms) */
+    if (   isAnyRGB(srcFormat)
+        &amp;&amp; isAnyRGB(dstFormat)
+        &amp;&amp; srcFormat != PIX_FMT_BGR8      &amp;&amp; dstFormat != PIX_FMT_BGR8
+        &amp;&amp; srcFormat != PIX_FMT_RGB8      &amp;&amp; dstFormat != PIX_FMT_RGB8
+        &amp;&amp; srcFormat != PIX_FMT_BGR4      &amp;&amp; dstFormat != PIX_FMT_BGR4
+        &amp;&amp; srcFormat != PIX_FMT_RGB4      &amp;&amp; dstFormat != PIX_FMT_RGB4
+        &amp;&amp; srcFormat != PIX_FMT_BGR4_BYTE &amp;&amp; dstFormat != PIX_FMT_BGR4_BYTE
+        &amp;&amp; srcFormat != PIX_FMT_RGB4_BYTE &amp;&amp; dstFormat != PIX_FMT_RGB4_BYTE
+        &amp;&amp; srcFormat != PIX_FMT_MONOBLACK &amp;&amp; dstFormat != PIX_FMT_MONOBLACK
+        &amp;&amp; srcFormat != PIX_FMT_MONOWHITE &amp;&amp; dstFormat != PIX_FMT_MONOWHITE
+        &amp;&amp; srcFormat != PIX_FMT_RGB48LE   &amp;&amp; dstFormat != PIX_FMT_RGB48LE
+        &amp;&amp; srcFormat != PIX_FMT_RGB48BE   &amp;&amp; dstFormat != PIX_FMT_RGB48BE
+        &amp;&amp; (!needsDither || (c-&gt;flags&amp;(SWS_FAST_BILINEAR|SWS_POINT))))
+        c-&gt;swScale= rgbToRgbWrapper;
 
-    c= av_mallocz(sizeof(SwsContext));
+    if ((usePal(srcFormat) &amp;&amp; (
+        dstFormat == PIX_FMT_RGB32   ||
+        dstFormat == PIX_FMT_RGB32_1 ||
+        dstFormat == PIX_FMT_RGB24   ||
+        dstFormat == PIX_FMT_BGR32   ||
+        dstFormat == PIX_FMT_BGR32_1 ||
+        dstFormat == PIX_FMT_BGR24)))
+        c-&gt;swScale= palToRgbWrapper;
 
-    c-&gt;av_class = &amp;sws_context_class;
-    c-&gt;srcW= srcW;
-    c-&gt;srcH= srcH;
-    c-&gt;dstW= dstW;
-    c-&gt;dstH= dstH;
-    c-&gt;lumXInc= ((srcW&lt;&lt;16) + (dstW&gt;&gt;1))/dstW;
-    c-&gt;lumYInc= ((srcH&lt;&lt;16) + (dstH&gt;&gt;1))/dstH;
-    c-&gt;flags= flags;
-    c-&gt;dstFormat= dstFormat;
-    c-&gt;srcFormat= srcFormat;
-    c-&gt;vRounder= 4* 0x0001000100010001ULL;
-
-    usesHFilter= usesVFilter= 0;
-    if (dstFilter-&gt;lumV &amp;&amp; dstFilter-&gt;lumV-&gt;length&gt;1) usesVFilter=1;
-    if (dstFilter-&gt;lumH &amp;&amp; dstFilter-&gt;lumH-&gt;length&gt;1) usesHFilter=1;
-    if (dstFilter-&gt;chrV &amp;&amp; dstFilter-&gt;chrV-&gt;length&gt;1) usesVFilter=1;
-    if (dstFilter-&gt;chrH &amp;&amp; dstFilter-&gt;chrH-&gt;length&gt;1) usesHFilter=1;
-    if (srcFilter-&gt;lumV &amp;&amp; srcFilter-&gt;lumV-&gt;length&gt;1) usesVFilter=1;
-    if (srcFilter-&gt;lumH &amp;&amp; srcFilter-&gt;lumH-&gt;length&gt;1) usesHFilter=1;
-    if (srcFilter-&gt;chrV &amp;&amp; srcFilter-&gt;chrV-&gt;length&gt;1) usesVFilter=1;
-    if (srcFilter-&gt;chrH &amp;&amp; srcFilter-&gt;chrH-&gt;length&gt;1) usesHFilter=1;
-
-    getSubSampleFactors(&amp;c-&gt;chrSrcHSubSample, &amp;c-&gt;chrSrcVSubSample, srcFormat);
-    getSubSampleFactors(&amp;c-&gt;chrDstHSubSample, &amp;c-&gt;chrDstVSubSample, dstFormat);
-
-    // reuse chroma for 2 pixels RGB/BGR unless user wants full chroma interpolation
-    if ((isBGR(dstFormat) || isRGB(dstFormat)) &amp;&amp; !(flags&amp;SWS_FULL_CHR_H_INT)) c-&gt;chrDstHSubSample=1;
-
-    // drop some chroma lines if the user wants it
-    c-&gt;vChrDrop= (flags&amp;SWS_SRC_V_CHR_DROP_MASK)&gt;&gt;SWS_SRC_V_CHR_DROP_SHIFT;
-    c-&gt;chrSrcVSubSample+= c-&gt;vChrDrop;
-
-    // drop every other pixel for chroma calculation unless user wants full chroma
-    if ((isBGR(srcFormat) || isRGB(srcFormat)) &amp;&amp; !(flags&amp;SWS_FULL_CHR_H_INP)
-      &amp;&amp; srcFormat!=PIX_FMT_RGB8      &amp;&amp; srcFormat!=PIX_FMT_BGR8
-      &amp;&amp; srcFormat!=PIX_FMT_RGB4      &amp;&amp; srcFormat!=PIX_FMT_BGR4
-      &amp;&amp; srcFormat!=PIX_FMT_RGB4_BYTE &amp;&amp; srcFormat!=PIX_FMT_BGR4_BYTE
-      &amp;&amp; ((dstW&gt;&gt;c-&gt;chrDstHSubSample) &lt;= (srcW&gt;&gt;1) || (flags&amp;(SWS_FAST_BILINEAR|SWS_POINT))))
-        c-&gt;chrSrcHSubSample=1;
-
-    if (param) {
-        c-&gt;param[0] = param[0];
-        c-&gt;param[1] = param[1];
-    } else {
-        c-&gt;param[0] =
-        c-&gt;param[1] = SWS_PARAM_DEFAULT;
+    if (srcFormat == PIX_FMT_YUV422P) {
+        if (dstFormat == PIX_FMT_YUYV422)
+            c-&gt;swScale= yuv422pToYuy2Wrapper;
+        else if (dstFormat == PIX_FMT_UYVY422)
+            c-&gt;swScale= yuv422pToUyvyWrapper;
     }
 
-    // Note the -((-x)&gt;&gt;y) is so that we always round toward +inf.
-    c-&gt;chrSrcW= -((-srcW) &gt;&gt; c-&gt;chrSrcHSubSample);
-    c-&gt;chrSrcH= -((-srcH) &gt;&gt; c-&gt;chrSrcVSubSample);
-    c-&gt;chrDstW= -((-dstW) &gt;&gt; c-&gt;chrDstHSubSample);
-    c-&gt;chrDstH= -((-dstH) &gt;&gt; c-&gt;chrDstVSubSample);
-
-    sws_setColorspaceDetails(c, ff_yuv2rgb_coeffs[SWS_CS_DEFAULT], srcRange, ff_yuv2rgb_coeffs[SWS_CS_DEFAULT] /* FIXME*/, dstRange, 0, 1&lt;&lt;16, 1&lt;&lt;16);
-
-    /* unscaled special cases */
-    if (unscaled &amp;&amp; !usesHFilter &amp;&amp; !usesVFilter &amp;&amp; (srcRange == dstRange || isBGR(dstFormat) || isRGB(dstFormat))) {
-        /* yv12_to_nv12 */
-        if ((srcFormat == PIX_FMT_YUV420P || srcFormat == PIX_FMT_YUVA420P) &amp;&amp; (dstFormat == PIX_FMT_NV12 || dstFormat == PIX_FMT_NV21)) {
-            c-&gt;swScale= PlanarToNV12Wrapper;
-        }
-        /* yuv2bgr */
-        if ((srcFormat==PIX_FMT_YUV420P || srcFormat==PIX_FMT_YUV422P || srcFormat==PIX_FMT_YUVA420P) &amp;&amp; (isBGR(dstFormat) || isRGB(dstFormat))
-            &amp;&amp; !(flags &amp; SWS_ACCURATE_RND) &amp;&amp; !(dstH&amp;1)) {
-            c-&gt;swScale= ff_yuv2rgb_get_func_ptr(c);
-        }
-
-        if (srcFormat==PIX_FMT_YUV410P &amp;&amp; (dstFormat==PIX_FMT_YUV420P || dstFormat==PIX_FMT_YUVA420P) &amp;&amp; !(flags &amp; SWS_BITEXACT)) {
-            c-&gt;swScale= yvu9toyv12Wrapper;
-        }
-
-        /* bgr24toYV12 */
-        if (srcFormat==PIX_FMT_BGR24 &amp;&amp; (dstFormat==PIX_FMT_YUV420P || dstFormat==PIX_FMT_YUVA420P) &amp;&amp; !(flags &amp; SWS_ACCURATE_RND))
-            c-&gt;swScale= bgr24toyv12Wrapper;
-
-        /* RGB/BGR -&gt; RGB/BGR (no dither needed forms) */
-        if (  (isBGR(srcFormat) || isRGB(srcFormat))
-           &amp;&amp; (isBGR(dstFormat) || isRGB(dstFormat))
-           &amp;&amp; srcFormat != PIX_FMT_BGR8      &amp;&amp; dstFormat != PIX_FMT_BGR8
-           &amp;&amp; srcFormat != PIX_FMT_RGB8      &amp;&amp; dstFormat != PIX_FMT_RGB8
-           &amp;&amp; srcFormat != PIX_FMT_BGR4      &amp;&amp; dstFormat != PIX_FMT_BGR4
-           &amp;&amp; srcFormat != PIX_FMT_RGB4      &amp;&amp; dstFormat != PIX_FMT_RGB4
-           &amp;&amp; srcFormat != PIX_FMT_BGR4_BYTE &amp;&amp; dstFormat != PIX_FMT_BGR4_BYTE
-           &amp;&amp; srcFormat != PIX_FMT_RGB4_BYTE &amp;&amp; dstFormat != PIX_FMT_RGB4_BYTE
-           &amp;&amp; srcFormat != PIX_FMT_MONOBLACK &amp;&amp; dstFormat != PIX_FMT_MONOBLACK
-           &amp;&amp; srcFormat != PIX_FMT_MONOWHITE &amp;&amp; dstFormat != PIX_FMT_MONOWHITE
-                                             &amp;&amp; dstFormat != PIX_FMT_RGB32_1
-                                             &amp;&amp; dstFormat != PIX_FMT_BGR32_1
-           &amp;&amp; srcFormat != PIX_FMT_RGB48LE   &amp;&amp; dstFormat != PIX_FMT_RGB48LE
-           &amp;&amp; srcFormat != PIX_FMT_RGB48BE   &amp;&amp; dstFormat != PIX_FMT_RGB48BE
-           &amp;&amp; (!needsDither || (c-&gt;flags&amp;(SWS_FAST_BILINEAR|SWS_POINT))))
-             c-&gt;swScale= rgb2rgbWrapper;
-
-        if ((usePal(srcFormat) &amp;&amp; (
-                 dstFormat == PIX_FMT_RGB32   ||
-                 dstFormat == PIX_FMT_RGB32_1 ||
-                 dstFormat == PIX_FMT_RGB24   ||
-                 dstFormat == PIX_FMT_BGR32   ||
-                 dstFormat == PIX_FMT_BGR32_1 ||
-                 dstFormat == PIX_FMT_BGR24)))
-             c-&gt;swScale= pal2rgbWrapper;
-
-        if (srcFormat == PIX_FMT_YUV422P) {
+    /* LQ converters if -sws 0 or -sws 4*/
+    if (c-&gt;flags&amp;(SWS_FAST_BILINEAR|SWS_POINT)) {
+        /* yv12_to_yuy2 */
+        if (srcFormat == PIX_FMT_YUV420P || srcFormat == PIX_FMT_YUVA420P) {
             if (dstFormat == PIX_FMT_YUYV422)
-                c-&gt;swScale= YUV422PToYuy2Wrapper;
+                c-&gt;swScale= planarToYuy2Wrapper;
             else if (dstFormat == PIX_FMT_UYVY422)
-                c-&gt;swScale= YUV422PToUyvyWrapper;
+                c-&gt;swScale= planarToUyvyWrapper;
         }
+    }
+    if(srcFormat == PIX_FMT_YUYV422 &amp;&amp; (dstFormat == PIX_FMT_YUV420P || dstFormat == PIX_FMT_YUVA420P))
+        c-&gt;swScale= yuyvToYuv420Wrapper;
+    if(srcFormat == PIX_FMT_UYVY422 &amp;&amp; (dstFormat == PIX_FMT_YUV420P || dstFormat == PIX_FMT_YUVA420P))
+        c-&gt;swScale= uyvyToYuv420Wrapper;
+    if(srcFormat == PIX_FMT_YUYV422 &amp;&amp; dstFormat == PIX_FMT_YUV422P)
+        c-&gt;swScale= yuyvToYuv422Wrapper;
+    if(srcFormat == PIX_FMT_UYVY422 &amp;&amp; dstFormat == PIX_FMT_YUV422P)
+        c-&gt;swScale= uyvyToYuv422Wrapper;
 
-        /* LQ converters if -sws 0 or -sws 4*/
-        if (c-&gt;flags&amp;(SWS_FAST_BILINEAR|SWS_POINT)) {
-            /* yv12_to_yuy2 */
-            if (srcFormat == PIX_FMT_YUV420P || srcFormat == PIX_FMT_YUVA420P) {
-                if (dstFormat == PIX_FMT_YUYV422)
-                    c-&gt;swScale= PlanarToYuy2Wrapper;
-                else if (dstFormat == PIX_FMT_UYVY422)
-                    c-&gt;swScale= PlanarToUyvyWrapper;
-            }
-        }
-        if(srcFormat == PIX_FMT_YUYV422 &amp;&amp; (dstFormat == PIX_FMT_YUV420P || dstFormat == PIX_FMT_YUVA420P))
-            c-&gt;swScale= YUYV2YUV420Wrapper;
-        if(srcFormat == PIX_FMT_UYVY422 &amp;&amp; (dstFormat == PIX_FMT_YUV420P || dstFormat == PIX_FMT_YUVA420P))
-            c-&gt;swScale= UYVY2YUV420Wrapper;
-        if(srcFormat == PIX_FMT_YUYV422 &amp;&amp; dstFormat == PIX_FMT_YUV422P)
-            c-&gt;swScale= YUYV2YUV422Wrapper;
-        if(srcFormat == PIX_FMT_UYVY422 &amp;&amp; dstFormat == PIX_FMT_YUV422P)
-            c-&gt;swScale= UYVY2YUV422Wrapper;
-
 #ifdef COMPILE_ALTIVEC
-        if ((c-&gt;flags &amp; SWS_CPU_CAPS_ALTIVEC) &amp;&amp;
-            !(c-&gt;flags &amp; SWS_BITEXACT) &amp;&amp;
-            srcFormat == PIX_FMT_YUV420P) {
-          // unscaled YV12 -&gt; packed YUV, we want speed
-          if (dstFormat == PIX_FMT_YUYV422)
-              c-&gt;swScale= yv12toyuy2_unscaled_altivec;
-          else if (dstFormat == PIX_FMT_UYVY422)
-              c-&gt;swScale= yv12touyvy_unscaled_altivec;
-        }
-#endif
-
-        /* simple copy */
-        if (  srcFormat == dstFormat
-            || (srcFormat == PIX_FMT_YUVA420P &amp;&amp; dstFormat == PIX_FMT_YUV420P)
-            || (srcFormat == PIX_FMT_YUV420P &amp;&amp; dstFormat == PIX_FMT_YUVA420P)
-            || (isPlanarYUV(srcFormat) &amp;&amp; isGray(dstFormat))
-            || (isPlanarYUV(dstFormat) &amp;&amp; isGray(srcFormat))
-            || (isGray(dstFormat) &amp;&amp; isGray(srcFormat))
-            || (isPlanarYUV(srcFormat) &amp;&amp; isPlanarYUV(dstFormat)
-                &amp;&amp; c-&gt;chrDstHSubSample == c-&gt;chrSrcHSubSample
-                &amp;&amp; c-&gt;chrDstVSubSample == c-&gt;chrSrcVSubSample
-                &amp;&amp; dstFormat != PIX_FMT_NV12 &amp;&amp; dstFormat != PIX_FMT_NV21
-                &amp;&amp; srcFormat != PIX_FMT_NV12 &amp;&amp; srcFormat != PIX_FMT_NV21))
-        {
-            if (isPacked(c-&gt;srcFormat))
-                c-&gt;swScale= packedCopy;
-            else /* Planar YUV or gray */
-                c-&gt;swScale= planarCopy;
-        }
-#if ARCH_BFIN
-        if (flags &amp; SWS_CPU_CAPS_BFIN)
-            ff_bfin_get_unscaled_swscale (c);
-#endif
-
-        if (c-&gt;swScale) {
-            if (flags&amp;SWS_PRINT_INFO)
-                av_log(c, AV_LOG_INFO, &quot;using unscaled %s -&gt; %s special converter\n&quot;,
-                       sws_format_name(srcFormat), sws_format_name(dstFormat));
-            return c;
-        }
+    if ((c-&gt;flags &amp; SWS_CPU_CAPS_ALTIVEC) &amp;&amp;
+        !(c-&gt;flags &amp; SWS_BITEXACT) &amp;&amp;
+        srcFormat == PIX_FMT_YUV420P) {
+        // unscaled YV12 -&gt; packed YUV, we want speed
+        if (dstFormat == PIX_FMT_YUYV422)
+            c-&gt;swScale= yv12toyuy2_unscaled_altivec;
+        else if (dstFormat == PIX_FMT_UYVY422)
+            c-&gt;swScale= yv12touyvy_unscaled_altivec;
     }
-
-    if (flags &amp; SWS_CPU_CAPS_MMX2) {
-        c-&gt;canMMX2BeUsed= (dstW &gt;=srcW &amp;&amp; (dstW&amp;31)==0 &amp;&amp; (srcW&amp;15)==0) ? 1 : 0;
-        if (!c-&gt;canMMX2BeUsed &amp;&amp; dstW &gt;=srcW &amp;&amp; (srcW&amp;15)==0 &amp;&amp; (flags&amp;SWS_FAST_BILINEAR)) {
-            if (flags&amp;SWS_PRINT_INFO)
-                av_log(c, AV_LOG_INFO, &quot;output width is not a multiple of 32 -&gt; no MMX2 scaler\n&quot;);
-        }
-        if (usesHFilter) c-&gt;canMMX2BeUsed=0;
-    }
-    else
-        c-&gt;canMMX2BeUsed=0;
-
-    c-&gt;chrXInc= ((c-&gt;chrSrcW&lt;&lt;16) + (c-&gt;chrDstW&gt;&gt;1))/c-&gt;chrDstW;
-    c-&gt;chrYInc= ((c-&gt;chrSrcH&lt;&lt;16) + (c-&gt;chrDstH&gt;&gt;1))/c-&gt;chrDstH;
-
-    // match pixel 0 of the src to pixel 0 of dst and match pixel n-2 of src to pixel n-2 of dst
-    // but only for the FAST_BILINEAR mode otherwise do correct scaling
-    // n-2 is the last chrominance sample available
-    // this is not perfect, but no one should notice the difference, the more correct variant
-    // would be like the vertical one, but that would require some special code for the
-    // first and last pixel
-    if (flags&amp;SWS_FAST_BILINEAR) {
-        if (c-&gt;canMMX2BeUsed) {
-            c-&gt;lumXInc+= 20;
-            c-&gt;chrXInc+= 20;
-        }
-        //we don't use the x86 asm scaler if MMX is available
-        else if (flags &amp; SWS_CPU_CAPS_MMX) {
-            c-&gt;lumXInc = ((srcW-2)&lt;&lt;16)/(dstW-2) - 20;
-            c-&gt;chrXInc = ((c-&gt;chrSrcW-2)&lt;&lt;16)/(c-&gt;chrDstW-2) - 20;
-        }
-    }
-
-    /* precalculate horizontal scaler filter coefficients */
-    {
-        const int filterAlign=
-            (flags &amp; SWS_CPU_CAPS_MMX) ? 4 :
-            (flags &amp; SWS_CPU_CAPS_ALTIVEC) ? 8 :
-            1;
-
-        initFilter(&amp;c-&gt;hLumFilter, &amp;c-&gt;hLumFilterPos, &amp;c-&gt;hLumFilterSize, c-&gt;lumXInc,
-                   srcW      ,       dstW, filterAlign, 1&lt;&lt;14,
-                   (flags&amp;SWS_BICUBLIN) ? (flags|SWS_BICUBIC)  : flags,
-                   srcFilter-&gt;lumH, dstFilter-&gt;lumH, c-&gt;param);
-        initFilter(&amp;c-&gt;hChrFilter, &amp;c-&gt;hChrFilterPos, &amp;c-&gt;hChrFilterSize, c-&gt;chrXInc,
-                   c-&gt;chrSrcW, c-&gt;chrDstW, filterAlign, 1&lt;&lt;14,
-                   (flags&amp;SWS_BICUBLIN) ? (flags|SWS_BILINEAR) : flags,
-                   srcFilter-&gt;chrH, dstFilter-&gt;chrH, c-&gt;param);
-
-#if defined(COMPILE_MMX2)
-// can't downscale !!!
-        if (c-&gt;canMMX2BeUsed &amp;&amp; (flags &amp; SWS_FAST_BILINEAR)) {
-            c-&gt;lumMmx2FilterCodeSize = initMMX2HScaler(      dstW, c-&gt;lumXInc, NULL, NULL, NULL, 8);
-            c-&gt;chrMmx2FilterCodeSize = initMMX2HScaler(c-&gt;chrDstW, c-&gt;chrXInc, NULL, NULL, NULL, 4);
-
-#ifdef MAP_ANONYMOUS
-            c-&gt;lumMmx2FilterCode = mmap(NULL, c-&gt;lumMmx2FilterCodeSize, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS, 0, 0);
-            c-&gt;chrMmx2FilterCode = mmap(NULL, c-&gt;chrMmx2FilterCodeSize, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS, 0, 0);
-#elif HAVE_VIRTUALALLOC
-            c-&gt;lumMmx2FilterCode = VirtualAlloc(NULL, c-&gt;lumMmx2FilterCodeSize, MEM_COMMIT, PAGE_EXECUTE_READWRITE);
-            c-&gt;chrMmx2FilterCode = VirtualAlloc(NULL, c-&gt;chrMmx2FilterCodeSize, MEM_COMMIT, PAGE_EXECUTE_READWRITE);
-#else
-            c-&gt;lumMmx2FilterCode = av_malloc(c-&gt;lumMmx2FilterCodeSize);
-            c-&gt;chrMmx2FilterCode = av_malloc(c-&gt;chrMmx2FilterCodeSize);
 #endif
 
-            c-&gt;lumMmx2Filter   = av_malloc((dstW        /8+8)*sizeof(int16_t));
-            c-&gt;chrMmx2Filter   = av_malloc((c-&gt;chrDstW  /4+8)*sizeof(int16_t));
-            c-&gt;lumMmx2FilterPos= av_malloc((dstW      /2/8+8)*sizeof(int32_t));
-            c-&gt;chrMmx2FilterPos= av_malloc((c-&gt;chrDstW/2/4+8)*sizeof(int32_t));
-
-            initMMX2HScaler(      dstW, c-&gt;lumXInc, c-&gt;lumMmx2FilterCode, c-&gt;lumMmx2Filter, c-&gt;lumMmx2FilterPos, 8);
-            initMMX2HScaler(c-&gt;chrDstW, c-&gt;chrXInc, c-&gt;chrMmx2FilterCode, c-&gt;chrMmx2Filter, c-&gt;chrMmx2FilterPos, 4);
-
-#ifdef MAP_ANONYMOUS
-            mprotect(c-&gt;lumMmx2FilterCode, c-&gt;lumMmx2FilterCodeSize, PROT_EXEC | PROT_READ);
-            mprotect(c-&gt;chrMmx2FilterCode, c-&gt;chrMmx2FilterCodeSize, PROT_EXEC | PROT_READ);
-#endif
-        }
-#endif /* defined(COMPILE_MMX2) */
-    } // initialize horizontal stuff
-
-
-
-    /* precalculate vertical scaler filter coefficients */
+    /* simple copy */
+    if (  srcFormat == dstFormat
+        || (srcFormat == PIX_FMT_YUVA420P &amp;&amp; dstFormat == PIX_FMT_YUV420P)
+        || (srcFormat == PIX_FMT_YUV420P &amp;&amp; dstFormat == PIX_FMT_YUVA420P)
+        || (isPlanarYUV(srcFormat) &amp;&amp; isGray(dstFormat))
+        || (isPlanarYUV(dstFormat) &amp;&amp; isGray(srcFormat))
+        || (isGray(dstFormat) &amp;&amp; isGray(srcFormat))
+        || (isPlanarYUV(srcFormat) &amp;&amp; isPlanarYUV(dstFormat)
+            &amp;&amp; c-&gt;chrDstHSubSample == c-&gt;chrSrcHSubSample
+            &amp;&amp; c-&gt;chrDstVSubSample == c-&gt;chrSrcVSubSample
+            &amp;&amp; dstFormat != PIX_FMT_NV12 &amp;&amp; dstFormat != PIX_FMT_NV21
+            &amp;&amp; srcFormat != PIX_FMT_NV12 &amp;&amp; srcFormat != PIX_FMT_NV21))
     {
-        const int filterAlign=
-            (flags &amp; SWS_CPU_CAPS_MMX) &amp;&amp; (flags &amp; SWS_ACCURATE_RND) ? 2 :
-            (flags &amp; SWS_CPU_CAPS_ALTIVEC) ? 8 :
-            1;
-
-        initFilter(&amp;c-&gt;vLumFilter, &amp;c-&gt;vLumFilterPos, &amp;c-&gt;vLumFilterSize, c-&gt;lumYInc,
-                   srcH      ,        dstH, filterAlign, (1&lt;&lt;12),
-                   (flags&amp;SWS_BICUBLIN) ? (flags|SWS_BICUBIC)  : flags,
-                   srcFilter-&gt;lumV, dstFilter-&gt;lumV, c-&gt;param);
-        initFilter(&amp;c-&gt;vChrFilter, &amp;c-&gt;vChrFilterPos, &amp;c-&gt;vChrFilterSize, c-&gt;chrYInc,
-                   c-&gt;chrSrcH, c-&gt;chrDstH, filterAlign, (1&lt;&lt;12),
-                   (flags&amp;SWS_BICUBLIN) ? (flags|SWS_BILINEAR) : flags,
-                   srcFilter-&gt;chrV, dstFilter-&gt;chrV, c-&gt;param);
-
-#ifdef COMPILE_ALTIVEC
-        c-&gt;vYCoeffsBank = av_malloc(sizeof (vector signed short)*c-&gt;vLumFilterSize*c-&gt;dstH);
-        c-&gt;vCCoeffsBank = av_malloc(sizeof (vector signed short)*c-&gt;vChrFilterSize*c-&gt;chrDstH);
-
-        for (i=0;i&lt;c-&gt;vLumFilterSize*c-&gt;dstH;i++) {
-            int j;
-            short *p = (short *)&amp;c-&gt;vYCoeffsBank[i];
-            for (j=0;j&lt;8;j++)
-                p[j] = c-&gt;vLumFilter[i];
-        }
-
-        for (i=0;i&lt;c-&gt;vChrFilterSize*c-&gt;chrDstH;i++) {
-            int j;
-            short *p = (short *)&amp;c-&gt;vCCoeffsBank[i];
-            for (j=0;j&lt;8;j++)
-                p[j] = c-&gt;vChrFilter[i];
-        }
-#endif
+        if (isPacked(c-&gt;srcFormat))
+            c-&gt;swScale= packedCopyWrapper;
+        else /* Planar YUV or gray */
+            c-&gt;swScale= planarCopyWrapper;
     }
-
-    // calculate buffer sizes so that they won't run out while handling these damn slices
-    c-&gt;vLumBufSize= c-&gt;vLumFilterSize;
-    c-&gt;vChrBufSize= c-&gt;vChrFilterSize;
-    for (i=0; i&lt;dstH; i++) {
-        int chrI= i*c-&gt;chrDstH / dstH;
-        int nextSlice= FFMAX(c-&gt;vLumFilterPos[i   ] + c-&gt;vLumFilterSize - 1,
-                           ((c-&gt;vChrFilterPos[chrI] + c-&gt;vChrFilterSize - 1)&lt;&lt;c-&gt;chrSrcVSubSample));
-
-        nextSlice&gt;&gt;= c-&gt;chrSrcVSubSample;
-        nextSlice&lt;&lt;= c-&gt;chrSrcVSubSample;
-        if (c-&gt;vLumFilterPos[i   ] + c-&gt;vLumBufSize &lt; nextSlice)
-            c-&gt;vLumBufSize= nextSlice - c-&gt;vLumFilterPos[i];
-        if (c-&gt;vChrFilterPos[chrI] + c-&gt;vChrBufSize &lt; (nextSlice&gt;&gt;c-&gt;chrSrcVSubSample))
-            c-&gt;vChrBufSize= (nextSlice&gt;&gt;c-&gt;chrSrcVSubSample) - c-&gt;vChrFilterPos[chrI];
-    }
-
-    // allocate pixbufs (we use dynamic allocation because otherwise we would need to
-    c-&gt;lumPixBuf= av_malloc(c-&gt;vLumBufSize*2*sizeof(int16_t*));
-    c-&gt;chrPixBuf= av_malloc(c-&gt;vChrBufSize*2*sizeof(int16_t*));
-    if (CONFIG_SWSCALE_ALPHA &amp;&amp; isALPHA(c-&gt;srcFormat) &amp;&amp; isALPHA(c-&gt;dstFormat))
-        c-&gt;alpPixBuf= av_malloc(c-&gt;vLumBufSize*2*sizeof(int16_t*));
-    //Note we need at least one pixel more at the end because of the MMX code (just in case someone wanna replace the 4000/8000)
-    /* align at 16 bytes for AltiVec */
-    for (i=0; i&lt;c-&gt;vLumBufSize; i++)
-        c-&gt;lumPixBuf[i]= c-&gt;lumPixBuf[i+c-&gt;vLumBufSize]= av_mallocz(VOF+1);
-    for (i=0; i&lt;c-&gt;vChrBufSize; i++)
-        c-&gt;chrPixBuf[i]= c-&gt;chrPixBuf[i+c-&gt;vChrBufSize]= av_malloc((VOF+1)*2);
-    if (CONFIG_SWSCALE_ALPHA &amp;&amp; c-&gt;alpPixBuf)
-        for (i=0; i&lt;c-&gt;vLumBufSize; i++)
-            c-&gt;alpPixBuf[i]= c-&gt;alpPixBuf[i+c-&gt;vLumBufSize]= av_mallocz(VOF+1);
-
-    //try to avoid drawing green stuff between the right end and the stride end
-    for (i=0; i&lt;c-&gt;vChrBufSize; i++) memset(c-&gt;chrPixBuf[i], 64, (VOF+1)*2);
-
-    assert(2*VOFW == VOF);
-
-    assert(c-&gt;chrDstH &lt;= dstH);
-
-    if (flags&amp;SWS_PRINT_INFO) {
-#ifdef DITHER1XBPP
-        const char *dither= &quot; dithered&quot;;
-#else
-        const char *dither= &quot;&quot;;
+#if ARCH_BFIN
+    if (flags &amp; SWS_CPU_CAPS_BFIN)
+        ff_bfin_get_unscaled_swscale (c);
 #endif
-        if (flags&amp;SWS_FAST_BILINEAR)
-            av_log(c, AV_LOG_INFO, &quot;FAST_BILINEAR scaler, &quot;);
-        else if (flags&amp;SWS_BILINEAR)
-            av_log(c, AV_LOG_INFO, &quot;BILINEAR scaler, &quot;);
-        else if (flags&amp;SWS_BICUBIC)
-            av_log(c, AV_LOG_INFO, &quot;BICUBIC scaler, &quot;);
-        else if (flags&amp;SWS_X)
-            av_log(c, AV_LOG_INFO, &quot;Experimental scaler, &quot;);
-        else if (flags&amp;SWS_POINT)
-            av_log(c, AV_LOG_INFO, &quot;Nearest Neighbor / POINT scaler, &quot;);
-        else if (flags&amp;SWS_AREA)
-            av_log(c, AV_LOG_INFO, &quot;Area Averageing scaler, &quot;);
-        else if (flags&amp;SWS_BICUBLIN)
-            av_log(c, AV_LOG_INFO, &quot;luma BICUBIC / chroma BILINEAR scaler, &quot;);
-        else if (flags&amp;SWS_GAUSS)
-            av_log(c, AV_LOG_INFO, &quot;Gaussian scaler, &quot;);
-        else if (flags&amp;SWS_SINC)
-            av_log(c, AV_LOG_INFO, &quot;Sinc scaler, &quot;);
-        else if (flags&amp;SWS_LANCZOS)
-            av_log(c, AV_LOG_INFO, &quot;Lanczos scaler, &quot;);
-        else if (flags&amp;SWS_SPLINE)
-            av_log(c, AV_LOG_INFO, &quot;Bicubic spline scaler, &quot;);
-        else
-            av_log(c, AV_LOG_INFO, &quot;ehh flags invalid?! &quot;);
-
-        if (dstFormat==PIX_FMT_BGR555 || dstFormat==PIX_FMT_BGR565)
-            av_log(c, AV_LOG_INFO, &quot;from %s to%s %s &quot;,
-                   sws_format_name(srcFormat), dither, sws_format_name(dstFormat));
-        else
-            av_log(c, AV_LOG_INFO, &quot;from %s to %s &quot;,
-                   sws_format_name(srcFormat), sws_format_name(dstFormat));
-
-        if (flags &amp; SWS_CPU_CAPS_MMX2)
-            av_log(c, AV_LOG_INFO, &quot;using MMX2\n&quot;);
-        else if (flags &amp; SWS_CPU_CAPS_3DNOW)
-            av_log(c, AV_LOG_INFO, &quot;using 3DNOW\n&quot;);
-        else if (flags &amp; SWS_CPU_CAPS_MMX)
-            av_log(c, AV_LOG_INFO, &quot;using MMX\n&quot;);
-        else if (flags &amp; SWS_CPU_CAPS_ALTIVEC)
-            av_log(c, AV_LOG_INFO, &quot;using AltiVec\n&quot;);
-        else
-            av_log(c, AV_LOG_INFO, &quot;using C\n&quot;);
-    }
-
-    if (flags &amp; SWS_PRINT_INFO) {
-        if (flags &amp; SWS_CPU_CAPS_MMX) {
-            if (c-&gt;canMMX2BeUsed &amp;&amp; (flags&amp;SWS_FAST_BILINEAR))
-                av_log(c, AV_LOG_VERBOSE, &quot;using FAST_BILINEAR MMX2 scaler for horizontal scaling\n&quot;);
-            else {
-                if (c-&gt;hLumFilterSize==4)
-                    av_log(c, AV_LOG_VERBOSE, &quot;using 4-tap MMX scaler for horizontal luminance scaling\n&quot;);
-                else if (c-&gt;hLumFilterSize==8)
-                    av_log(c, AV_LOG_VERBOSE, &quot;using 8-tap MMX scaler for horizontal luminance scaling\n&quot;);
-                else
-                    av_log(c, AV_LOG_VERBOSE, &quot;using n-tap MMX scaler for horizontal luminance scaling\n&quot;);
-
-                if (c-&gt;hChrFilterSize==4)
-                    av_log(c, AV_LOG_VERBOSE, &quot;using 4-tap MMX scaler for horizontal chrominance scaling\n&quot;);
-                else if (c-&gt;hChrFilterSize==8)
-                    av_log(c, AV_LOG_VERBOSE, &quot;using 8-tap MMX scaler for horizontal chrominance scaling\n&quot;);
-                else
-                    av_log(c, AV_LOG_VERBOSE, &quot;using n-tap MMX scaler for horizontal chrominance scaling\n&quot;);
-            }
-        } else {
-#if ARCH_X86
-            av_log(c, AV_LOG_VERBOSE, &quot;using x86 asm scaler for horizontal scaling\n&quot;);
-#else
-            if (flags &amp; SWS_FAST_BILINEAR)
-                av_log(c, AV_LOG_VERBOSE, &quot;using FAST_BILINEAR C scaler for horizontal scaling\n&quot;);
-            else
-                av_log(c, AV_LOG_VERBOSE, &quot;using C scaler for horizontal scaling\n&quot;);
-#endif
-        }
-        if (isPlanarYUV(dstFormat)) {
-            if (c-&gt;vLumFilterSize==1)
-                av_log(c, AV_LOG_VERBOSE, &quot;using 1-tap %s \&quot;scaler\&quot; for vertical scaling (YV12 like)\n&quot;, (flags &amp; SWS_CPU_CAPS_MMX) ? &quot;MMX&quot; : &quot;C&quot;);
-            else
-                av_log(c, AV_LOG_VERBOSE, &quot;using n-tap %s scaler for vertical scaling (YV12 like)\n&quot;, (flags &amp; SWS_CPU_CAPS_MMX) ? &quot;MMX&quot; : &quot;C&quot;);
-        } else {
-            if (c-&gt;vLumFilterSize==1 &amp;&amp; c-&gt;vChrFilterSize==2)
-                av_log(c, AV_LOG_VERBOSE, &quot;using 1-tap %s \&quot;scaler\&quot; for vertical luminance scaling (BGR)\n&quot;
-                       &quot;      2-tap scaler for vertical chrominance scaling (BGR)\n&quot;, (flags &amp; SWS_CPU_CAPS_MMX) ? &quot;MMX&quot; : &quot;C&quot;);
-            else if (c-&gt;vLumFilterSize==2 &amp;&amp; c-&gt;vChrFilterSize==2)
-                av_log(c, AV_LOG_VERBOSE, &quot;using 2-tap linear %s scaler for vertical scaling (BGR)\n&quot;, (flags &amp; SWS_CPU_CAPS_MMX) ? &quot;MMX&quot; : &quot;C&quot;);
-            else
-                av_log(c, AV_LOG_VERBOSE, &quot;using n-tap %s scaler for vertical scaling (BGR)\n&quot;, (flags &amp; SWS_CPU_CAPS_MMX) ? &quot;MMX&quot; : &quot;C&quot;);
-        }
-
-        if (dstFormat==PIX_FMT_BGR24)
-            av_log(c, AV_LOG_VERBOSE, &quot;using %s YV12-&gt;BGR24 converter\n&quot;,
-                   (flags &amp; SWS_CPU_CAPS_MMX2) ? &quot;MMX2&quot; : ((flags &amp; SWS_CPU_CAPS_MMX) ? &quot;MMX&quot; : &quot;C&quot;));
-        else if (dstFormat==PIX_FMT_RGB32)
-            av_log(c, AV_LOG_VERBOSE, &quot;using %s YV12-&gt;BGR32 converter\n&quot;, (flags &amp; SWS_CPU_CAPS_MMX) ? &quot;MMX&quot; : &quot;C&quot;);
-        else if (dstFormat==PIX_FMT_BGR565)
-            av_log(c, AV_LOG_VERBOSE, &quot;using %s YV12-&gt;BGR16 converter\n&quot;, (flags &amp; SWS_CPU_CAPS_MMX) ? &quot;MMX&quot; : &quot;C&quot;);
-        else if (dstFormat==PIX_FMT_BGR555)
-            av_log(c, AV_LOG_VERBOSE, &quot;using %s YV12-&gt;BGR15 converter\n&quot;, (flags &amp; SWS_CPU_CAPS_MMX) ? &quot;MMX&quot; : &quot;C&quot;);
-
-        av_log(c, AV_LOG_VERBOSE, &quot;%dx%d -&gt; %dx%d\n&quot;, srcW, srcH, dstW, dstH);
-    }
-    if (flags &amp; SWS_PRINT_INFO) {
-        av_log(c, AV_LOG_DEBUG, &quot;lum srcW=%d srcH=%d dstW=%d dstH=%d xInc=%d yInc=%d\n&quot;,
-               c-&gt;srcW, c-&gt;srcH, c-&gt;dstW, c-&gt;dstH, c-&gt;lumXInc, c-&gt;lumYInc);
-        av_log(c, AV_LOG_DEBUG, &quot;chr srcW=%d srcH=%d dstW=%d dstH=%d xInc=%d yInc=%d\n&quot;,
-               c-&gt;chrSrcW, c-&gt;chrSrcH, c-&gt;chrDstW, c-&gt;chrDstH, c-&gt;chrXInc, c-&gt;chrYInc);
-    }
-
-    c-&gt;swScale= getSwsFunc(c);
-    return c;
 }
 
-static void reset_ptr(uint8_t* src[], int format)
+static void reset_ptr(const uint8_t* src[], int format)
 {
     if(!isALPHA(format))
         src[3]=NULL;
     if(!isPlanarYUV(format)) {
         src[3]=src[2]=NULL;
-        if(   format != PIX_FMT_PAL8
-           &amp;&amp; format != PIX_FMT_RGB8
-           &amp;&amp; format != PIX_FMT_BGR8
-           &amp;&amp; format != PIX_FMT_RGB4_BYTE
-           &amp;&amp; format != PIX_FMT_BGR4_BYTE
-          )
+
+        if (!usePal(format))
             src[1]= NULL;
     }
 }
@@ -3066,13 +1810,17 @@
  * swscale wrapper, so we don't need to export the SwsContext.
  * Assumes planar YUV to be in YUV order instead of YVU.
  */
-int sws_scale(SwsContext *c, uint8_t* src[], int srcStride[], int srcSliceY,
-              int srcSliceH, uint8_t* dst[], int dstStride[])
+int sws_scale(SwsContext *c, const uint8_t* const src[], const int srcStride[], int srcSliceY,
+              int srcSliceH, uint8_t* const dst[], const int dstStride[])
 {
     int i;
-    uint8_t* src2[4]= {src[0], src[1], src[2], src[3]};
+    const uint8_t* src2[4]= {src[0], src[1], src[2], src[3]};
     uint8_t* dst2[4]= {dst[0], dst[1], dst[2], dst[3]};
 
+    // do not mess up sliceDir if we have a &quot;trailing&quot; 0-size slice
+    if (srcSliceH == 0)
+        return 0;
+
     if (c-&gt;sliceDir == 0 &amp;&amp; srcSliceY != 0 &amp;&amp; srcSliceY + srcSliceH != c-&gt;srcH) {
         av_log(c, AV_LOG_ERROR, &quot;Slices start in the middle!\n&quot;);
         return 0;
@@ -3085,7 +1833,7 @@
         for (i=0; i&lt;256; i++) {
             int p, r, g, b,y,u,v;
             if(c-&gt;srcFormat == PIX_FMT_PAL8) {
-                p=((uint32_t*)(src[1]))[i];
+                p=((const uint32_t*)(src[1]))[i];
                 r= (p&gt;&gt;16)&amp;0xFF;
                 g= (p&gt;&gt; 8)&amp;0xFF;
                 b=  p     &amp;0xFF;
@@ -3112,7 +1860,6 @@
             v= av_clip_uint8((RV*r + GV*g + BV*b + (257&lt;&lt;(RGB2YUV_SHIFT-1)))&gt;&gt;RGB2YUV_SHIFT);
             c-&gt;pal_yuv[i]= y + (u&lt;&lt;8) + (v&lt;&lt;16);
 
-
             switch(c-&gt;dstFormat) {
             case PIX_FMT_BGR32:
 #if !HAVE_BIGENDIAN
@@ -3149,8 +1896,12 @@
         int dstStride2[4]= {dstStride[0], dstStride[1], dstStride[2], dstStride[3]};
 
         reset_ptr(src2, c-&gt;srcFormat);
-        reset_ptr(dst2, c-&gt;dstFormat);
+        reset_ptr((const uint8_t**)dst2, c-&gt;dstFormat);
 
+        /* reset slice direction at end of frame */
+        if (srcSliceY + srcSliceH == c-&gt;srcH)
+            c-&gt;sliceDir = 0;
+
         return c-&gt;swScale(c, src2, srcStride2, srcSliceY, srcSliceH, dst2, dstStride2);
     } else {
         // slices go from bottom to top =&gt; we flip the image internally
@@ -3168,405 +1919,20 @@
         dst2[3] += ( c-&gt;dstH                      -1)*dstStride[3];
 
         reset_ptr(src2, c-&gt;srcFormat);
-        reset_ptr(dst2, c-&gt;dstFormat);
+        reset_ptr((const uint8_t**)dst2, c-&gt;dstFormat);
 
+        /* reset slice direction at end of frame */
+        if (!srcSliceY)
+            c-&gt;sliceDir = 0;
+
         return c-&gt;swScale(c, src2, srcStride2, c-&gt;srcH-srcSliceY-srcSliceH, srcSliceH, dst2, dstStride2);
     }
 }
 
 #if LIBSWSCALE_VERSION_MAJOR &lt; 1
-int sws_scale_ordered(SwsContext *c, uint8_t* src[], int srcStride[], int srcSliceY,
+int sws_scale_ordered(SwsContext *c, const uint8_t* const src[], int srcStride[], int srcSliceY,
                       int srcSliceH, uint8_t* dst[], int dstStride[])
 {
     return sws_scale(c, src, srcStride, srcSliceY, srcSliceH, dst, dstStride);
 }
 #endif
-
-SwsFilter *sws_getDefaultFilter(float lumaGBlur, float chromaGBlur,
-                                float lumaSharpen, float chromaSharpen,
-                                float chromaHShift, float chromaVShift,
-                                int verbose)
-{
-    SwsFilter *filter= av_malloc(sizeof(SwsFilter));
-
-    if (lumaGBlur!=0.0) {
-        filter-&gt;lumH= sws_getGaussianVec(lumaGBlur, 3.0);
-        filter-&gt;lumV= sws_getGaussianVec(lumaGBlur, 3.0);
-    } else {
-        filter-&gt;lumH= sws_getIdentityVec();
-        filter-&gt;lumV= sws_getIdentityVec();
-    }
-
-    if (chromaGBlur!=0.0) {
-        filter-&gt;chrH= sws_getGaussianVec(chromaGBlur, 3.0);
-        filter-&gt;chrV= sws_getGaussianVec(chromaGBlur, 3.0);
-    } else {
-        filter-&gt;chrH= sws_getIdentityVec();
-        filter-&gt;chrV= sws_getIdentityVec();
-    }
-
-    if (chromaSharpen!=0.0) {
-        SwsVector *id= sws_getIdentityVec();
-        sws_scaleVec(filter-&gt;chrH, -chromaSharpen);
-        sws_scaleVec(filter-&gt;chrV, -chromaSharpen);
-        sws_addVec(filter-&gt;chrH, id);
-        sws_addVec(filter-&gt;chrV, id);
-        sws_freeVec(id);
-    }
-
-    if (lumaSharpen!=0.0) {
-        SwsVector *id= sws_getIdentityVec();
-        sws_scaleVec(filter-&gt;lumH, -lumaSharpen);
-        sws_scaleVec(filter-&gt;lumV, -lumaSharpen);
-        sws_addVec(filter-&gt;lumH, id);
-        sws_addVec(filter-&gt;lumV, id);
-        sws_freeVec(id);
-    }
-
-    if (chromaHShift != 0.0)
-        sws_shiftVec(filter-&gt;chrH, (int)(chromaHShift+0.5));
-
-    if (chromaVShift != 0.0)
-        sws_shiftVec(filter-&gt;chrV, (int)(chromaVShift+0.5));
-
-    sws_normalizeVec(filter-&gt;chrH, 1.0);
-    sws_normalizeVec(filter-&gt;chrV, 1.0);
-    sws_normalizeVec(filter-&gt;lumH, 1.0);
-    sws_normalizeVec(filter-&gt;lumV, 1.0);
-
-    if (verbose) sws_printVec2(filter-&gt;chrH, NULL, AV_LOG_DEBUG);
-    if (verbose) sws_printVec2(filter-&gt;lumH, NULL, AV_LOG_DEBUG);
-
-    return filter;
-}
-
-SwsVector *sws_allocVec(int length)
-{
-    SwsVector *vec = av_malloc(sizeof(SwsVector));
-    if (!vec)
-        return NULL;
-    vec-&gt;length = length;
-    vec-&gt;coeff  = av_malloc(sizeof(double) * length);
-    if (!vec-&gt;coeff)
-        av_freep(&amp;vec);
-    return vec;
-}
-
-SwsVector *sws_getGaussianVec(double variance, double quality)
-{
-    const int length= (int)(variance*quality + 0.5) | 1;
-    int i;
-    double middle= (length-1)*0.5;
-    SwsVector *vec= sws_allocVec(length);
-
-    if (!vec)
-        return NULL;
-
-    for (i=0; i&lt;length; i++) {
-        double dist= i-middle;
-        vec-&gt;coeff[i]= exp(-dist*dist/(2*variance*variance)) / sqrt(2*variance*PI);
-    }
-
-    sws_normalizeVec(vec, 1.0);
-
-    return vec;
-}
-
-SwsVector *sws_getConstVec(double c, int length)
-{
-    int i;
-    SwsVector *vec= sws_allocVec(length);
-
-    if (!vec)
-        return NULL;
-
-    for (i=0; i&lt;length; i++)
-        vec-&gt;coeff[i]= c;
-
-    return vec;
-}
-
-
-SwsVector *sws_getIdentityVec(void)
-{
-    return sws_getConstVec(1.0, 1);
-}
-
-double sws_dcVec(SwsVector *a)
-{
-    int i;
-    double sum=0;
-
-    for (i=0; i&lt;a-&gt;length; i++)
-        sum+= a-&gt;coeff[i];
-
-    return sum;
-}
-
-void sws_scaleVec(SwsVector *a, double scalar)
-{
-    int i;
-
-    for (i=0; i&lt;a-&gt;length; i++)
-        a-&gt;coeff[i]*= scalar;
-}
-
-void sws_normalizeVec(SwsVector *a, double height)
-{
-    sws_scaleVec(a, height/sws_dcVec(a));
-}
-
-static SwsVector *sws_getConvVec(SwsVector *a, SwsVector *b)
-{
-    int length= a-&gt;length + b-&gt;length - 1;
-    int i, j;
-    SwsVector *vec= sws_getConstVec(0.0, length);
-
-    if (!vec)
-        return NULL;
-
-    for (i=0; i&lt;a-&gt;length; i++) {
-        for (j=0; j&lt;b-&gt;length; j++) {
-            vec-&gt;coeff[i+j]+= a-&gt;coeff[i]*b-&gt;coeff[j];
-        }
-    }
-
-    return vec;
-}
-
-static SwsVector *sws_sumVec(SwsVector *a, SwsVector *b)
-{
-    int length= FFMAX(a-&gt;length, b-&gt;length);
-    int i;
-    SwsVector *vec= sws_getConstVec(0.0, length);
-
-    if (!vec)
-        return NULL;
-
-    for (i=0; i&lt;a-&gt;length; i++) vec-&gt;coeff[i + (length-1)/2 - (a-&gt;length-1)/2]+= a-&gt;coeff[i];
-    for (i=0; i&lt;b-&gt;length; i++) vec-&gt;coeff[i + (length-1)/2 - (b-&gt;length-1)/2]+= b-&gt;coeff[i];
-
-    return vec;
-}
-
-static SwsVector *sws_diffVec(SwsVector *a, SwsVector *b)
-{
-    int length= FFMAX(a-&gt;length, b-&gt;length);
-    int i;
-    SwsVector *vec= sws_getConstVec(0.0, length);
-
-    if (!vec)
-        return NULL;
-
-    for (i=0; i&lt;a-&gt;length; i++) vec-&gt;coeff[i + (length-1)/2 - (a-&gt;length-1)/2]+= a-&gt;coeff[i];
-    for (i=0; i&lt;b-&gt;length; i++) vec-&gt;coeff[i + (length-1)/2 - (b-&gt;length-1)/2]-= b-&gt;coeff[i];
-
-    return vec;
-}
-
-/* shift left / or right if &quot;shift&quot; is negative */
-static SwsVector *sws_getShiftedVec(SwsVector *a, int shift)
-{
-    int length= a-&gt;length + FFABS(shift)*2;
-    int i;
-    SwsVector *vec= sws_getConstVec(0.0, length);
-
-    if (!vec)
-        return NULL;
-
-    for (i=0; i&lt;a-&gt;length; i++) {
-        vec-&gt;coeff[i + (length-1)/2 - (a-&gt;length-1)/2 - shift]= a-&gt;coeff[i];
-    }
-
-    return vec;
-}
-
-void sws_shiftVec(SwsVector *a, int shift)
-{
-    SwsVector *shifted= sws_getShiftedVec(a, shift);
-    av_free(a-&gt;coeff);
-    a-&gt;coeff= shifted-&gt;coeff;
-    a-&gt;length= shifted-&gt;length;
-    av_free(shifted);
-}
-
-void sws_addVec(SwsVector *a, SwsVector *b)
-{
-    SwsVector *sum= sws_sumVec(a, b);
-    av_free(a-&gt;coeff);
-    a-&gt;coeff= sum-&gt;coeff;
-    a-&gt;length= sum-&gt;length;
-    av_free(sum);
-}
-
-void sws_subVec(SwsVector *a, SwsVector *b)
-{
-    SwsVector *diff= sws_diffVec(a, b);
-    av_free(a-&gt;coeff);
-    a-&gt;coeff= diff-&gt;coeff;
-    a-&gt;length= diff-&gt;length;
-    av_free(diff);
-}
-
-void sws_convVec(SwsVector *a, SwsVector *b)
-{
-    SwsVector *conv= sws_getConvVec(a, b);
-    av_free(a-&gt;coeff);
-    a-&gt;coeff= conv-&gt;coeff;
-    a-&gt;length= conv-&gt;length;
-    av_free(conv);
-}
-
-SwsVector *sws_cloneVec(SwsVector *a)
-{
-    int i;
-    SwsVector *vec= sws_allocVec(a-&gt;length);
-
-    if (!vec)
-        return NULL;
-
-    for (i=0; i&lt;a-&gt;length; i++) vec-&gt;coeff[i]= a-&gt;coeff[i];
-
-    return vec;
-}
-
-void sws_printVec2(SwsVector *a, AVClass *log_ctx, int log_level)
-{
-    int i;
-    double max=0;
-    double min=0;
-    double range;
-
-    for (i=0; i&lt;a-&gt;length; i++)
-        if (a-&gt;coeff[i]&gt;max) max= a-&gt;coeff[i];
-
-    for (i=0; i&lt;a-&gt;length; i++)
-        if (a-&gt;coeff[i]&lt;min) min= a-&gt;coeff[i];
-
-    range= max - min;
-
-    for (i=0; i&lt;a-&gt;length; i++) {
-        int x= (int)((a-&gt;coeff[i]-min)*60.0/range +0.5);
-        av_log(log_ctx, log_level, &quot;%1.3f &quot;, a-&gt;coeff[i]);
-        for (;x&gt;0; x--) av_log(log_ctx, log_level, &quot; &quot;);
-        av_log(log_ctx, log_level, &quot;|\n&quot;);
-    }
-}
-
-#if LIBSWSCALE_VERSION_MAJOR &lt; 1
-void sws_printVec(SwsVector *a)
-{
-    sws_printVec2(a, NULL, AV_LOG_DEBUG);
-}
-#endif
-
-void sws_freeVec(SwsVector *a)
-{
-    if (!a) return;
-    av_freep(&amp;a-&gt;coeff);
-    a-&gt;length=0;
-    av_free(a);
-}
-
-void sws_freeFilter(SwsFilter *filter)
-{
-    if (!filter) return;
-
-    if (filter-&gt;lumH) sws_freeVec(filter-&gt;lumH);
-    if (filter-&gt;lumV) sws_freeVec(filter-&gt;lumV);
-    if (filter-&gt;chrH) sws_freeVec(filter-&gt;chrH);
-    if (filter-&gt;chrV) sws_freeVec(filter-&gt;chrV);
-    av_free(filter);
-}
-
-
-void sws_freeContext(SwsContext *c)
-{
-    int i;
-    if (!c) return;
-
-    if (c-&gt;lumPixBuf) {
-        for (i=0; i&lt;c-&gt;vLumBufSize; i++)
-            av_freep(&amp;c-&gt;lumPixBuf[i]);
-        av_freep(&amp;c-&gt;lumPixBuf);
-    }
-
-    if (c-&gt;chrPixBuf) {
-        for (i=0; i&lt;c-&gt;vChrBufSize; i++)
-            av_freep(&amp;c-&gt;chrPixBuf[i]);
-        av_freep(&amp;c-&gt;chrPixBuf);
-    }
-
-    if (CONFIG_SWSCALE_ALPHA &amp;&amp; c-&gt;alpPixBuf) {
-        for (i=0; i&lt;c-&gt;vLumBufSize; i++)
-            av_freep(&amp;c-&gt;alpPixBuf[i]);
-        av_freep(&amp;c-&gt;alpPixBuf);
-    }
-
-    av_freep(&amp;c-&gt;vLumFilter);
-    av_freep(&amp;c-&gt;vChrFilter);
-    av_freep(&amp;c-&gt;hLumFilter);
-    av_freep(&amp;c-&gt;hChrFilter);
-#ifdef COMPILE_ALTIVEC
-    av_freep(&amp;c-&gt;vYCoeffsBank);
-    av_freep(&amp;c-&gt;vCCoeffsBank);
-#endif
-
-    av_freep(&amp;c-&gt;vLumFilterPos);
-    av_freep(&amp;c-&gt;vChrFilterPos);
-    av_freep(&amp;c-&gt;hLumFilterPos);
-    av_freep(&amp;c-&gt;hChrFilterPos);
-
-#if ARCH_X86 &amp;&amp; CONFIG_GPL
-#ifdef MAP_ANONYMOUS
-    if (c-&gt;lumMmx2FilterCode) munmap(c-&gt;lumMmx2FilterCode, c-&gt;lumMmx2FilterCodeSize);
-    if (c-&gt;chrMmx2FilterCode) munmap(c-&gt;chrMmx2FilterCode, c-&gt;chrMmx2FilterCodeSize);
-#elif HAVE_VIRTUALALLOC
-    if (c-&gt;lumMmx2FilterCode) VirtualFree(c-&gt;lumMmx2FilterCode, c-&gt;lumMmx2FilterCodeSize, MEM_RELEASE);
-    if (c-&gt;chrMmx2FilterCode) VirtualFree(c-&gt;chrMmx2FilterCode, c-&gt;chrMmx2FilterCodeSize, MEM_RELEASE);
-#else
-    av_free(c-&gt;lumMmx2FilterCode);
-    av_free(c-&gt;chrMmx2FilterCode);
-#endif
-    c-&gt;lumMmx2FilterCode=NULL;
-    c-&gt;chrMmx2FilterCode=NULL;
-#endif /* ARCH_X86 &amp;&amp; CONFIG_GPL */
-
-    av_freep(&amp;c-&gt;lumMmx2Filter);
-    av_freep(&amp;c-&gt;chrMmx2Filter);
-    av_freep(&amp;c-&gt;lumMmx2FilterPos);
-    av_freep(&amp;c-&gt;chrMmx2FilterPos);
-    av_freep(&amp;c-&gt;yuvTable);
-
-    av_free(c);
-}
-
-struct SwsContext *sws_getCachedContext(struct SwsContext *context,
-                                        int srcW, int srcH, enum PixelFormat srcFormat,
-                                        int dstW, int dstH, enum PixelFormat dstFormat, int flags,
-                                        SwsFilter *srcFilter, SwsFilter *dstFilter, const double *param)
-{
-    static const double default_param[2] = {SWS_PARAM_DEFAULT, SWS_PARAM_DEFAULT};
-
-    if (!param)
-        param = default_param;
-
-    if (context) {
-        if (context-&gt;srcW != srcW || context-&gt;srcH != srcH ||
-            context-&gt;srcFormat != srcFormat ||
-            context-&gt;dstW != dstW || context-&gt;dstH != dstH ||
-            context-&gt;dstFormat != dstFormat || context-&gt;flags != flags ||
-            context-&gt;param[0] != param[0] || context-&gt;param[1] != param[1])
-        {
-            sws_freeContext(context);
-            context = NULL;
-        }
-    }
-    if (!context) {
-        return sws_getContext(srcW, srcH, srcFormat,
-                              dstW, dstH, dstFormat, flags,
-                              srcFilter, dstFilter, param);
-    }
-    return context;
-}
-

Modified: branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/swscale.h
===================================================================
--- branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/swscale.h	2010-05-26 05:26:42 UTC (rev 6237)
+++ branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/swscale.h	2010-05-26 05:26:46 UTC (rev 6238)
@@ -30,8 +30,8 @@
 #include &quot;libavutil/avutil.h&quot;
 
 #define LIBSWSCALE_VERSION_MAJOR 0
-#define LIBSWSCALE_VERSION_MINOR 7
-#define LIBSWSCALE_VERSION_MICRO 1
+#define LIBSWSCALE_VERSION_MINOR 10
+#define LIBSWSCALE_VERSION_MICRO 0
 
 #define LIBSWSCALE_VERSION_INT  AV_VERSION_INT(LIBSWSCALE_VERSION_MAJOR, \
                                                LIBSWSCALE_VERSION_MINOR, \
@@ -48,6 +48,16 @@
  */
 unsigned swscale_version(void);
 
+/**
+ * Returns the libswscale build-time configuration.
+ */
+const char *swscale_configuration(void);
+
+/**
+ * Returns the libswscale license.
+ */
+const char *swscale_license(void);
+
 /* values for the flags, the stuff on the command line is different */
 #define SWS_FAST_BILINEAR     1
 #define SWS_BILINEAR          2
@@ -93,6 +103,14 @@
 #define SWS_CS_SMPTE240M      7
 #define SWS_CS_DEFAULT        5
 
+/**
+ * Returns a pointer to yuv&lt;-&gt;rgb coefficients for the given colorspace
+ * suitable for sws_setColorspaceDetails().
+ *
+ * @param colorspace One of the SWS_CS_* macros. If invalid,
+ * SWS_CS_DEFAULT is used.
+ */
+const int *sws_getCoefficients(int colorspace);
 
 
 // when used for filters they must have an odd number of elements
@@ -112,6 +130,22 @@
 
 struct SwsContext;
 
+/**
+ * Returns a positive value if pix_fmt is a supported input format, 0
+ * otherwise.
+ */
+int sws_isSupportedInput(enum PixelFormat pix_fmt);
+
+/**
+ * Returns a positive value if pix_fmt is a supported output format, 0
+ * otherwise.
+ */
+int sws_isSupportedOutput(enum PixelFormat pix_fmt);
+
+/**
+ * Frees the swscaler context swsContext.
+ * If swsContext is NULL, then does nothing.
+ */
 void sws_freeContext(struct SwsContext *swsContext);
 
 /**
@@ -137,6 +171,10 @@
  * slice in the image in dst. A slice is a sequence of consecutive
  * rows in an image.
  *
+ * Slices have to be provided in sequential order, either in
+ * top-bottom or bottom-top order. If slices are provided in
+ * non-sequential order the behavior of the function is undefined.
+ *
  * @param context   the scaling context previously created with
  *                  sws_getContext()
  * @param srcSlice  the array containing the pointers to the planes of
@@ -154,13 +192,13 @@
  *                  the destination image
  * @return          the height of the output slice
  */
-int sws_scale(struct SwsContext *context, uint8_t* srcSlice[], int srcStride[],
-              int srcSliceY, int srcSliceH, uint8_t* dst[], int dstStride[]);
+int sws_scale(struct SwsContext *context, const uint8_t* const srcSlice[], const int srcStride[],
+              int srcSliceY, int srcSliceH, uint8_t* const dst[], const int dstStride[]);
 #if LIBSWSCALE_VERSION_MAJOR &lt; 1
 /**
  * @deprecated Use sws_scale() instead.
  */
-int sws_scale_ordered(struct SwsContext *context, uint8_t* src[],
+int sws_scale_ordered(struct SwsContext *context, const uint8_t* const src[],
                       int srcStride[], int srcSliceY, int srcSliceH,
                       uint8_t* dst[], int dstStride[]) attribute_deprecated;
 #endif

Modified: branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/swscale_internal.h
===================================================================
--- branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/swscale_internal.h	2010-05-26 05:26:42 UTC (rev 6237)
+++ branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/swscale_internal.h	2010-05-26 05:26:46 UTC (rev 6238)
@@ -59,7 +59,7 @@
 
 struct SwsContext;
 
-typedef int (*SwsFunc)(struct SwsContext *context, uint8_t* src[],
+typedef int (*SwsFunc)(struct SwsContext *context, const uint8_t* src[],
                        int srcStride[], int srcSliceY, int srcSliceH,
                        uint8_t* dst[], int dstStride[]);
 
@@ -75,59 +75,90 @@
      * sws_scale() wrapper so they can be freely modified here.
      */
     SwsFunc swScale;
-    int srcW, srcH, dstH;
-    int chrSrcW, chrSrcH, chrDstW, chrDstH;
+    int srcW;                     ///&lt; Width  of source      luma/alpha planes.
+    int srcH;                     ///&lt; Height of source      luma/alpha planes.
+    int dstH;                     ///&lt; Height of destination luma/alpha planes.
+    int chrSrcW;                  ///&lt; Width  of source      chroma     planes.
+    int chrSrcH;                  ///&lt; Height of source      chroma     planes.
+    int chrDstW;                  ///&lt; Width  of destination chroma     planes.
+    int chrDstH;                  ///&lt; Height of destination chroma     planes.
     int lumXInc, chrXInc;
     int lumYInc, chrYInc;
-    enum PixelFormat dstFormat, srcFormat;  ///&lt; format 4:2:0 type is always YV12
-    int origDstFormat, origSrcFormat;       ///&lt; format
-    int chrSrcHSubSample, chrSrcVSubSample;
-    int chrDstHSubSample, chrDstVSubSample;
-    int vChrDrop;
-    int sliceDir;
-    double param[2];
+    enum PixelFormat dstFormat;   ///&lt; Destination pixel format.
+    enum PixelFormat srcFormat;   ///&lt; Source      pixel format.
+    int dstFormatBpp;             ///&lt; Number of bits per pixel of the destination pixel format.
+    int srcFormatBpp;             ///&lt; Number of bits per pixel of the source      pixel format.
+    int chrSrcHSubSample;         ///&lt; Binary logarithm of horizontal subsampling factor between luma/alpha and chroma planes in source      image.
+    int chrSrcVSubSample;         ///&lt; Binary logarithm of vertical   subsampling factor between luma/alpha and chroma planes in source      image.
+    int chrDstHSubSample;         ///&lt; Binary logarithm of horizontal subsampling factor between luma/alpha and chroma planes in destination image.
+    int chrDstVSubSample;         ///&lt; Binary logarithm of vertical   subsampling factor between luma/alpha and chroma planes in destination image.
+    int vChrDrop;                 ///&lt; Binary logarithm of extra vertical subsampling factor in source image chroma planes specified by user.
+    int sliceDir;                 ///&lt; Direction that slices are fed to the scaler (1 = top-to-bottom, -1 = bottom-to-top).
+    double param[2];              ///&lt; Input parameters for scaling algorithms that need them.
 
     uint32_t pal_yuv[256];
     uint32_t pal_rgb[256];
 
-    int16_t **lumPixBuf;
-    int16_t **chrPixBuf;
-    int16_t **alpPixBuf;
-    int16_t *hLumFilter;
-    int16_t *hLumFilterPos;
-    int16_t *hChrFilter;
-    int16_t *hChrFilterPos;
-    int16_t *vLumFilter;
-    int16_t *vLumFilterPos;
-    int16_t *vChrFilter;
-    int16_t *vChrFilterPos;
+    /**
+     * @name Scaled horizontal lines ring buffer.
+     * The horizontal scaler keeps just enough scaled lines in a ring buffer
+     * so they may be passed to the vertical scaler. The pointers to the
+     * allocated buffers for each line are duplicated in sequence in the ring
+     * buffer to simplify indexing and avoid wrapping around between lines
+     * inside the vertical scaler code. The wrapping is done before the
+     * vertical scaler is called.
+     */
+    //@{
+    int16_t **lumPixBuf;          ///&lt; Ring buffer for scaled horizontal luma   plane lines to be fed to the vertical scaler.
+    int16_t **chrPixBuf;          ///&lt; Ring buffer for scaled horizontal chroma plane lines to be fed to the vertical scaler.
+    int16_t **alpPixBuf;          ///&lt; Ring buffer for scaled horizontal alpha  plane lines to be fed to the vertical scaler.
+    int       vLumBufSize;        ///&lt; Number of vertical luma/alpha lines allocated in the ring buffer.
+    int       vChrBufSize;        ///&lt; Number of vertical chroma     lines allocated in the ring buffer.
+    int       lastInLumBuf;       ///&lt; Last scaled horizontal luma/alpha line from source in the ring buffer.
+    int       lastInChrBuf;       ///&lt; Last scaled horizontal chroma     line from source in the ring buffer.
+    int       lumBufIndex;        ///&lt; Index in ring buffer of the last scaled horizontal luma/alpha line from source.
+    int       chrBufIndex;        ///&lt; Index in ring buffer of the last scaled horizontal chroma     line from source.
+    //@}
 
     uint8_t formatConvBuffer[VOF]; //FIXME dynamic allocation, but we have to change a lot of code for this to be useful
 
-    int hLumFilterSize;
-    int hChrFilterSize;
-    int vLumFilterSize;
-    int vChrFilterSize;
-    int vLumBufSize;
-    int vChrBufSize;
+    /**
+     * @name Horizontal and vertical filters.
+     * To better understand the following fields, here is a pseudo-code of
+     * their usage in filtering a horizontal line:
+     * @code
+     * for (i = 0; i &lt; width; i++) {
+     *     dst[i] = 0;
+     *     for (j = 0; j &lt; filterSize; j++)
+     *         dst[i] += src[ filterPos[i] + j ] * filter[ filterSize * i + j ];
+     *     dst[i] &gt;&gt;= FRAC_BITS; // The actual implementation is fixed-point.
+     * }
+     * @endcode
+     */
+    //@{
+    int16_t *hLumFilter;          ///&lt; Array of horizontal filter coefficients for luma/alpha planes.
+    int16_t *hChrFilter;          ///&lt; Array of horizontal filter coefficients for chroma     planes.
+    int16_t *vLumFilter;          ///&lt; Array of vertical   filter coefficients for luma/alpha planes.
+    int16_t *vChrFilter;          ///&lt; Array of vertical   filter coefficients for chroma     planes.
+    int16_t *hLumFilterPos;       ///&lt; Array of horizontal filter starting positions for each dst[i] for luma/alpha planes.
+    int16_t *hChrFilterPos;       ///&lt; Array of horizontal filter starting positions for each dst[i] for chroma     planes.
+    int16_t *vLumFilterPos;       ///&lt; Array of vertical   filter starting positions for each dst[i] for luma/alpha planes.
+    int16_t *vChrFilterPos;       ///&lt; Array of vertical   filter starting positions for each dst[i] for chroma     planes.
+    int      hLumFilterSize;      ///&lt; Horizontal filter size for luma/alpha pixels.
+    int      hChrFilterSize;      ///&lt; Horizontal filter size for chroma     pixels.
+    int      vLumFilterSize;      ///&lt; Vertical   filter size for luma/alpha pixels.
+    int      vChrFilterSize;      ///&lt; Vertical   filter size for chroma     pixels.
+    //@}
 
-    int lumMmx2FilterCodeSize;
-    int chrMmx2FilterCodeSize;
-    uint8_t *lumMmx2FilterCode;
-    uint8_t *chrMmx2FilterCode;
-    int32_t *lumMmx2FilterPos;
-    int32_t *chrMmx2FilterPos;
-    int16_t *lumMmx2Filter;
-    int16_t *chrMmx2Filter;
+    int lumMmx2FilterCodeSize;    ///&lt; Runtime-generated MMX2 horizontal fast bilinear scaler code size for luma/alpha planes.
+    int chrMmx2FilterCodeSize;    ///&lt; Runtime-generated MMX2 horizontal fast bilinear scaler code size for chroma     planes.
+    uint8_t *lumMmx2FilterCode;   ///&lt; Runtime-generated MMX2 horizontal fast bilinear scaler code for luma/alpha planes.
+    uint8_t *chrMmx2FilterCode;   ///&lt; Runtime-generated MMX2 horizontal fast bilinear scaler code for chroma     planes.
 
     int canMMX2BeUsed;
 
-    int lastInLumBuf;
-    int lastInChrBuf;
-    int lumBufIndex;
-    int chrBufIndex;
-    int dstY;
-    int flags;
+    int dstY;                     ///&lt; Last destination vertical line output from last slice.
+    int flags;                    ///&lt; Flags passed by the user to select scaler algorithm, optimizations, subsampling, etc...
     void * yuvTable;            // pointer to the yuv-&gt;rgb table start so it can be freed()
     uint8_t * table_rV[256];
     uint8_t * table_gU[256];
@@ -138,7 +169,8 @@
     int contrast, brightness, saturation;    // for sws_getColorspaceDetails
     int srcColorspaceTable[4];
     int dstColorspaceTable[4];
-    int srcRange, dstRange;
+    int srcRange;                 ///&lt; 0 = MPG YUV range, 1 = JPG YUV range (source      image).
+    int dstRange;                 ///&lt; 0 = MPG YUV range, 1 = JPG YUV range (destination image).
     int yuv2rgb_y_offset;
     int yuv2rgb_y_coeff;
     int yuv2rgb_v2r_coeff;
@@ -181,7 +213,7 @@
     DECLARE_ALIGNED(8, uint64_t, vOffset);
     int32_t  lumMmxFilter[4*MAX_FILTER_SIZE];
     int32_t  chrMmxFilter[4*MAX_FILTER_SIZE];
-    int dstW;
+    int dstW;                     ///&lt; Width  of destination luma/alpha planes.
     DECLARE_ALIGNED(8, uint64_t, esp);
     DECLARE_ALIGNED(8, uint64_t, vRounder);
     DECLARE_ALIGNED(8, uint64_t, u_temp);
@@ -190,14 +222,14 @@
     int32_t  alpMmxFilter[4*MAX_FILTER_SIZE];
 
 #if HAVE_ALTIVEC
-  vector signed short   CY;
-  vector signed short   CRV;
-  vector signed short   CBU;
-  vector signed short   CGU;
-  vector signed short   CGV;
-  vector signed short   OY;
-  vector unsigned short CSHIFT;
-  vector signed short   *vYCoeffsBank, *vCCoeffsBank;
+    vector signed short   CY;
+    vector signed short   CRV;
+    vector signed short   CBU;
+    vector signed short   CGU;
+    vector signed short   CGV;
+    vector signed short   OY;
+    vector unsigned short CSHIFT;
+    vector signed short   *vYCoeffsBank, *vCCoeffsBank;
 #endif
 
 #if ARCH_BFIN
@@ -215,7 +247,7 @@
 #endif
 
 #if HAVE_VIS
-    DECLARE_ALIGNED(8, uint64_t, sparc_coeffs[10]);
+    DECLARE_ALIGNED(8, uint64_t, sparc_coeffs)[10];
 #endif
 
     /* function pointers for swScale() */
@@ -254,18 +286,18 @@
                         const int16_t **alpSrc, uint8_t *dest,
                         long dstW, long dstY);
 
-    void (*hyscale_internal)(uint8_t *dst, const uint8_t *src,
-                             long width, uint32_t *pal);
-    void (*hascale_internal)(uint8_t *dst, const uint8_t *src,
-                             long width, uint32_t *pal);
-    void (*hcscale_internal)(uint8_t *dstU, uint8_t *dstV,
-                             const uint8_t *src1, const uint8_t *src2,
-                             long width, uint32_t *pal);
+    void (*lumToYV12)(uint8_t *dst, const uint8_t *src,
+                      long width, uint32_t *pal); ///&lt; Unscaled conversion of luma plane to YV12 for horizontal scaler.
+    void (*alpToYV12)(uint8_t *dst, const uint8_t *src,
+                      long width, uint32_t *pal); ///&lt; Unscaled conversion of alpha plane to YV12 for horizontal scaler.
+    void (*chrToYV12)(uint8_t *dstU, uint8_t *dstV,
+                      const uint8_t *src1, const uint8_t *src2,
+                      long width, uint32_t *pal); ///&lt; Unscaled conversion of chroma planes to YV12 for horizontal scaler.
     void (*hyscale_fast)(struct SwsContext *c,
-                         int16_t *dst, int dstWidth,
+                         int16_t *dst, long dstWidth,
                          const uint8_t *src, int srcW, int xInc);
     void (*hcscale_fast)(struct SwsContext *c,
-                         int16_t *dst, int dstWidth,
+                         int16_t *dst, long dstWidth,
                          const uint8_t *src1, const uint8_t *src2,
                          int srcW, int xInc);
 
@@ -273,6 +305,15 @@
                    int xInc, const int16_t *filter, const int16_t *filterPos,
                    long filterSize);
 
+    void (*lumConvertRange)(uint16_t *dst, int width); ///&lt; Color range conversion function for luma plane if needed.
+    void (*chrConvertRange)(uint16_t *dst, int width); ///&lt; Color range conversion function for chroma planes if needed.
+
+    int lumSrcOffset; ///&lt; Offset given to luma src pointers passed to horizontal input functions.
+    int chrSrcOffset; ///&lt; Offset given to chroma src pointers passed to horizontal input functions.
+    int alpSrcOffset; ///&lt; Offset given to alpha src pointers passed to horizontal input functions.
+
+    int needs_hcscale; ///&lt; Set if there are chroma planes to be converted.
+
 } SwsContext;
 //FIXME check init (where 0)
 
@@ -302,12 +343,12 @@
         || (x)==PIX_FMT_GRAY16LE    \
         || (x)==PIX_FMT_RGB48BE     \
         || (x)==PIX_FMT_RGB48LE     \
-        || (x)==PIX_FMT_YUV420PLE   \
-        || (x)==PIX_FMT_YUV422PLE   \
-        || (x)==PIX_FMT_YUV444PLE   \
-        || (x)==PIX_FMT_YUV420PBE   \
-        || (x)==PIX_FMT_YUV422PBE   \
-        || (x)==PIX_FMT_YUV444PBE   \
+        || (x)==PIX_FMT_YUV420P16LE   \
+        || (x)==PIX_FMT_YUV422P16LE   \
+        || (x)==PIX_FMT_YUV444P16LE   \
+        || (x)==PIX_FMT_YUV420P16BE   \
+        || (x)==PIX_FMT_YUV422P16BE   \
+        || (x)==PIX_FMT_YUV444P16BE   \
     )
 #define isBE(x) ((x)&amp;1)
 #define isPlanar8YUV(x) (           \
@@ -323,12 +364,12 @@
     )
 #define isPlanarYUV(x)  (           \
         isPlanar8YUV(x)             \
-        || (x)==PIX_FMT_YUV420PLE   \
-        || (x)==PIX_FMT_YUV422PLE   \
-        || (x)==PIX_FMT_YUV444PLE   \
-        || (x)==PIX_FMT_YUV420PBE   \
-        || (x)==PIX_FMT_YUV422PBE   \
-        || (x)==PIX_FMT_YUV444PBE   \
+        || (x)==PIX_FMT_YUV420P16LE   \
+        || (x)==PIX_FMT_YUV422P16LE   \
+        || (x)==PIX_FMT_YUV444P16LE   \
+        || (x)==PIX_FMT_YUV420P16BE   \
+        || (x)==PIX_FMT_YUV422P16BE   \
+        || (x)==PIX_FMT_YUV444P16BE   \
     )
 #define isYUV(x)        (           \
            (x)==PIX_FMT_UYVY422     \
@@ -344,7 +385,7 @@
            (x)==PIX_FMT_GRAY16BE    \
         || (x)==PIX_FMT_GRAY16LE    \
     )
-#define isRGB(x)        (           \
+#define isRGBinInt(x)   (           \
            (x)==PIX_FMT_RGB48BE     \
         || (x)==PIX_FMT_RGB48LE     \
         || (x)==PIX_FMT_RGB32       \
@@ -358,7 +399,7 @@
         || (x)==PIX_FMT_MONOBLACK   \
         || (x)==PIX_FMT_MONOWHITE   \
     )
-#define isBGR(x)        (           \
+#define isBGRinInt(x)   (           \
            (x)==PIX_FMT_BGR32       \
         || (x)==PIX_FMT_BGR32_1     \
         || (x)==PIX_FMT_BGR24       \
@@ -370,6 +411,22 @@
         || (x)==PIX_FMT_MONOBLACK   \
         || (x)==PIX_FMT_MONOWHITE   \
     )
+#define isRGBinBytes(x) (           \
+           (x)==PIX_FMT_RGB48BE     \
+        || (x)==PIX_FMT_RGB48LE     \
+        || (x)==PIX_FMT_RGBA        \
+        || (x)==PIX_FMT_ARGB        \
+        || (x)==PIX_FMT_RGB24       \
+    )
+#define isBGRinBytes(x) (           \
+           (x)==PIX_FMT_BGRA        \
+        || (x)==PIX_FMT_ABGR        \
+        || (x)==PIX_FMT_BGR24       \
+    )
+#define isAnyRGB(x)     (           \
+            isRGBinInt(x)           \
+        ||  isBGRinInt(x)           \
+    )
 #define isALPHA(x)      (           \
            (x)==PIX_FMT_BGR32       \
         || (x)==PIX_FMT_BGR32_1     \
@@ -378,47 +435,26 @@
         || (x)==PIX_FMT_YUVA420P    \
     )
 
-static inline int fmt_depth(int fmt)
-{
-    switch(fmt) {
-    case PIX_FMT_RGB48BE:
-    case PIX_FMT_RGB48LE:
-        return 48;
-    case PIX_FMT_BGRA:
-    case PIX_FMT_ABGR:
-    case PIX_FMT_RGBA:
-    case PIX_FMT_ARGB:
-        return 32;
-    case PIX_FMT_BGR24:
-    case PIX_FMT_RGB24:
-        return 24;
-    case PIX_FMT_BGR565:
-    case PIX_FMT_RGB565:
-    case PIX_FMT_GRAY16BE:
-    case PIX_FMT_GRAY16LE:
-        return 16;
-    case PIX_FMT_BGR555:
-    case PIX_FMT_RGB555:
-        return 15;
-    case PIX_FMT_BGR8:
-    case PIX_FMT_RGB8:
-        return 8;
-    case PIX_FMT_BGR4:
-    case PIX_FMT_RGB4:
-    case PIX_FMT_BGR4_BYTE:
-    case PIX_FMT_RGB4_BYTE:
-        return 4;
-    case PIX_FMT_MONOBLACK:
-    case PIX_FMT_MONOWHITE:
-        return 1;
-    default:
-        return 0;
-    }
-}
-
 extern const uint64_t ff_dither4[2];
 extern const uint64_t ff_dither8[2];
 
 extern const AVClass sws_context_class;
 
+/**
+ * Sets c-&gt;swScale to an unscaled converter if one exists for the specific
+ * source and destination formats, bit depths, flags, etc.
+ */
+void ff_get_unscaled_swscale(SwsContext *c);
+
+/**
+ * Returns the SWS_CPU_CAPS for the optimized code compiled into swscale.
+ */
+int ff_hardcodedcpuflags(void);
+
+/**
+ * Returns function pointer to fastest main scaler path function depending
+ * on architecture and available optimizations.
+ */
+SwsFunc ff_getSwsFunc(SwsContext *c);
+
 #endif /* SWSCALE_SWSCALE_INTERNAL_H */

Modified: branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/swscale_template.c
===================================================================
--- branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/swscale_template.c	2010-05-26 05:26:42 UTC (rev 6237)
+++ branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/swscale_template.c	2010-05-26 05:26:46 UTC (rev 6238)
@@ -25,17 +25,13 @@
 #undef MOVNTQ
 #undef PAVGB
 #undef PREFETCH
-#undef PREFETCHW
 
 #if COMPILE_TEMPLATE_AMD3DNOW
 #define PREFETCH  &quot;prefetch&quot;
-#define PREFETCHW &quot;prefetchw&quot;
 #elif COMPILE_TEMPLATE_MMX2
 #define PREFETCH &quot;prefetchnta&quot;
-#define PREFETCHW &quot;prefetcht0&quot;
 #else
 #define PREFETCH  &quot; # nop&quot;
-#define PREFETCHW &quot; # nop&quot;
 #endif
 
 #if COMPILE_TEMPLATE_MMX2
@@ -944,7 +940,7 @@
 
 static inline void RENAME(yuv2nv12X)(SwsContext *c, const int16_t *lumFilter, const int16_t **lumSrc, int lumFilterSize,
                                      const int16_t *chrFilter, const int16_t **chrSrc, int chrFilterSize,
-                                     uint8_t *dest, uint8_t *uDest, int dstW, int chrDstW, int dstFormat)
+                                     uint8_t *dest, uint8_t *uDest, int dstW, int chrDstW, enum PixelFormat dstFormat)
 {
     yuv2nv12XinC(lumFilter, lumSrc, lumFilterSize,
                  chrFilter, chrSrc, chrFilterSize,
@@ -958,7 +954,7 @@
 #if COMPILE_TEMPLATE_MMX
     if(!(c-&gt;flags &amp; SWS_BITEXACT)) {
         long p= 4;
-        uint8_t *src[4]= {alpSrc + dstW, lumSrc + dstW, chrSrc + chrDstW, chrSrc + VOFW + chrDstW};
+        const uint8_t *src[4]= {alpSrc + dstW, lumSrc + dstW, chrSrc + chrDstW, chrSrc + VOFW + chrDstW};
         uint8_t *dst[4]= {aDest, dest, uDest, vDest};
         x86_reg counter[4]= {dstW, dstW, chrDstW, chrDstW};
 
@@ -1226,21 +1222,21 @@
             if (CONFIG_SWSCALE_ALPHA &amp;&amp; c-&gt;alpPixBuf) {
 #if ARCH_X86_64
                 __asm__ volatile(
-                    YSCALEYUV2RGB(%%REGBP, %5)
-                    YSCALEYUV2RGB_YA(%%REGBP, %5, %6, %7)
+                    YSCALEYUV2RGB(%%r8, %5)
+                    YSCALEYUV2RGB_YA(%%r8, %5, %6, %7)
                     &quot;psraw                  $3, %%mm1       \n\t&quot; /* abuf0[eax] - abuf1[eax] &gt;&gt;7*/
                     &quot;psraw                  $3, %%mm7       \n\t&quot; /* abuf0[eax] - abuf1[eax] &gt;&gt;7*/
                     &quot;packuswb            %%mm7, %%mm1       \n\t&quot;
-                    WRITEBGR32(%4, 8280(%5), %%REGBP, %%mm2, %%mm4, %%mm5, %%mm1, %%mm0, %%mm7, %%mm3, %%mm6)
+                    WRITEBGR32(%4, 8280(%5), %%r8, %%mm2, %%mm4, %%mm5, %%mm1, %%mm0, %%mm7, %%mm3, %%mm6)
 
                     :: &quot;c&quot; (buf0), &quot;d&quot; (buf1), &quot;S&quot; (uvbuf0), &quot;D&quot; (uvbuf1), &quot;r&quot; (dest),
                     &quot;a&quot; (&amp;c-&gt;redDither)
                     ,&quot;r&quot; (abuf0), &quot;r&quot; (abuf1)
-                    : &quot;%&quot;REG_BP
+                    : &quot;%r8&quot;
                 );
 #else
-                *(uint16_t **)(&amp;c-&gt;u_temp)=abuf0;
-                *(uint16_t **)(&amp;c-&gt;v_temp)=abuf1;
+                *(const uint16_t **)(&amp;c-&gt;u_temp)=abuf0;
+                *(const uint16_t **)(&amp;c-&gt;v_temp)=abuf1;
                 __asm__ volatile(
                     &quot;mov %%&quot;REG_b&quot;, &quot;ESP_OFFSET&quot;(%5)        \n\t&quot;
                     &quot;mov        %4, %%&quot;REG_b&quot;               \n\t&quot;
@@ -1361,7 +1357,7 @@
  * YV12 to RGB without scaling or interpolating
  */
 static inline void RENAME(yuv2packed1)(SwsContext *c, const uint16_t *buf0, const uint16_t *uvbuf0, const uint16_t *uvbuf1,
-                          const uint16_t *abuf0, uint8_t *dest, int dstW, int uvalpha, int dstFormat, int flags, int y)
+                          const uint16_t *abuf0, uint8_t *dest, int dstW, int uvalpha, enum PixelFormat dstFormat, int flags, int y)
 {
     const int yalpha1=0;
     int i;
@@ -1784,10 +1780,58 @@
 #endif
 }
 
+static inline void RENAME(nvXXtoUV)(uint8_t *dst1, uint8_t *dst2,
+                                    const uint8_t *src, long width)
+{
 #if COMPILE_TEMPLATE_MMX
-static inline void RENAME(bgr24ToY_mmx)(uint8_t *dst, const uint8_t *src, long width, int srcFormat)
+    __asm__ volatile(
+        &quot;movq &quot;MANGLE(bm01010101)&quot;, %%mm4           \n\t&quot;
+        &quot;mov                    %0, %%&quot;REG_a&quot;       \n\t&quot;
+        &quot;1:                                         \n\t&quot;
+        &quot;movq    (%1, %%&quot;REG_a&quot;,2), %%mm0           \n\t&quot;
+        &quot;movq   8(%1, %%&quot;REG_a&quot;,2), %%mm1           \n\t&quot;
+        &quot;movq                %%mm0, %%mm2           \n\t&quot;
+        &quot;movq                %%mm1, %%mm3           \n\t&quot;
+        &quot;pand                %%mm4, %%mm0           \n\t&quot;
+        &quot;pand                %%mm4, %%mm1           \n\t&quot;
+        &quot;psrlw                  $8, %%mm2           \n\t&quot;
+        &quot;psrlw                  $8, %%mm3           \n\t&quot;
+        &quot;packuswb            %%mm1, %%mm0           \n\t&quot;
+        &quot;packuswb            %%mm3, %%mm2           \n\t&quot;
+        &quot;movq                %%mm0, (%2, %%&quot;REG_a&quot;) \n\t&quot;
+        &quot;movq                %%mm2, (%3, %%&quot;REG_a&quot;) \n\t&quot;
+        &quot;add                    $8, %%&quot;REG_a&quot;       \n\t&quot;
+        &quot; js                    1b                  \n\t&quot;
+        : : &quot;g&quot; ((x86_reg)-width), &quot;r&quot; (src+width*2), &quot;r&quot; (dst1+width), &quot;r&quot; (dst2+width)
+        : &quot;%&quot;REG_a
+    );
+#else
+    int i;
+    for (i = 0; i &lt; width; i++) {
+        dst1[i] = src[2*i+0];
+        dst2[i] = src[2*i+1];
+    }
+#endif
+}
+
+static inline void RENAME(nv12ToUV)(uint8_t *dstU, uint8_t *dstV,
+                                    const uint8_t *src1, const uint8_t *src2,
+                                    long width, uint32_t *unused)
 {
+    RENAME(nvXXtoUV)(dstU, dstV, src1, width);
+}
 
+static inline void RENAME(nv21ToUV)(uint8_t *dstU, uint8_t *dstV,
+                                    const uint8_t *src1, const uint8_t *src2,
+                                    long width, uint32_t *unused)
+{
+    RENAME(nvXXtoUV)(dstV, dstU, src1, width);
+}
+
+#if COMPILE_TEMPLATE_MMX
+static inline void RENAME(bgr24ToY_mmx)(uint8_t *dst, const uint8_t *src, long width, enum PixelFormat srcFormat)
+{
+
     if(srcFormat == PIX_FMT_BGR24) {
         __asm__ volatile(
             &quot;movq  &quot;MANGLE(ff_bgr24toY1Coeff)&quot;, %%mm5       \n\t&quot;
@@ -1838,7 +1882,7 @@
     );
 }
 
-static inline void RENAME(bgr24ToUV_mmx)(uint8_t *dstU, uint8_t *dstV, const uint8_t *src, long width, int srcFormat)
+static inline void RENAME(bgr24ToUV_mmx)(uint8_t *dstU, uint8_t *dstV, const uint8_t *src, long width, enum PixelFormat srcFormat)
 {
     __asm__ volatile(
         &quot;movq                    24+%4, %%mm6       \n\t&quot;
@@ -2101,7 +2145,7 @@
 #endif
         );
     } else {
-        uint8_t *offset = src+filterSize;
+        const uint8_t *offset = src+filterSize;
         x86_reg counter= -2*dstW;
         //filter-= counter*filterSize/2;
         filterPos-= counter/2;
@@ -2171,6 +2215,37 @@
 #endif /* COMPILE_MMX */
 }
 
+//FIXME all pal and rgb srcFormats could do this convertion as well
+//FIXME all scalers more complex than bilinear could do half of this transform
+static void RENAME(chrRangeToJpeg)(uint16_t *dst, int width)
+{
+    int i;
+    for (i = 0; i &lt; width; i++) {
+        dst[i     ] = (FFMIN(dst[i     ],30775)*4663 - 9289992)&gt;&gt;12; //-264
+        dst[i+VOFW] = (FFMIN(dst[i+VOFW],30775)*4663 - 9289992)&gt;&gt;12; //-264
+    }
+}
+static void RENAME(chrRangeFromJpeg)(uint16_t *dst, int width)
+{
+    int i;
+    for (i = 0; i &lt; width; i++) {
+        dst[i     ] = (dst[i     ]*1799 + 4081085)&gt;&gt;11; //1469
+        dst[i+VOFW] = (dst[i+VOFW]*1799 + 4081085)&gt;&gt;11; //1469
+    }
+}
+static void RENAME(lumRangeToJpeg)(uint16_t *dst, int width)
+{
+    int i;
+    for (i = 0; i &lt; width; i++)
+        dst[i] = (FFMIN(dst[i],30189)*19077 - 39057361)&gt;&gt;14;
+}
+static void RENAME(lumRangeFromJpeg)(uint16_t *dst, int width)
+{
+    int i;
+    for (i = 0; i &lt; width; i++)
+        dst[i] = (dst[i]*14071 + 33561947)&gt;&gt;14;
+}
+
 #define FAST_BILINEAR_X86 \
     &quot;subl    %%edi, %%esi    \n\t&quot; /*  src[xx+1] - src[xx] */                   \
     &quot;imull   %%ecx, %%esi    \n\t&quot; /* (src[xx+1] - src[xx])*xalpha */           \
@@ -2180,10 +2255,117 @@
     &quot;shrl       $9, %%esi    \n\t&quot;                                              \
 
 static inline void RENAME(hyscale_fast)(SwsContext *c, int16_t *dst,
-                                        int dstWidth, const uint8_t *src, int srcW,
+                                        long dstWidth, const uint8_t *src, int srcW,
                                         int xInc)
 {
+#if ARCH_X86 &amp;&amp; CONFIG_GPL
+#if COMPILE_TEMPLATE_MMX2
+    int32_t *filterPos = c-&gt;hLumFilterPos;
+    int16_t *filter    = c-&gt;hLumFilter;
+    int     canMMX2BeUsed  = c-&gt;canMMX2BeUsed;
+    void    *mmx2FilterCode= c-&gt;lumMmx2FilterCode;
     int i;
+#if defined(PIC)
+    DECLARE_ALIGNED(8, uint64_t, ebxsave);
+#endif
+    if (canMMX2BeUsed) {
+        __asm__ volatile(
+#if defined(PIC)
+            &quot;mov               %%&quot;REG_b&quot;, %5        \n\t&quot;
+#endif
+            &quot;pxor                  %%mm7, %%mm7     \n\t&quot;
+            &quot;mov                      %0, %%&quot;REG_c&quot; \n\t&quot;
+            &quot;mov                      %1, %%&quot;REG_D&quot; \n\t&quot;
+            &quot;mov                      %2, %%&quot;REG_d&quot; \n\t&quot;
+            &quot;mov                      %3, %%&quot;REG_b&quot; \n\t&quot;
+            &quot;xor               %%&quot;REG_a&quot;, %%&quot;REG_a&quot; \n\t&quot; // i
+            PREFETCH&quot;        (%%&quot;REG_c&quot;)            \n\t&quot;
+            PREFETCH&quot;      32(%%&quot;REG_c&quot;)            \n\t&quot;
+            PREFETCH&quot;      64(%%&quot;REG_c&quot;)            \n\t&quot;
+
+#if ARCH_X86_64
+
+#define CALL_MMX2_FILTER_CODE \
+            &quot;movl            (%%&quot;REG_b&quot;), %%esi     \n\t&quot;\
+            &quot;call                    *%4            \n\t&quot;\
+            &quot;movl (%%&quot;REG_b&quot;, %%&quot;REG_a&quot;), %%esi     \n\t&quot;\
+            &quot;add               %%&quot;REG_S&quot;, %%&quot;REG_c&quot; \n\t&quot;\
+            &quot;add               %%&quot;REG_a&quot;, %%&quot;REG_D&quot; \n\t&quot;\
+            &quot;xor               %%&quot;REG_a&quot;, %%&quot;REG_a&quot; \n\t&quot;\
+
+#else
+
+#define CALL_MMX2_FILTER_CODE \
+            &quot;movl (%%&quot;REG_b&quot;), %%esi        \n\t&quot;\
+            &quot;call         *%4                       \n\t&quot;\
+            &quot;addl (%%&quot;REG_b&quot;, %%&quot;REG_a&quot;), %%&quot;REG_c&quot; \n\t&quot;\
+            &quot;add               %%&quot;REG_a&quot;, %%&quot;REG_D&quot; \n\t&quot;\
+            &quot;xor               %%&quot;REG_a&quot;, %%&quot;REG_a&quot; \n\t&quot;\
+
+#endif /* ARCH_X86_64 */
+
+            CALL_MMX2_FILTER_CODE
+            CALL_MMX2_FILTER_CODE
+            CALL_MMX2_FILTER_CODE
+            CALL_MMX2_FILTER_CODE
+            CALL_MMX2_FILTER_CODE
+            CALL_MMX2_FILTER_CODE
+            CALL_MMX2_FILTER_CODE
+            CALL_MMX2_FILTER_CODE
+
+#if defined(PIC)
+            &quot;mov                      %5, %%&quot;REG_b&quot; \n\t&quot;
+#endif
+            :: &quot;m&quot; (src), &quot;m&quot; (dst), &quot;m&quot; (filter), &quot;m&quot; (filterPos),
+            &quot;m&quot; (mmx2FilterCode)
+#if defined(PIC)
+            ,&quot;m&quot; (ebxsave)
+#endif
+            : &quot;%&quot;REG_a, &quot;%&quot;REG_c, &quot;%&quot;REG_d, &quot;%&quot;REG_S, &quot;%&quot;REG_D
+#if !defined(PIC)
+            ,&quot;%&quot;REG_b
+#endif
+        );
+        for (i=dstWidth-1; (i*xInc)&gt;&gt;16 &gt;=srcW-1; i--) dst[i] = src[srcW-1]*128;
+    } else {
+#endif /* COMPILE_TEMPLATE_MMX2 */
+    x86_reg xInc_shr16 = xInc &gt;&gt; 16;
+    uint16_t xInc_mask = xInc &amp; 0xffff;
+    //NO MMX just normal asm ...
+    __asm__ volatile(
+        &quot;xor %%&quot;REG_a&quot;, %%&quot;REG_a&quot;            \n\t&quot; // i
+        &quot;xor %%&quot;REG_d&quot;, %%&quot;REG_d&quot;            \n\t&quot; // xx
+        &quot;xorl    %%ecx, %%ecx                \n\t&quot; // xalpha
+        ASMALIGN(4)
+        &quot;1:                                  \n\t&quot;
+        &quot;movzbl    (%0, %%&quot;REG_d&quot;), %%edi    \n\t&quot; //src[xx]
+        &quot;movzbl   1(%0, %%&quot;REG_d&quot;), %%esi    \n\t&quot; //src[xx+1]
+        FAST_BILINEAR_X86
+        &quot;movw     %%si, (%%&quot;REG_D&quot;, %%&quot;REG_a&quot;, 2)   \n\t&quot;
+        &quot;addw       %4, %%cx                 \n\t&quot; //xalpha += xInc&amp;0xFFFF
+        &quot;adc        %3, %%&quot;REG_d&quot;            \n\t&quot; //xx+= xInc&gt;&gt;16 + carry
+
+        &quot;movzbl    (%0, %%&quot;REG_d&quot;), %%edi    \n\t&quot; //src[xx]
+        &quot;movzbl   1(%0, %%&quot;REG_d&quot;), %%esi    \n\t&quot; //src[xx+1]
+        FAST_BILINEAR_X86
+        &quot;movw     %%si, 2(%%&quot;REG_D&quot;, %%&quot;REG_a&quot;, 2)  \n\t&quot;
+        &quot;addw       %4, %%cx                 \n\t&quot; //xalpha += xInc&amp;0xFFFF
+        &quot;adc        %3, %%&quot;REG_d&quot;            \n\t&quot; //xx+= xInc&gt;&gt;16 + carry
+
+
+        &quot;add        $2, %%&quot;REG_a&quot;            \n\t&quot;
+        &quot;cmp        %2, %%&quot;REG_a&quot;            \n\t&quot;
+        &quot; jb        1b                       \n\t&quot;
+
+
+        :: &quot;r&quot; (src), &quot;m&quot; (dst), &quot;m&quot; (dstWidth), &quot;m&quot; (xInc_shr16), &quot;m&quot; (xInc_mask)
+        : &quot;%&quot;REG_a, &quot;%&quot;REG_d, &quot;%ecx&quot;, &quot;%&quot;REG_D, &quot;%esi&quot;
+    );
+#if COMPILE_TEMPLATE_MMX2
+    } //if MMX2 can't be used
+#endif
+#else
+    int i;
     unsigned int xpos=0;
     for (i=0;i&lt;dstWidth;i++) {
         register unsigned int xx=xpos&gt;&gt;16;
@@ -2191,171 +2373,141 @@
         dst[i]= (src[xx]&lt;&lt;7) + (src[xx+1] - src[xx])*xalpha;
         xpos+=xInc;
     }
+#endif /* ARCH_X86 */
 }
 
       // *** horizontal scale Y line to temp buffer
 static inline void RENAME(hyscale)(SwsContext *c, uint16_t *dst, long dstWidth, const uint8_t *src, int srcW, int xInc,
-                                   int flags, const int16_t *hLumFilter,
+                                   const int16_t *hLumFilter,
                                    const int16_t *hLumFilterPos, int hLumFilterSize,
-                                   int srcFormat, uint8_t *formatConvBuffer,
+                                   uint8_t *formatConvBuffer,
                                    uint32_t *pal, int isAlpha)
 {
-    int32_t av_unused *mmx2FilterPos = c-&gt;lumMmx2FilterPos;
-    int16_t av_unused *mmx2Filter    = c-&gt;lumMmx2Filter;
-    int     av_unused canMMX2BeUsed  = c-&gt;canMMX2BeUsed;
-    void    av_unused *mmx2FilterCode= c-&gt;lumMmx2FilterCode;
-    void (*internal_func)(uint8_t *, const uint8_t *, long, uint32_t *) = isAlpha ? c-&gt;hascale_internal : c-&gt;hyscale_internal;
+    void (*toYV12)(uint8_t *, const uint8_t *, long, uint32_t *) = isAlpha ? c-&gt;alpToYV12 : c-&gt;lumToYV12;
+    void (*convertRange)(uint16_t *, int) = isAlpha ? NULL : c-&gt;lumConvertRange;
 
-    if (isAlpha) {
-        if (srcFormat == PIX_FMT_RGB32   || srcFormat == PIX_FMT_BGR32  )
-            src += 3;
-    } else {
-        if (srcFormat == PIX_FMT_RGB32_1 || srcFormat == PIX_FMT_BGR32_1)
-            src += ALT32_CORR;
-    }
+    src += isAlpha ? c-&gt;alpSrcOffset : c-&gt;lumSrcOffset;
 
-    if (srcFormat == PIX_FMT_RGB48LE)
-        src++;
-
-    if (internal_func) {
-        internal_func(formatConvBuffer, src, srcW, pal);
+    if (toYV12) {
+        toYV12(formatConvBuffer, src, srcW, pal);
         src= formatConvBuffer;
     }
 
-#if COMPILE_TEMPLATE_MMX
-    // Use the new MMX scaler if the MMX2 one can't be used (it is faster than the x86 ASM one).
-    if (!(flags&amp;SWS_FAST_BILINEAR) || (!canMMX2BeUsed))
-#else
-    if (!(flags&amp;SWS_FAST_BILINEAR))
-#endif
-    {
+    if (!c-&gt;hyscale_fast) {
         c-&gt;hScale(dst, dstWidth, src, srcW, xInc, hLumFilter, hLumFilterPos, hLumFilterSize);
     } else { // fast bilinear upscale / crap downscale
+        c-&gt;hyscale_fast(c, dst, dstWidth, src, srcW, xInc);
+    }
+
+    if (convertRange)
+        convertRange(dst, dstWidth);
+}
+
+static inline void RENAME(hcscale_fast)(SwsContext *c, int16_t *dst,
+                                        long dstWidth, const uint8_t *src1,
+                                        const uint8_t *src2, int srcW, int xInc)
+{
 #if ARCH_X86 &amp;&amp; CONFIG_GPL
 #if COMPILE_TEMPLATE_MMX2
-        int i;
+    int32_t *filterPos = c-&gt;hChrFilterPos;
+    int16_t *filter    = c-&gt;hChrFilter;
+    int     canMMX2BeUsed  = c-&gt;canMMX2BeUsed;
+    void    *mmx2FilterCode= c-&gt;chrMmx2FilterCode;
+    int i;
 #if defined(PIC)
-        DECLARE_ALIGNED(8, uint64_t, ebxsave);
+    DECLARE_ALIGNED(8, uint64_t, ebxsave);
 #endif
-        if (canMMX2BeUsed) {
-            __asm__ volatile(
+    if (canMMX2BeUsed) {
+        __asm__ volatile(
 #if defined(PIC)
-                &quot;mov               %%&quot;REG_b&quot;, %5        \n\t&quot;
+            &quot;mov          %%&quot;REG_b&quot;, %6         \n\t&quot;
 #endif
-                &quot;pxor                  %%mm7, %%mm7     \n\t&quot;
-                &quot;mov                      %0, %%&quot;REG_c&quot; \n\t&quot;
-                &quot;mov                      %1, %%&quot;REG_D&quot; \n\t&quot;
-                &quot;mov                      %2, %%&quot;REG_d&quot; \n\t&quot;
-                &quot;mov                      %3, %%&quot;REG_b&quot; \n\t&quot;
-                &quot;xor               %%&quot;REG_a&quot;, %%&quot;REG_a&quot; \n\t&quot; // i
-                PREFETCH&quot;        (%%&quot;REG_c&quot;)            \n\t&quot;
-                PREFETCH&quot;      32(%%&quot;REG_c&quot;)            \n\t&quot;
-                PREFETCH&quot;      64(%%&quot;REG_c&quot;)            \n\t&quot;
+            &quot;pxor             %%mm7, %%mm7      \n\t&quot;
+            &quot;mov                 %0, %%&quot;REG_c&quot;  \n\t&quot;
+            &quot;mov                 %1, %%&quot;REG_D&quot;  \n\t&quot;
+            &quot;mov                 %2, %%&quot;REG_d&quot;  \n\t&quot;
+            &quot;mov                 %3, %%&quot;REG_b&quot;  \n\t&quot;
+            &quot;xor          %%&quot;REG_a&quot;, %%&quot;REG_a&quot;  \n\t&quot; // i
+            PREFETCH&quot;   (%%&quot;REG_c&quot;)             \n\t&quot;
+            PREFETCH&quot; 32(%%&quot;REG_c&quot;)             \n\t&quot;
+            PREFETCH&quot; 64(%%&quot;REG_c&quot;)             \n\t&quot;
 
-#if ARCH_X86_64
+            CALL_MMX2_FILTER_CODE
+            CALL_MMX2_FILTER_CODE
+            CALL_MMX2_FILTER_CODE
+            CALL_MMX2_FILTER_CODE
+            &quot;xor          %%&quot;REG_a&quot;, %%&quot;REG_a&quot;  \n\t&quot; // i
+            &quot;mov                 %5, %%&quot;REG_c&quot;  \n\t&quot; // src
+            &quot;mov                 %1, %%&quot;REG_D&quot;  \n\t&quot; // buf1
+            &quot;add              $&quot;AV_STRINGIFY(VOF)&quot;, %%&quot;REG_D&quot;  \n\t&quot;
+            PREFETCH&quot;   (%%&quot;REG_c&quot;)             \n\t&quot;
+            PREFETCH&quot; 32(%%&quot;REG_c&quot;)             \n\t&quot;
+            PREFETCH&quot; 64(%%&quot;REG_c&quot;)             \n\t&quot;
 
-#define CALL_MMX2_FILTER_CODE \
-                &quot;movl            (%%&quot;REG_b&quot;), %%esi     \n\t&quot;\
-                &quot;call                    *%4            \n\t&quot;\
-                &quot;movl (%%&quot;REG_b&quot;, %%&quot;REG_a&quot;), %%esi     \n\t&quot;\
-                &quot;add               %%&quot;REG_S&quot;, %%&quot;REG_c&quot; \n\t&quot;\
-                &quot;add               %%&quot;REG_a&quot;, %%&quot;REG_D&quot; \n\t&quot;\
-                &quot;xor               %%&quot;REG_a&quot;, %%&quot;REG_a&quot; \n\t&quot;\
+            CALL_MMX2_FILTER_CODE
+            CALL_MMX2_FILTER_CODE
+            CALL_MMX2_FILTER_CODE
+            CALL_MMX2_FILTER_CODE
 
-#else
-
-#define CALL_MMX2_FILTER_CODE \
-                &quot;movl (%%&quot;REG_b&quot;), %%esi        \n\t&quot;\
-                &quot;call         *%4                       \n\t&quot;\
-                &quot;addl (%%&quot;REG_b&quot;, %%&quot;REG_a&quot;), %%&quot;REG_c&quot; \n\t&quot;\
-                &quot;add               %%&quot;REG_a&quot;, %%&quot;REG_D&quot; \n\t&quot;\
-                &quot;xor               %%&quot;REG_a&quot;, %%&quot;REG_a&quot; \n\t&quot;\
-
-#endif /* ARCH_X86_64 */
-
-                CALL_MMX2_FILTER_CODE
-                CALL_MMX2_FILTER_CODE
-                CALL_MMX2_FILTER_CODE
-                CALL_MMX2_FILTER_CODE
-                CALL_MMX2_FILTER_CODE
-                CALL_MMX2_FILTER_CODE
-                CALL_MMX2_FILTER_CODE
-                CALL_MMX2_FILTER_CODE
-
 #if defined(PIC)
-                &quot;mov                      %5, %%&quot;REG_b&quot; \n\t&quot;
+            &quot;mov %6, %%&quot;REG_b&quot;    \n\t&quot;
 #endif
-                :: &quot;m&quot; (src), &quot;m&quot; (dst), &quot;m&quot; (mmx2Filter), &quot;m&quot; (mmx2FilterPos),
-                &quot;m&quot; (mmx2FilterCode)
+            :: &quot;m&quot; (src1), &quot;m&quot; (dst), &quot;m&quot; (filter), &quot;m&quot; (filterPos),
+            &quot;m&quot; (mmx2FilterCode), &quot;m&quot; (src2)
 #if defined(PIC)
-                ,&quot;m&quot; (ebxsave)
+            ,&quot;m&quot; (ebxsave)
 #endif
-                : &quot;%&quot;REG_a, &quot;%&quot;REG_c, &quot;%&quot;REG_d, &quot;%&quot;REG_S, &quot;%&quot;REG_D
+            : &quot;%&quot;REG_a, &quot;%&quot;REG_c, &quot;%&quot;REG_d, &quot;%&quot;REG_S, &quot;%&quot;REG_D
 #if !defined(PIC)
-                ,&quot;%&quot;REG_b
+            ,&quot;%&quot;REG_b
 #endif
-            );
-            for (i=dstWidth-1; (i*xInc)&gt;&gt;16 &gt;=srcW-1; i--) dst[i] = src[srcW-1]*128;
-        } else {
+        );
+        for (i=dstWidth-1; (i*xInc)&gt;&gt;16 &gt;=srcW-1; i--) {
+            //printf(&quot;%d %d %d\n&quot;, dstWidth, i, srcW);
+            dst[i] = src1[srcW-1]*128;
+            dst[i+VOFW] = src2[srcW-1]*128;
+        }
+    } else {
 #endif /* COMPILE_TEMPLATE_MMX2 */
-        x86_reg xInc_shr16 = xInc &gt;&gt; 16;
+        x86_reg xInc_shr16 = (x86_reg) (xInc &gt;&gt; 16);
         uint16_t xInc_mask = xInc &amp; 0xffff;
-        //NO MMX just normal asm ...
         __asm__ volatile(
-            &quot;xor %%&quot;REG_a&quot;, %%&quot;REG_a&quot;            \n\t&quot; // i
-            &quot;xor %%&quot;REG_d&quot;, %%&quot;REG_d&quot;            \n\t&quot; // xx
-            &quot;xorl    %%ecx, %%ecx                \n\t&quot; // xalpha
+            &quot;xor %%&quot;REG_a&quot;, %%&quot;REG_a&quot;               \n\t&quot; // i
+            &quot;xor %%&quot;REG_d&quot;, %%&quot;REG_d&quot;               \n\t&quot; // xx
+            &quot;xorl    %%ecx, %%ecx                   \n\t&quot; // xalpha
             ASMALIGN(4)
-            &quot;1:                                  \n\t&quot;
-            &quot;movzbl    (%0, %%&quot;REG_d&quot;), %%edi    \n\t&quot; //src[xx]
-            &quot;movzbl   1(%0, %%&quot;REG_d&quot;), %%esi    \n\t&quot; //src[xx+1]
+            &quot;1:                                     \n\t&quot;
+            &quot;mov        %0, %%&quot;REG_S&quot;               \n\t&quot;
+            &quot;movzbl  (%%&quot;REG_S&quot;, %%&quot;REG_d&quot;), %%edi  \n\t&quot; //src[xx]
+            &quot;movzbl 1(%%&quot;REG_S&quot;, %%&quot;REG_d&quot;), %%esi  \n\t&quot; //src[xx+1]
             FAST_BILINEAR_X86
             &quot;movw     %%si, (%%&quot;REG_D&quot;, %%&quot;REG_a&quot;, 2)   \n\t&quot;
-            &quot;addw       %4, %%cx                 \n\t&quot; //xalpha += xInc&amp;0xFFFF
-            &quot;adc        %3, %%&quot;REG_d&quot;            \n\t&quot; //xx+= xInc&gt;&gt;16 + carry
 
-            &quot;movzbl    (%0, %%&quot;REG_d&quot;), %%edi    \n\t&quot; //src[xx]
-            &quot;movzbl   1(%0, %%&quot;REG_d&quot;), %%esi    \n\t&quot; //src[xx+1]
+            &quot;movzbl    (%5, %%&quot;REG_d&quot;), %%edi       \n\t&quot; //src[xx]
+            &quot;movzbl   1(%5, %%&quot;REG_d&quot;), %%esi       \n\t&quot; //src[xx+1]
             FAST_BILINEAR_X86
-            &quot;movw     %%si, 2(%%&quot;REG_D&quot;, %%&quot;REG_a&quot;, 2)  \n\t&quot;
-            &quot;addw       %4, %%cx                 \n\t&quot; //xalpha += xInc&amp;0xFFFF
-            &quot;adc        %3, %%&quot;REG_d&quot;            \n\t&quot; //xx+= xInc&gt;&gt;16 + carry
+            &quot;movw     %%si, &quot;AV_STRINGIFY(VOF)&quot;(%%&quot;REG_D&quot;, %%&quot;REG_a&quot;, 2)   \n\t&quot;
 
+            &quot;addw       %4, %%cx                    \n\t&quot; //xalpha += xInc&amp;0xFFFF
+            &quot;adc        %3, %%&quot;REG_d&quot;               \n\t&quot; //xx+= xInc&gt;&gt;16 + carry
+            &quot;add        $1, %%&quot;REG_a&quot;               \n\t&quot;
+            &quot;cmp        %2, %%&quot;REG_a&quot;               \n\t&quot;
+            &quot; jb        1b                          \n\t&quot;
 
-            &quot;add        $2, %%&quot;REG_a&quot;            \n\t&quot;
-            &quot;cmp        %2, %%&quot;REG_a&quot;            \n\t&quot;
-            &quot; jb        1b                       \n\t&quot;
-
-
-            :: &quot;r&quot; (src), &quot;m&quot; (dst), &quot;m&quot; (dstWidth), &quot;m&quot; (xInc_shr16), &quot;m&quot; (xInc_mask)
+/* GCC 3.3 makes MPlayer crash on IA-32 machines when using &quot;g&quot; operand here,
+which is needed to support GCC 4.0. */
+#if ARCH_X86_64 &amp;&amp; AV_GCC_VERSION_AT_LEAST(3,4)
+            :: &quot;m&quot; (src1), &quot;m&quot; (dst), &quot;g&quot; (dstWidth), &quot;m&quot; (xInc_shr16), &quot;m&quot; (xInc_mask),
+#else
+            :: &quot;m&quot; (src1), &quot;m&quot; (dst), &quot;m&quot; (dstWidth), &quot;m&quot; (xInc_shr16), &quot;m&quot; (xInc_mask),
+#endif
+            &quot;r&quot; (src2)
             : &quot;%&quot;REG_a, &quot;%&quot;REG_d, &quot;%ecx&quot;, &quot;%&quot;REG_D, &quot;%esi&quot;
         );
 #if COMPILE_TEMPLATE_MMX2
-        } //if MMX2 can't be used
+    } //if MMX2 can't be used
 #endif
 #else
-        c-&gt;hyscale_fast(c, dst, dstWidth, src, srcW, xInc);
-#endif /* ARCH_X86 */
-    }
-
-    if(!isAlpha &amp;&amp; c-&gt;srcRange != c-&gt;dstRange &amp;&amp; !(isRGB(c-&gt;dstFormat) || isBGR(c-&gt;dstFormat))) {
-        int i;
-        //FIXME all pal and rgb srcFormats could do this convertion as well
-        //FIXME all scalers more complex than bilinear could do half of this transform
-        if(c-&gt;srcRange) {
-            for (i=0; i&lt;dstWidth; i++)
-                dst[i]= (dst[i]*14071 + 33561947)&gt;&gt;14;
-        } else {
-            for (i=0; i&lt;dstWidth; i++)
-                dst[i]= (FFMIN(dst[i],30189)*19077 - 39057361)&gt;&gt;14;
-        }
-    }
-}
-
-static inline void RENAME(hcscale_fast)(SwsContext *c, int16_t *dst,
-                                        int dstWidth, const uint8_t *src1,
-                                        const uint8_t *src2, int srcW, int xInc)
-{
     int i;
     unsigned int xpos=0;
     for (i=0;i&lt;dstWidth;i++) {
@@ -2369,167 +2521,40 @@
         */
         xpos+=xInc;
     }
+#endif /* ARCH_X86 */
 }
 
 inline static void RENAME(hcscale)(SwsContext *c, uint16_t *dst, long dstWidth, const uint8_t *src1, const uint8_t *src2,
-                                   int srcW, int xInc, int flags, const int16_t *hChrFilter,
+                                   int srcW, int xInc, const int16_t *hChrFilter,
                                    const int16_t *hChrFilterPos, int hChrFilterSize,
-                                   int srcFormat, uint8_t *formatConvBuffer,
+                                   uint8_t *formatConvBuffer,
                                    uint32_t *pal)
 {
-    int32_t av_unused *mmx2FilterPos = c-&gt;chrMmx2FilterPos;
-    int16_t av_unused *mmx2Filter    = c-&gt;chrMmx2Filter;
-    int     av_unused canMMX2BeUsed  = c-&gt;canMMX2BeUsed;
-    void    av_unused *mmx2FilterCode= c-&gt;chrMmx2FilterCode;
 
-    if (isGray(srcFormat) || srcFormat==PIX_FMT_MONOBLACK || srcFormat==PIX_FMT_MONOWHITE)
-        return;
+    src1 += c-&gt;chrSrcOffset;
+    src2 += c-&gt;chrSrcOffset;
 
-    if (srcFormat==PIX_FMT_RGB32_1 || srcFormat==PIX_FMT_BGR32_1) {
-        src1 += ALT32_CORR;
-        src2 += ALT32_CORR;
-    }
-
-    if (srcFormat==PIX_FMT_RGB48LE) {
-        src1++;
-        src2++;
-    }
-
-    if (c-&gt;hcscale_internal) {
-        c-&gt;hcscale_internal(formatConvBuffer, formatConvBuffer+VOFW, src1, src2, srcW, pal);
+    if (c-&gt;chrToYV12) {
+        c-&gt;chrToYV12(formatConvBuffer, formatConvBuffer+VOFW, src1, src2, srcW, pal);
         src1= formatConvBuffer;
         src2= formatConvBuffer+VOFW;
     }
 
-#if COMPILE_TEMPLATE_MMX
-    // Use the new MMX scaler if the MMX2 one can't be used (it is faster than the x86 ASM one).
-    if (!(flags&amp;SWS_FAST_BILINEAR) || (!canMMX2BeUsed))
-#else
-    if (!(flags&amp;SWS_FAST_BILINEAR))
-#endif
-    {
+    if (!c-&gt;hcscale_fast) {
         c-&gt;hScale(dst     , dstWidth, src1, srcW, xInc, hChrFilter, hChrFilterPos, hChrFilterSize);
         c-&gt;hScale(dst+VOFW, dstWidth, src2, srcW, xInc, hChrFilter, hChrFilterPos, hChrFilterSize);
     } else { // fast bilinear upscale / crap downscale
-#if ARCH_X86 &amp;&amp; CONFIG_GPL
-#if COMPILE_TEMPLATE_MMX2
-        int i;
-#if defined(PIC)
-        DECLARE_ALIGNED(8, uint64_t, ebxsave);
-#endif
-        if (canMMX2BeUsed) {
-            __asm__ volatile(
-#if defined(PIC)
-                &quot;mov          %%&quot;REG_b&quot;, %6         \n\t&quot;
-#endif
-                &quot;pxor             %%mm7, %%mm7      \n\t&quot;
-                &quot;mov                 %0, %%&quot;REG_c&quot;  \n\t&quot;
-                &quot;mov                 %1, %%&quot;REG_D&quot;  \n\t&quot;
-                &quot;mov                 %2, %%&quot;REG_d&quot;  \n\t&quot;
-                &quot;mov                 %3, %%&quot;REG_b&quot;  \n\t&quot;
-                &quot;xor          %%&quot;REG_a&quot;, %%&quot;REG_a&quot;  \n\t&quot; // i
-                PREFETCH&quot;   (%%&quot;REG_c&quot;)             \n\t&quot;
-                PREFETCH&quot; 32(%%&quot;REG_c&quot;)             \n\t&quot;
-                PREFETCH&quot; 64(%%&quot;REG_c&quot;)             \n\t&quot;
-
-                CALL_MMX2_FILTER_CODE
-                CALL_MMX2_FILTER_CODE
-                CALL_MMX2_FILTER_CODE
-                CALL_MMX2_FILTER_CODE
-                &quot;xor          %%&quot;REG_a&quot;, %%&quot;REG_a&quot;  \n\t&quot; // i
-                &quot;mov                 %5, %%&quot;REG_c&quot;  \n\t&quot; // src
-                &quot;mov                 %1, %%&quot;REG_D&quot;  \n\t&quot; // buf1
-                &quot;add              $&quot;AV_STRINGIFY(VOF)&quot;, %%&quot;REG_D&quot;  \n\t&quot;
-                PREFETCH&quot;   (%%&quot;REG_c&quot;)             \n\t&quot;
-                PREFETCH&quot; 32(%%&quot;REG_c&quot;)             \n\t&quot;
-                PREFETCH&quot; 64(%%&quot;REG_c&quot;)             \n\t&quot;
-
-                CALL_MMX2_FILTER_CODE
-                CALL_MMX2_FILTER_CODE
-                CALL_MMX2_FILTER_CODE
-                CALL_MMX2_FILTER_CODE
-
-#if defined(PIC)
-                &quot;mov %6, %%&quot;REG_b&quot;    \n\t&quot;
-#endif
-                :: &quot;m&quot; (src1), &quot;m&quot; (dst), &quot;m&quot; (mmx2Filter), &quot;m&quot; (mmx2FilterPos),
-                &quot;m&quot; (mmx2FilterCode), &quot;m&quot; (src2)
-#if defined(PIC)
-                ,&quot;m&quot; (ebxsave)
-#endif
-                : &quot;%&quot;REG_a, &quot;%&quot;REG_c, &quot;%&quot;REG_d, &quot;%&quot;REG_S, &quot;%&quot;REG_D
-#if !defined(PIC)
-                ,&quot;%&quot;REG_b
-#endif
-            );
-            for (i=dstWidth-1; (i*xInc)&gt;&gt;16 &gt;=srcW-1; i--) {
-                //printf(&quot;%d %d %d\n&quot;, dstWidth, i, srcW);
-                dst[i] = src1[srcW-1]*128;
-                dst[i+VOFW] = src2[srcW-1]*128;
-            }
-        } else {
-#endif /* COMPILE_TEMPLATE_MMX2 */
-            x86_reg xInc_shr16 = (x86_reg) (xInc &gt;&gt; 16);
-            uint16_t xInc_mask = xInc &amp; 0xffff;
-            __asm__ volatile(
-                &quot;xor %%&quot;REG_a&quot;, %%&quot;REG_a&quot;               \n\t&quot; // i
-                &quot;xor %%&quot;REG_d&quot;, %%&quot;REG_d&quot;               \n\t&quot; // xx
-                &quot;xorl    %%ecx, %%ecx                   \n\t&quot; // xalpha
-                ASMALIGN(4)
-                &quot;1:                                     \n\t&quot;
-                &quot;mov        %0, %%&quot;REG_S&quot;               \n\t&quot;
-                &quot;movzbl  (%%&quot;REG_S&quot;, %%&quot;REG_d&quot;), %%edi  \n\t&quot; //src[xx]
-                &quot;movzbl 1(%%&quot;REG_S&quot;, %%&quot;REG_d&quot;), %%esi  \n\t&quot; //src[xx+1]
-                FAST_BILINEAR_X86
-                &quot;movw     %%si, (%%&quot;REG_D&quot;, %%&quot;REG_a&quot;, 2)   \n\t&quot;
-
-                &quot;movzbl    (%5, %%&quot;REG_d&quot;), %%edi       \n\t&quot; //src[xx]
-                &quot;movzbl   1(%5, %%&quot;REG_d&quot;), %%esi       \n\t&quot; //src[xx+1]
-                FAST_BILINEAR_X86
-                &quot;movw     %%si, &quot;AV_STRINGIFY(VOF)&quot;(%%&quot;REG_D&quot;, %%&quot;REG_a&quot;, 2)   \n\t&quot;
-
-                &quot;addw       %4, %%cx                    \n\t&quot; //xalpha += xInc&amp;0xFFFF
-                &quot;adc        %3, %%&quot;REG_d&quot;               \n\t&quot; //xx+= xInc&gt;&gt;16 + carry
-                &quot;add        $1, %%&quot;REG_a&quot;               \n\t&quot;
-                &quot;cmp        %2, %%&quot;REG_a&quot;               \n\t&quot;
-                &quot; jb        1b                          \n\t&quot;
-
-/* GCC 3.3 makes MPlayer crash on IA-32 machines when using &quot;g&quot; operand here,
-   which is needed to support GCC 4.0. */
-#if ARCH_X86_64 &amp;&amp; ((__GNUC__ &gt; 3) || (__GNUC__ == 3 &amp;&amp; __GNUC_MINOR__ &gt;= 4))
-                :: &quot;m&quot; (src1), &quot;m&quot; (dst), &quot;g&quot; (dstWidth), &quot;m&quot; (xInc_shr16), &quot;m&quot; (xInc_mask),
-#else
-                :: &quot;m&quot; (src1), &quot;m&quot; (dst), &quot;m&quot; (dstWidth), &quot;m&quot; (xInc_shr16), &quot;m&quot; (xInc_mask),
-#endif
-                &quot;r&quot; (src2)
-                : &quot;%&quot;REG_a, &quot;%&quot;REG_d, &quot;%ecx&quot;, &quot;%&quot;REG_D, &quot;%esi&quot;
-            );
-#if COMPILE_TEMPLATE_MMX2
-        } //if MMX2 can't be used
-#endif
-#else
         c-&gt;hcscale_fast(c, dst, dstWidth, src1, src2, srcW, xInc);
-#endif /* ARCH_X86 */
     }
-    if(c-&gt;srcRange != c-&gt;dstRange &amp;&amp; !(isRGB(c-&gt;dstFormat) || isBGR(c-&gt;dstFormat))) {
-        int i;
-        //FIXME all pal and rgb srcFormats could do this convertion as well
-        //FIXME all scalers more complex than bilinear could do half of this transform
-        if(c-&gt;srcRange) {
-            for (i=0; i&lt;dstWidth; i++) {
-                dst[i     ]= (dst[i     ]*1799 + 4081085)&gt;&gt;11; //1469
-                dst[i+VOFW]= (dst[i+VOFW]*1799 + 4081085)&gt;&gt;11; //1469
-            }
-        } else {
-            for (i=0; i&lt;dstWidth; i++) {
-                dst[i     ]= (FFMIN(dst[i     ],30775)*4663 - 9289992)&gt;&gt;12; //-264
-                dst[i+VOFW]= (FFMIN(dst[i+VOFW],30775)*4663 - 9289992)&gt;&gt;12; //-264
-            }
-        }
-    }
+
+    if (c-&gt;chrConvertRange)
+        c-&gt;chrConvertRange(dst, dstWidth);
 }
 
-static int RENAME(swScale)(SwsContext *c, uint8_t* src[], int srcStride[], int srcSliceY,
+#define DEBUG_SWSCALE_BUFFERS 0
+#define DEBUG_BUFFERS(...) if (DEBUG_SWSCALE_BUFFERS) av_log(c, AV_LOG_DEBUG, __VA_ARGS__)
+
+static int RENAME(swScale)(SwsContext *c, const uint8_t* src[], int srcStride[], int srcSliceY,
                            int srcSliceH, uint8_t* dst[], int dstStride[])
 {
     /* load a few things into local vars to make the code more readable? and faster */
@@ -2540,8 +2565,7 @@
     const int chrSrcW= c-&gt;chrSrcW;
     const int lumXInc= c-&gt;lumXInc;
     const int chrXInc= c-&gt;chrXInc;
-    const int dstFormat= c-&gt;dstFormat;
-    const int srcFormat= c-&gt;srcFormat;
+    const enum PixelFormat dstFormat= c-&gt;dstFormat;
     const int flags= c-&gt;flags;
     int16_t *vLumFilterPos= c-&gt;vLumFilterPos;
     int16_t *vChrFilterPos= c-&gt;vChrFilterPos;
@@ -2553,7 +2577,7 @@
     int16_t *hChrFilter= c-&gt;hChrFilter;
     int32_t *lumMmxFilter= c-&gt;lumMmxFilter;
     int32_t *chrMmxFilter= c-&gt;chrMmxFilter;
-    int32_t *alpMmxFilter= c-&gt;alpMmxFilter;
+    int32_t av_unused *alpMmxFilter= c-&gt;alpMmxFilter;
     const int vLumFilterSize= c-&gt;vLumFilterSize;
     const int vChrFilterSize= c-&gt;vChrFilterSize;
     const int hLumFilterSize= c-&gt;hLumFilterSize;
@@ -2589,12 +2613,14 @@
     srcStride[1]&lt;&lt;= c-&gt;vChrDrop;
     srcStride[2]&lt;&lt;= c-&gt;vChrDrop;
 
-    //printf(&quot;swscale %X %X %X -&gt; %X %X %X\n&quot;, (int)src[0], (int)src[1], (int)src[2],
-    //       (int)dst[0], (int)dst[1], (int)dst[2]);
+    DEBUG_BUFFERS(&quot;swScale() %p[%d] %p[%d] %p[%d] %p[%d] -&gt; %p[%d] %p[%d] %p[%d] %p[%d]\n&quot;,
+                  src[0], srcStride[0], src[1], srcStride[1], src[2], srcStride[2], src[3], srcStride[3],
+                  dst[0], dstStride[0], dst[1], dstStride[1], dst[2], dstStride[2], dst[3], dstStride[3]);
+    DEBUG_BUFFERS(&quot;srcSliceY: %d srcSliceH: %d dstY: %d dstH: %d\n&quot;,
+                   srcSliceY,    srcSliceH,    dstY,    dstH);
+    DEBUG_BUFFERS(&quot;vLumFilterSize: %d vLumBufSize: %d vChrFilterSize: %d vChrBufSize: %d\n&quot;,
+                   vLumFilterSize,    vLumBufSize,    vChrFilterSize,    vChrBufSize);
 
-    //printf(&quot;sws Strides:%d %d %d -&gt; %d %d %d\n&quot;, srcStride[0],srcStride[1],srcStride[2],
-    //dstStride[0],dstStride[1],dstStride[2]);
-
     if (dstStride[0]%8 !=0 || dstStride[1]%8 !=0 || dstStride[2]%8 !=0 || dstStride[3]%8 != 0) {
         static int warnedAlready=0; //FIXME move this into the context perhaps
         if (flags &amp; SWS_PRINT_INFO &amp;&amp; !warnedAlready) {
@@ -2608,8 +2634,8 @@
        will not get executed. This is not really intended but works
        currently, so people might do it. */
     if (srcSliceY ==0) {
-        lumBufIndex=0;
-        chrBufIndex=0;
+        lumBufIndex=-1;
+        chrBufIndex=-1;
         dstY=0;
         lastInLumBuf= -1;
         lastInChrBuf= -1;
@@ -2630,63 +2656,65 @@
         int lastChrSrcY= firstChrSrcY + vChrFilterSize -1; // Last line needed as input
         int enough_lines;
 
-        //printf(&quot;dstY:%d dstH:%d firstLumSrcY:%d lastInLumBuf:%d vLumBufSize: %d vChrBufSize: %d slice: %d %d vLumFilterSize: %d firstChrSrcY: %d vChrFilterSize: %d c-&gt;chrSrcVSubSample: %d\n&quot;,
-        // dstY, dstH, firstLumSrcY, lastInLumBuf, vLumBufSize, vChrBufSize, srcSliceY, srcSliceH, vLumFilterSize, firstChrSrcY, vChrFilterSize,  c-&gt;chrSrcVSubSample);
         //handle holes (FAST_BILINEAR &amp; weird filters)
         if (firstLumSrcY &gt; lastInLumBuf) lastInLumBuf= firstLumSrcY-1;
         if (firstChrSrcY &gt; lastInChrBuf) lastInChrBuf= firstChrSrcY-1;
-        //printf(&quot;%d %d %d\n&quot;, firstChrSrcY, lastInChrBuf, vChrBufSize);
         assert(firstLumSrcY &gt;= lastInLumBuf - vLumBufSize + 1);
         assert(firstChrSrcY &gt;= lastInChrBuf - vChrBufSize + 1);
 
+        DEBUG_BUFFERS(&quot;dstY: %d\n&quot;, dstY);
+        DEBUG_BUFFERS(&quot;\tfirstLumSrcY: %d lastLumSrcY: %d lastInLumBuf: %d\n&quot;,
+                         firstLumSrcY,    lastLumSrcY,    lastInLumBuf);
+        DEBUG_BUFFERS(&quot;\tfirstChrSrcY: %d lastChrSrcY: %d lastInChrBuf: %d\n&quot;,
+                         firstChrSrcY,    lastChrSrcY,    lastInChrBuf);
+
         // Do we have enough lines in this slice to output the dstY line
         enough_lines = lastLumSrcY &lt; srcSliceY + srcSliceH &amp;&amp; lastChrSrcY &lt; -((-srcSliceY - srcSliceH)&gt;&gt;c-&gt;chrSrcVSubSample);
         if (!enough_lines) {
             lastLumSrcY = srcSliceY + srcSliceH - 1;
             lastChrSrcY = chrSrcSliceY + chrSrcSliceH - 1;
+            DEBUG_BUFFERS(&quot;buffering slice: lastLumSrcY %d lastChrSrcY %d\n&quot;,
+                                            lastLumSrcY, lastChrSrcY);
         }
 
-        /* printf(&quot;%d %d Last:%d %d LastInBuf:%d %d Index:%d %d Y:%d FSize: %d %d BSize: %d %d\n&quot;,
-        firstChrSrcY,firstLumSrcY,lastChrSrcY,lastLumSrcY,
-        lastInChrBuf,lastInLumBuf,chrBufIndex,lumBufIndex,dstY,vChrFilterSize,vLumFilterSize,
-        vChrBufSize, vLumBufSize);*/
-
         //Do horizontal scaling
         while(lastInLumBuf &lt; lastLumSrcY) {
-            uint8_t *src1= src[0]+(lastInLumBuf + 1 - srcSliceY)*srcStride[0];
-            uint8_t *src2= src[3]+(lastInLumBuf + 1 - srcSliceY)*srcStride[3];
+            const uint8_t *src1= src[0]+(lastInLumBuf + 1 - srcSliceY)*srcStride[0];
+            const uint8_t *src2= src[3]+(lastInLumBuf + 1 - srcSliceY)*srcStride[3];
             lumBufIndex++;
-            //printf(&quot;%d %d %d %d\n&quot;, lumBufIndex, vLumBufSize, lastInLumBuf,  lastLumSrcY);
             assert(lumBufIndex &lt; 2*vLumBufSize);
             assert(lastInLumBuf + 1 - srcSliceY &lt; srcSliceH);
             assert(lastInLumBuf + 1 - srcSliceY &gt;= 0);
-            //printf(&quot;%d %d\n&quot;, lumBufIndex, vLumBufSize);
             RENAME(hyscale)(c, lumPixBuf[ lumBufIndex ], dstW, src1, srcW, lumXInc,
-                            flags, hLumFilter, hLumFilterPos, hLumFilterSize,
-                            c-&gt;srcFormat, formatConvBuffer,
+                            hLumFilter, hLumFilterPos, hLumFilterSize,
+                            formatConvBuffer,
                             pal, 0);
             if (CONFIG_SWSCALE_ALPHA &amp;&amp; alpPixBuf)
                 RENAME(hyscale)(c, alpPixBuf[ lumBufIndex ], dstW, src2, srcW, lumXInc,
-                                flags, hLumFilter, hLumFilterPos, hLumFilterSize,
-                                c-&gt;srcFormat, formatConvBuffer,
+                                hLumFilter, hLumFilterPos, hLumFilterSize,
+                                formatConvBuffer,
                                 pal, 1);
             lastInLumBuf++;
+            DEBUG_BUFFERS(&quot;\t\tlumBufIndex %d: lastInLumBuf: %d\n&quot;,
+                               lumBufIndex,    lastInLumBuf);
         }
         while(lastInChrBuf &lt; lastChrSrcY) {
-            uint8_t *src1= src[1]+(lastInChrBuf + 1 - chrSrcSliceY)*srcStride[1];
-            uint8_t *src2= src[2]+(lastInChrBuf + 1 - chrSrcSliceY)*srcStride[2];
+            const uint8_t *src1= src[1]+(lastInChrBuf + 1 - chrSrcSliceY)*srcStride[1];
+            const uint8_t *src2= src[2]+(lastInChrBuf + 1 - chrSrcSliceY)*srcStride[2];
             chrBufIndex++;
             assert(chrBufIndex &lt; 2*vChrBufSize);
             assert(lastInChrBuf + 1 - chrSrcSliceY &lt; (chrSrcSliceH));
             assert(lastInChrBuf + 1 - chrSrcSliceY &gt;= 0);
             //FIXME replace parameters through context struct (some at least)
 
-            if (!(isGray(srcFormat) || isGray(dstFormat)))
+            if (c-&gt;needs_hcscale)
                 RENAME(hcscale)(c, chrPixBuf[ chrBufIndex ], chrDstW, src1, src2, chrSrcW, chrXInc,
-                                flags, hChrFilter, hChrFilterPos, hChrFilterSize,
-                                c-&gt;srcFormat, formatConvBuffer,
+                                hChrFilter, hChrFilterPos, hChrFilterSize,
+                                formatConvBuffer,
                                 pal);
             lastInChrBuf++;
+            DEBUG_BUFFERS(&quot;\t\tchrBufIndex %d: lastInChrBuf: %d\n&quot;,
+                               chrBufIndex,    lastInChrBuf);
         }
         //wrap buf index around to stay inside the ring buffer
         if (lumBufIndex &gt;= vLumBufSize) lumBufIndex-= vLumBufSize;
@@ -2711,21 +2739,21 @@
             if (flags &amp; SWS_ACCURATE_RND) {
                 int s= APCK_SIZE / 8;
                 for (i=0; i&lt;vLumFilterSize; i+=2) {
-                    *(void**)&amp;lumMmxFilter[s*i              ]= lumSrcPtr[i  ];
-                    *(void**)&amp;lumMmxFilter[s*i+APCK_PTR2/4  ]= lumSrcPtr[i+(vLumFilterSize&gt;1)];
+                    *(const void**)&amp;lumMmxFilter[s*i              ]= lumSrcPtr[i  ];
+                    *(const void**)&amp;lumMmxFilter[s*i+APCK_PTR2/4  ]= lumSrcPtr[i+(vLumFilterSize&gt;1)];
                               lumMmxFilter[s*i+APCK_COEF/4  ]=
                               lumMmxFilter[s*i+APCK_COEF/4+1]= vLumFilter[dstY*vLumFilterSize + i    ]
                         + (vLumFilterSize&gt;1 ? vLumFilter[dstY*vLumFilterSize + i + 1]&lt;&lt;16 : 0);
                     if (CONFIG_SWSCALE_ALPHA &amp;&amp; alpPixBuf) {
-                        *(void**)&amp;alpMmxFilter[s*i              ]= alpSrcPtr[i  ];
-                        *(void**)&amp;alpMmxFilter[s*i+APCK_PTR2/4  ]= alpSrcPtr[i+(vLumFilterSize&gt;1)];
+                        *(const void**)&amp;alpMmxFilter[s*i              ]= alpSrcPtr[i  ];
+                        *(const void**)&amp;alpMmxFilter[s*i+APCK_PTR2/4  ]= alpSrcPtr[i+(vLumFilterSize&gt;1)];
                                   alpMmxFilter[s*i+APCK_COEF/4  ]=
                                   alpMmxFilter[s*i+APCK_COEF/4+1]= lumMmxFilter[s*i+APCK_COEF/4  ];
                     }
                 }
                 for (i=0; i&lt;vChrFilterSize; i+=2) {
-                    *(void**)&amp;chrMmxFilter[s*i              ]= chrSrcPtr[i  ];
-                    *(void**)&amp;chrMmxFilter[s*i+APCK_PTR2/4  ]= chrSrcPtr[i+(vChrFilterSize&gt;1)];
+                    *(const void**)&amp;chrMmxFilter[s*i              ]= chrSrcPtr[i  ];
+                    *(const void**)&amp;chrMmxFilter[s*i+APCK_PTR2/4  ]= chrSrcPtr[i+(vChrFilterSize&gt;1)];
                               chrMmxFilter[s*i+APCK_COEF/4  ]=
                               chrMmxFilter[s*i+APCK_COEF/4+1]= vChrFilter[chrDstY*vChrFilterSize + i    ]
                         + (vChrFilterSize&gt;1 ? vChrFilter[chrDstY*vChrFilterSize + i + 1]&lt;&lt;16 : 0);
@@ -2770,9 +2798,9 @@
                                   alpSrcPtr, (uint16_t *) dest, (uint16_t *) uDest, (uint16_t *) vDest, (uint16_t *) aDest, dstW, chrDstW,
                                   dstFormat);
                 } else if (vLumFilterSize == 1 &amp;&amp; vChrFilterSize == 1) { // unscaled YV12
-                    int16_t *lumBuf = lumPixBuf[0];
-                    int16_t *chrBuf= chrPixBuf[0];
-                    int16_t *alpBuf= (CONFIG_SWSCALE_ALPHA &amp;&amp; alpPixBuf) ? alpPixBuf[0] : NULL;
+                    const int16_t *lumBuf = lumSrcPtr[0];
+                    const int16_t *chrBuf= chrSrcPtr[0];
+                    const int16_t *alpBuf= (CONFIG_SWSCALE_ALPHA &amp;&amp; alpPixBuf) ? alpSrcPtr[0] : NULL;
                     c-&gt;yuv2yuv1(c, lumBuf, chrBuf, alpBuf, dest, uDest, vDest, aDest, dstW, chrDstW);
                 } else { //General YV12
                     c-&gt;yuv2yuvX(c,
@@ -2902,96 +2930,137 @@
 
     c-&gt;hScale       = RENAME(hScale      );
 
-    c-&gt;hyscale_fast = RENAME(hyscale_fast);
-    c-&gt;hcscale_fast = RENAME(hcscale_fast);
+#if COMPILE_TEMPLATE_MMX
+    // Use the new MMX scaler if the MMX2 one can't be used (it is faster than the x86 ASM one).
+    if (c-&gt;flags &amp; SWS_FAST_BILINEAR &amp;&amp; c-&gt;canMMX2BeUsed)
+#else
+    if (c-&gt;flags &amp; SWS_FAST_BILINEAR)
+#endif
+    {
+        c-&gt;hyscale_fast = RENAME(hyscale_fast);
+        c-&gt;hcscale_fast = RENAME(hcscale_fast);
+    }
 
-    c-&gt;hcscale_internal = NULL;
+    c-&gt;chrToYV12 = NULL;
     switch(srcFormat) {
-        case PIX_FMT_YUYV422  : c-&gt;hcscale_internal = RENAME(yuy2ToUV); break;
-        case PIX_FMT_UYVY422  : c-&gt;hcscale_internal = RENAME(uyvyToUV); break;
+        case PIX_FMT_YUYV422  : c-&gt;chrToYV12 = RENAME(yuy2ToUV); break;
+        case PIX_FMT_UYVY422  : c-&gt;chrToYV12 = RENAME(uyvyToUV); break;
+        case PIX_FMT_NV12     : c-&gt;chrToYV12 = RENAME(nv12ToUV); break;
+        case PIX_FMT_NV21     : c-&gt;chrToYV12 = RENAME(nv21ToUV); break;
         case PIX_FMT_RGB8     :
         case PIX_FMT_BGR8     :
         case PIX_FMT_PAL8     :
         case PIX_FMT_BGR4_BYTE:
-        case PIX_FMT_RGB4_BYTE: c-&gt;hcscale_internal = palToUV; break;
-        case PIX_FMT_YUV420PBE:
-        case PIX_FMT_YUV422PBE:
-        case PIX_FMT_YUV444PBE: c-&gt;hcscale_internal = RENAME(BEToUV); break;
-        case PIX_FMT_YUV420PLE:
-        case PIX_FMT_YUV422PLE:
-        case PIX_FMT_YUV444PLE: c-&gt;hcscale_internal = RENAME(LEToUV); break;
+        case PIX_FMT_RGB4_BYTE: c-&gt;chrToYV12 = palToUV; break;
+        case PIX_FMT_YUV420P16BE:
+        case PIX_FMT_YUV422P16BE:
+        case PIX_FMT_YUV444P16BE: c-&gt;chrToYV12 = RENAME(BEToUV); break;
+        case PIX_FMT_YUV420P16LE:
+        case PIX_FMT_YUV422P16LE:
+        case PIX_FMT_YUV444P16LE: c-&gt;chrToYV12 = RENAME(LEToUV); break;
     }
     if (c-&gt;chrSrcHSubSample) {
         switch(srcFormat) {
         case PIX_FMT_RGB48BE:
-        case PIX_FMT_RGB48LE: c-&gt;hcscale_internal = rgb48ToUV_half; break;
+        case PIX_FMT_RGB48LE: c-&gt;chrToYV12 = rgb48ToUV_half; break;
         case PIX_FMT_RGB32  :
-        case PIX_FMT_RGB32_1: c-&gt;hcscale_internal = bgr32ToUV_half; break;
-        case PIX_FMT_BGR24  : c-&gt;hcscale_internal = RENAME(bgr24ToUV_half); break;
-        case PIX_FMT_BGR565 : c-&gt;hcscale_internal = bgr16ToUV_half; break;
-        case PIX_FMT_BGR555 : c-&gt;hcscale_internal = bgr15ToUV_half; break;
+        case PIX_FMT_RGB32_1: c-&gt;chrToYV12 = bgr32ToUV_half; break;
+        case PIX_FMT_BGR24  : c-&gt;chrToYV12 = RENAME(bgr24ToUV_half); break;
+        case PIX_FMT_BGR565 : c-&gt;chrToYV12 = bgr16ToUV_half; break;
+        case PIX_FMT_BGR555 : c-&gt;chrToYV12 = bgr15ToUV_half; break;
         case PIX_FMT_BGR32  :
-        case PIX_FMT_BGR32_1: c-&gt;hcscale_internal = rgb32ToUV_half; break;
-        case PIX_FMT_RGB24  : c-&gt;hcscale_internal = RENAME(rgb24ToUV_half); break;
-        case PIX_FMT_RGB565 : c-&gt;hcscale_internal = rgb16ToUV_half; break;
-        case PIX_FMT_RGB555 : c-&gt;hcscale_internal = rgb15ToUV_half; break;
+        case PIX_FMT_BGR32_1: c-&gt;chrToYV12 = rgb32ToUV_half; break;
+        case PIX_FMT_RGB24  : c-&gt;chrToYV12 = RENAME(rgb24ToUV_half); break;
+        case PIX_FMT_RGB565 : c-&gt;chrToYV12 = rgb16ToUV_half; break;
+        case PIX_FMT_RGB555 : c-&gt;chrToYV12 = rgb15ToUV_half; break;
         }
     } else {
         switch(srcFormat) {
         case PIX_FMT_RGB48BE:
-        case PIX_FMT_RGB48LE: c-&gt;hcscale_internal = rgb48ToUV; break;
+        case PIX_FMT_RGB48LE: c-&gt;chrToYV12 = rgb48ToUV; break;
         case PIX_FMT_RGB32  :
-        case PIX_FMT_RGB32_1: c-&gt;hcscale_internal = bgr32ToUV; break;
-        case PIX_FMT_BGR24  : c-&gt;hcscale_internal = RENAME(bgr24ToUV); break;
-        case PIX_FMT_BGR565 : c-&gt;hcscale_internal = bgr16ToUV; break;
-        case PIX_FMT_BGR555 : c-&gt;hcscale_internal = bgr15ToUV; break;
+        case PIX_FMT_RGB32_1: c-&gt;chrToYV12 = bgr32ToUV; break;
+        case PIX_FMT_BGR24  : c-&gt;chrToYV12 = RENAME(bgr24ToUV); break;
+        case PIX_FMT_BGR565 : c-&gt;chrToYV12 = bgr16ToUV; break;
+        case PIX_FMT_BGR555 : c-&gt;chrToYV12 = bgr15ToUV; break;
         case PIX_FMT_BGR32  :
-        case PIX_FMT_BGR32_1: c-&gt;hcscale_internal = rgb32ToUV; break;
-        case PIX_FMT_RGB24  : c-&gt;hcscale_internal = RENAME(rgb24ToUV); break;
-        case PIX_FMT_RGB565 : c-&gt;hcscale_internal = rgb16ToUV; break;
-        case PIX_FMT_RGB555 : c-&gt;hcscale_internal = rgb15ToUV; break;
+        case PIX_FMT_BGR32_1: c-&gt;chrToYV12 = rgb32ToUV; break;
+        case PIX_FMT_RGB24  : c-&gt;chrToYV12 = RENAME(rgb24ToUV); break;
+        case PIX_FMT_RGB565 : c-&gt;chrToYV12 = rgb16ToUV; break;
+        case PIX_FMT_RGB555 : c-&gt;chrToYV12 = rgb15ToUV; break;
         }
     }
 
-    c-&gt;hyscale_internal = NULL;
-    c-&gt;hascale_internal = NULL;
+    c-&gt;lumToYV12 = NULL;
+    c-&gt;alpToYV12 = NULL;
     switch (srcFormat) {
     case PIX_FMT_YUYV422  :
-    case PIX_FMT_YUV420PBE:
-    case PIX_FMT_YUV422PBE:
-    case PIX_FMT_YUV444PBE:
-    case PIX_FMT_GRAY16BE : c-&gt;hyscale_internal = RENAME(yuy2ToY); break;
+    case PIX_FMT_YUV420P16BE:
+    case PIX_FMT_YUV422P16BE:
+    case PIX_FMT_YUV444P16BE:
+    case PIX_FMT_GRAY16BE : c-&gt;lumToYV12 = RENAME(yuy2ToY); break;
     case PIX_FMT_UYVY422  :
-    case PIX_FMT_YUV420PLE:
-    case PIX_FMT_YUV422PLE:
-    case PIX_FMT_YUV444PLE:
-    case PIX_FMT_GRAY16LE : c-&gt;hyscale_internal = RENAME(uyvyToY); break;
-    case PIX_FMT_BGR24    : c-&gt;hyscale_internal = RENAME(bgr24ToY); break;
-    case PIX_FMT_BGR565   : c-&gt;hyscale_internal = bgr16ToY; break;
-    case PIX_FMT_BGR555   : c-&gt;hyscale_internal = bgr15ToY; break;
-    case PIX_FMT_RGB24    : c-&gt;hyscale_internal = RENAME(rgb24ToY); break;
-    case PIX_FMT_RGB565   : c-&gt;hyscale_internal = rgb16ToY; break;
-    case PIX_FMT_RGB555   : c-&gt;hyscale_internal = rgb15ToY; break;
+    case PIX_FMT_YUV420P16LE:
+    case PIX_FMT_YUV422P16LE:
+    case PIX_FMT_YUV444P16LE:
+    case PIX_FMT_GRAY16LE : c-&gt;lumToYV12 = RENAME(uyvyToY); break;
+    case PIX_FMT_BGR24    : c-&gt;lumToYV12 = RENAME(bgr24ToY); break;
+    case PIX_FMT_BGR565   : c-&gt;lumToYV12 = bgr16ToY; break;
+    case PIX_FMT_BGR555   : c-&gt;lumToYV12 = bgr15ToY; break;
+    case PIX_FMT_RGB24    : c-&gt;lumToYV12 = RENAME(rgb24ToY); break;
+    case PIX_FMT_RGB565   : c-&gt;lumToYV12 = rgb16ToY; break;
+    case PIX_FMT_RGB555   : c-&gt;lumToYV12 = rgb15ToY; break;
     case PIX_FMT_RGB8     :
     case PIX_FMT_BGR8     :
     case PIX_FMT_PAL8     :
     case PIX_FMT_BGR4_BYTE:
-    case PIX_FMT_RGB4_BYTE: c-&gt;hyscale_internal = palToY; break;
-    case PIX_FMT_MONOBLACK: c-&gt;hyscale_internal = monoblack2Y; break;
-    case PIX_FMT_MONOWHITE: c-&gt;hyscale_internal = monowhite2Y; break;
+    case PIX_FMT_RGB4_BYTE: c-&gt;lumToYV12 = palToY; break;
+    case PIX_FMT_MONOBLACK: c-&gt;lumToYV12 = monoblack2Y; break;
+    case PIX_FMT_MONOWHITE: c-&gt;lumToYV12 = monowhite2Y; break;
     case PIX_FMT_RGB32  :
-    case PIX_FMT_RGB32_1: c-&gt;hyscale_internal = bgr32ToY; break;
+    case PIX_FMT_RGB32_1: c-&gt;lumToYV12 = bgr32ToY; break;
     case PIX_FMT_BGR32  :
-    case PIX_FMT_BGR32_1: c-&gt;hyscale_internal = rgb32ToY; break;
+    case PIX_FMT_BGR32_1: c-&gt;lumToYV12 = rgb32ToY; break;
     case PIX_FMT_RGB48BE:
-    case PIX_FMT_RGB48LE: c-&gt;hyscale_internal = rgb48ToY; break;
+    case PIX_FMT_RGB48LE: c-&gt;lumToYV12 = rgb48ToY; break;
     }
     if (c-&gt;alpPixBuf) {
         switch (srcFormat) {
         case PIX_FMT_RGB32  :
         case PIX_FMT_RGB32_1:
         case PIX_FMT_BGR32  :
-        case PIX_FMT_BGR32_1: c-&gt;hascale_internal = abgrToA; break;
+        case PIX_FMT_BGR32_1: c-&gt;alpToYV12 = abgrToA; break;
         }
     }
+
+    switch (srcFormat) {
+    case PIX_FMT_RGB32  :
+    case PIX_FMT_BGR32  :
+        c-&gt;alpSrcOffset = 3;
+        break;
+    case PIX_FMT_RGB32_1:
+    case PIX_FMT_BGR32_1:
+        c-&gt;lumSrcOffset = ALT32_CORR;
+        c-&gt;chrSrcOffset = ALT32_CORR;
+        break;
+    case PIX_FMT_RGB48LE:
+        c-&gt;lumSrcOffset = 1;
+        c-&gt;chrSrcOffset = 1;
+        c-&gt;alpSrcOffset = 1;
+        break;
+    }
+
+    if (c-&gt;srcRange != c-&gt;dstRange &amp;&amp; !isAnyRGB(c-&gt;dstFormat)) {
+        if (c-&gt;srcRange) {
+            c-&gt;lumConvertRange = RENAME(lumRangeFromJpeg);
+            c-&gt;chrConvertRange = RENAME(chrRangeFromJpeg);
+        } else {
+            c-&gt;lumConvertRange = RENAME(lumRangeToJpeg);
+            c-&gt;chrConvertRange = RENAME(chrRangeToJpeg);
+        }
+    }
+
+    if (!(isGray(srcFormat) || isGray(c-&gt;dstFormat) ||
+          srcFormat == PIX_FMT_MONOBLACK || srcFormat == PIX_FMT_MONOWHITE))
+        c-&gt;needs_hcscale = 1;
 }

Added: branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/utils.c
===================================================================
--- branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/utils.c	2010-05-26 05:26:42 UTC (rev 6237)
+++ branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/utils.c	2010-05-26 05:26:46 UTC (rev 6238)
@@ -0,0 +1,1590 @@
+/*
+ * Copyright (C) 2001-2003 Michael Niedermayer &lt;<A HREF="https://lists.berlios.de/mailman/listinfo/avidemux-svn-commit">michaelni at gmx.at</A>&gt;
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ *
+ * the C code (not assembly, mmx, ...) of this file can be used
+ * under the LGPL license too
+ */
+
+#define _SVID_SOURCE //needed for MAP_ANONYMOUS
+#include &lt;inttypes.h&gt;
+#include &lt;string.h&gt;
+#include &lt;math.h&gt;
+#include &lt;stdio.h&gt;
+#include &quot;config.h&quot;
+#include &lt;assert.h&gt;
+#if HAVE_SYS_MMAN_H
+#include &lt;sys/mman.h&gt;
+#if defined(MAP_ANON) &amp;&amp; !defined(MAP_ANONYMOUS)
+#define MAP_ANONYMOUS MAP_ANON
+#endif
+#endif
+#if HAVE_VIRTUALALLOC
+#define WIN32_LEAN_AND_MEAN
+#include &lt;windows.h&gt;
+#endif
+#include &quot;swscale.h&quot;
+#include &quot;swscale_internal.h&quot;
+#include &quot;rgb2rgb.h&quot;
+#include &quot;libavutil/intreadwrite.h&quot;
+#include &quot;libavutil/x86_cpu.h&quot;
+#include &quot;libavutil/avutil.h&quot;
+#include &quot;libavutil/bswap.h&quot;
+#include &quot;libavutil/pixdesc.h&quot;
+
+unsigned swscale_version(void)
+{
+    return LIBSWSCALE_VERSION_INT;
+}
+
+const char *swscale_configuration(void)
+{
+    return &quot;avidemux&quot;;//FFMPEG_CONFIGURATION;
+}
+
+const char *swscale_license(void)
+{
+#define LICENSE_PREFIX &quot;libswscale license: &quot;
+    return LICENSE_PREFIX &quot;GPL&quot;; //FFMPEG_LICENSE + sizeof(LICENSE_PREFIX) - 1;
+}
+
+#define RET 0xC3 //near return opcode for x86
+
+#define isSupportedIn(x)    (       \
+           (x)==PIX_FMT_YUV420P     \
+        || (x)==PIX_FMT_YUVA420P    \
+        || (x)==PIX_FMT_YUYV422     \
+        || (x)==PIX_FMT_UYVY422     \
+        || (x)==PIX_FMT_RGB48BE     \
+        || (x)==PIX_FMT_RGB48LE     \
+        || (x)==PIX_FMT_RGB32       \
+        || (x)==PIX_FMT_RGB32_1     \
+        || (x)==PIX_FMT_BGR24       \
+        || (x)==PIX_FMT_BGR565      \
+        || (x)==PIX_FMT_BGR555      \
+        || (x)==PIX_FMT_BGR32       \
+        || (x)==PIX_FMT_BGR32_1     \
+        || (x)==PIX_FMT_RGB24       \
+        || (x)==PIX_FMT_RGB565      \
+        || (x)==PIX_FMT_RGB555      \
+        || (x)==PIX_FMT_GRAY8       \
+        || (x)==PIX_FMT_YUV410P     \
+        || (x)==PIX_FMT_YUV440P     \
+        || (x)==PIX_FMT_NV12        \
+        || (x)==PIX_FMT_NV21        \
+        || (x)==PIX_FMT_GRAY16BE    \
+        || (x)==PIX_FMT_GRAY16LE    \
+        || (x)==PIX_FMT_YUV444P     \
+        || (x)==PIX_FMT_YUV422P     \
+        || (x)==PIX_FMT_YUV411P     \
+        || (x)==PIX_FMT_YUVJ420P    \
+        || (x)==PIX_FMT_YUVJ422P    \
+        || (x)==PIX_FMT_YUVJ440P    \
+        || (x)==PIX_FMT_YUVJ444P    \
+        || (x)==PIX_FMT_PAL8        \
+        || (x)==PIX_FMT_BGR8        \
+        || (x)==PIX_FMT_RGB8        \
+        || (x)==PIX_FMT_BGR4_BYTE   \
+        || (x)==PIX_FMT_RGB4_BYTE   \
+        || (x)==PIX_FMT_YUV440P     \
+        || (x)==PIX_FMT_MONOWHITE   \
+        || (x)==PIX_FMT_MONOBLACK   \
+        || (x)==PIX_FMT_YUV420P16LE   \
+        || (x)==PIX_FMT_YUV422P16LE   \
+        || (x)==PIX_FMT_YUV444P16LE   \
+        || (x)==PIX_FMT_YUV420P16BE   \
+        || (x)==PIX_FMT_YUV422P16BE   \
+        || (x)==PIX_FMT_YUV444P16BE   \
+    )
+
+int sws_isSupportedInput(enum PixelFormat pix_fmt)
+{
+    return isSupportedIn(pix_fmt);
+}
+
+#define isSupportedOut(x)   (       \
+           (x)==PIX_FMT_YUV420P     \
+        || (x)==PIX_FMT_YUVA420P    \
+        || (x)==PIX_FMT_YUYV422     \
+        || (x)==PIX_FMT_UYVY422     \
+        || (x)==PIX_FMT_YUV444P     \
+        || (x)==PIX_FMT_YUV422P     \
+        || (x)==PIX_FMT_YUV411P     \
+        || (x)==PIX_FMT_YUVJ420P    \
+        || (x)==PIX_FMT_YUVJ422P    \
+        || (x)==PIX_FMT_YUVJ440P    \
+        || (x)==PIX_FMT_YUVJ444P    \
+        || isAnyRGB(x)              \
+        || (x)==PIX_FMT_NV12        \
+        || (x)==PIX_FMT_NV21        \
+        || (x)==PIX_FMT_GRAY16BE    \
+        || (x)==PIX_FMT_GRAY16LE    \
+        || (x)==PIX_FMT_GRAY8       \
+        || (x)==PIX_FMT_YUV410P     \
+        || (x)==PIX_FMT_YUV440P     \
+        || (x)==PIX_FMT_YUV420P16LE   \
+        || (x)==PIX_FMT_YUV422P16LE   \
+        || (x)==PIX_FMT_YUV444P16LE   \
+        || (x)==PIX_FMT_YUV420P16BE   \
+        || (x)==PIX_FMT_YUV422P16BE   \
+        || (x)==PIX_FMT_YUV444P16BE   \
+    )
+
+int sws_isSupportedOutput(enum PixelFormat pix_fmt)
+{
+    return isSupportedOut(pix_fmt);
+}
+
+#define usePal(x) (av_pix_fmt_descriptors[x].flags &amp; PIX_FMT_PAL)
+
+extern const int32_t ff_yuv2rgb_coeffs[8][4];
+
+const char *sws_format_name(enum PixelFormat format)
+{
+    if ((unsigned)format &lt; PIX_FMT_NB &amp;&amp; av_pix_fmt_descriptors[format].name)
+        return av_pix_fmt_descriptors[format].name;
+    else
+        return &quot;Unknown format&quot;;
+}
+
+static double getSplineCoeff(double a, double b, double c, double d, double dist)
+{
+//    printf(&quot;%f %f %f %f %f\n&quot;, a,b,c,d,dist);
+    if (dist&lt;=1.0) return ((d*dist + c)*dist + b)*dist +a;
+    else           return getSplineCoeff(        0.0,
+                                          b+ 2.0*c + 3.0*d,
+                                                 c + 3.0*d,
+                                         -b- 3.0*c - 6.0*d,
+                                         dist-1.0);
+}
+
+static int initFilter(int16_t **outFilter, int16_t **filterPos, int *outFilterSize, int xInc,
+                      int srcW, int dstW, int filterAlign, int one, int flags,
+                      SwsVector *srcFilter, SwsVector *dstFilter, double param[2])
+{
+    int i;
+    int filterSize;
+    int filter2Size;
+    int minFilterSize;
+    int64_t *filter=NULL;
+    int64_t *filter2=NULL;
+    const int64_t fone= 1LL&lt;&lt;54;
+    int ret= -1;
+#if ARCH_X86
+    if (flags &amp; SWS_CPU_CAPS_MMX)
+        __asm__ volatile(&quot;emms\n\t&quot;::: &quot;memory&quot;); //FIXME this should not be required but it IS (even for non-MMX versions)
+#endif
+
+    // NOTE: the +1 is for the MMX scaler which reads over the end
+    FF_ALLOC_OR_GOTO(NULL, *filterPos, (dstW+1)*sizeof(int16_t), fail);
+
+    if (FFABS(xInc - 0x10000) &lt;10) { // unscaled
+        int i;
+        filterSize= 1;
+        FF_ALLOCZ_OR_GOTO(NULL, filter, dstW*sizeof(*filter)*filterSize, fail);
+
+        for (i=0; i&lt;dstW; i++) {
+            filter[i*filterSize]= fone;
+            (*filterPos)[i]=i;
+        }
+
+    } else if (flags&amp;SWS_POINT) { // lame looking point sampling mode
+        int i;
+        int xDstInSrc;
+        filterSize= 1;
+        FF_ALLOC_OR_GOTO(NULL, filter, dstW*sizeof(*filter)*filterSize, fail);
+
+        xDstInSrc= xInc/2 - 0x8000;
+        for (i=0; i&lt;dstW; i++) {
+            int xx= (xDstInSrc - ((filterSize-1)&lt;&lt;15) + (1&lt;&lt;15))&gt;&gt;16;
+
+            (*filterPos)[i]= xx;
+            filter[i]= fone;
+            xDstInSrc+= xInc;
+        }
+    } else if ((xInc &lt;= (1&lt;&lt;16) &amp;&amp; (flags&amp;SWS_AREA)) || (flags&amp;SWS_FAST_BILINEAR)) { // bilinear upscale
+        int i;
+        int xDstInSrc;
+        filterSize= 2;
+        FF_ALLOC_OR_GOTO(NULL, filter, dstW*sizeof(*filter)*filterSize, fail);
+
+        xDstInSrc= xInc/2 - 0x8000;
+        for (i=0; i&lt;dstW; i++) {
+            int xx= (xDstInSrc - ((filterSize-1)&lt;&lt;15) + (1&lt;&lt;15))&gt;&gt;16;
+            int j;
+
+            (*filterPos)[i]= xx;
+            //bilinear upscale / linear interpolate / area averaging
+            for (j=0; j&lt;filterSize; j++) {
+                int64_t coeff= fone - FFABS((xx&lt;&lt;16) - xDstInSrc)*(fone&gt;&gt;16);
+                if (coeff&lt;0) coeff=0;
+                filter[i*filterSize + j]= coeff;
+                xx++;
+            }
+            xDstInSrc+= xInc;
+        }
+    } else {
+        int xDstInSrc;
+        int sizeFactor;
+
+        if      (flags&amp;SWS_BICUBIC)      sizeFactor=  4;
+        else if (flags&amp;SWS_X)            sizeFactor=  8;
+        else if (flags&amp;SWS_AREA)         sizeFactor=  1; //downscale only, for upscale it is bilinear
+        else if (flags&amp;SWS_GAUSS)        sizeFactor=  8;   // infinite ;)
+        else if (flags&amp;SWS_LANCZOS)      sizeFactor= param[0] != SWS_PARAM_DEFAULT ? ceil(2*param[0]) : 6;
+        else if (flags&amp;SWS_SINC)         sizeFactor= 20; // infinite ;)
+        else if (flags&amp;SWS_SPLINE)       sizeFactor= 20;  // infinite ;)
+        else if (flags&amp;SWS_BILINEAR)     sizeFactor=  2;
+        else {
+            sizeFactor= 0; //GCC warning killer
+            assert(0);
+        }
+
+        if (xInc &lt;= 1&lt;&lt;16)      filterSize= 1 + sizeFactor; // upscale
+        else                    filterSize= 1 + (sizeFactor*srcW + dstW - 1)/ dstW;
+
+        if (filterSize &gt; srcW-2) filterSize=srcW-2;
+
+        FF_ALLOC_OR_GOTO(NULL, filter, dstW*sizeof(*filter)*filterSize, fail);
+
+        xDstInSrc= xInc - 0x10000;
+        for (i=0; i&lt;dstW; i++) {
+            int xx= (xDstInSrc - ((filterSize-2)&lt;&lt;16)) / (1&lt;&lt;17);
+            int j;
+            (*filterPos)[i]= xx;
+            for (j=0; j&lt;filterSize; j++) {
+                int64_t d= ((int64_t)FFABS((xx&lt;&lt;17) - xDstInSrc))&lt;&lt;13;
+                double floatd;
+                int64_t coeff;
+
+                if (xInc &gt; 1&lt;&lt;16)
+                    d= d*dstW/srcW;
+                floatd= d * (1.0/(1&lt;&lt;30));
+
+                if (flags &amp; SWS_BICUBIC) {
+                    int64_t B= (param[0] != SWS_PARAM_DEFAULT ? param[0] :   0) * (1&lt;&lt;24);
+                    int64_t C= (param[1] != SWS_PARAM_DEFAULT ? param[1] : 0.6) * (1&lt;&lt;24);
+                    int64_t dd = ( d*d)&gt;&gt;30;
+                    int64_t ddd= (dd*d)&gt;&gt;30;
+
+                    if      (d &lt; 1LL&lt;&lt;30)
+                        coeff = (12*(1&lt;&lt;24)-9*B-6*C)*ddd + (-18*(1&lt;&lt;24)+12*B+6*C)*dd + (6*(1&lt;&lt;24)-2*B)*(1&lt;&lt;30);
+                    else if (d &lt; 1LL&lt;&lt;31)
+                        coeff = (-B-6*C)*ddd + (6*B+30*C)*dd + (-12*B-48*C)*d + (8*B+24*C)*(1&lt;&lt;30);
+                    else
+                        coeff=0.0;
+                    coeff *= fone&gt;&gt;(30+24);
+                }
+/*                else if (flags &amp; SWS_X) {
+                    double p= param ? param*0.01 : 0.3;
+                    coeff = d ? sin(d*PI)/(d*PI) : 1.0;
+                    coeff*= pow(2.0, - p*d*d);
+                }*/
+                else if (flags &amp; SWS_X) {
+                    double A= param[0] != SWS_PARAM_DEFAULT ? param[0] : 1.0;
+                    double c;
+
+                    if (floatd&lt;1.0)
+                        c = cos(floatd*M_PI);
+                    else
+                        c=-1.0;
+                    if (c&lt;0.0)      c= -pow(-c, A);
+                    else            c=  pow( c, A);
+                    coeff= (c*0.5 + 0.5)*fone;
+                } else if (flags &amp; SWS_AREA) {
+                    int64_t d2= d - (1&lt;&lt;29);
+                    if      (d2*xInc &lt; -(1LL&lt;&lt;(29+16))) coeff= 1.0 * (1LL&lt;&lt;(30+16));
+                    else if (d2*xInc &lt;  (1LL&lt;&lt;(29+16))) coeff= -d2*xInc + (1LL&lt;&lt;(29+16));
+                    else coeff=0.0;
+                    coeff *= fone&gt;&gt;(30+16);
+                } else if (flags &amp; SWS_GAUSS) {
+                    double p= param[0] != SWS_PARAM_DEFAULT ? param[0] : 3.0;
+                    coeff = (pow(2.0, - p*floatd*floatd))*fone;
+                } else if (flags &amp; SWS_SINC) {
+                    coeff = (d ? sin(floatd*M_PI)/(floatd*M_PI) : 1.0)*fone;
+                } else if (flags &amp; SWS_LANCZOS) {
+                    double p= param[0] != SWS_PARAM_DEFAULT ? param[0] : 3.0;
+                    coeff = (d ? sin(floatd*M_PI)*sin(floatd*M_PI/p)/(floatd*floatd*M_PI*M_PI/p) : 1.0)*fone;
+                    if (floatd&gt;p) coeff=0;
+                } else if (flags &amp; SWS_BILINEAR) {
+                    coeff= (1&lt;&lt;30) - d;
+                    if (coeff&lt;0) coeff=0;
+                    coeff *= fone &gt;&gt; 30;
+                } else if (flags &amp; SWS_SPLINE) {
+                    double p=-2.196152422706632;
+                    coeff = getSplineCoeff(1.0, 0.0, p, -p-1.0, floatd) * fone;
+                } else {
+                    coeff= 0.0; //GCC warning killer
+                    assert(0);
+                }
+
+                filter[i*filterSize + j]= coeff;
+                xx++;
+            }
+            xDstInSrc+= 2*xInc;
+        }
+    }
+
+    /* apply src &amp; dst Filter to filter -&gt; filter2
+       av_free(filter);
+    */
+    assert(filterSize&gt;0);
+    filter2Size= filterSize;
+    if (srcFilter) filter2Size+= srcFilter-&gt;length - 1;
+    if (dstFilter) filter2Size+= dstFilter-&gt;length - 1;
+    assert(filter2Size&gt;0);
+    FF_ALLOCZ_OR_GOTO(NULL, filter2, filter2Size*dstW*sizeof(*filter2), fail);
+
+    for (i=0; i&lt;dstW; i++) {
+        int j, k;
+
+        if(srcFilter) {
+            for (k=0; k&lt;srcFilter-&gt;length; k++) {
+                for (j=0; j&lt;filterSize; j++)
+                    filter2[i*filter2Size + k + j] += srcFilter-&gt;coeff[k]*filter[i*filterSize + j];
+            }
+        } else {
+            for (j=0; j&lt;filterSize; j++)
+                filter2[i*filter2Size + j]= filter[i*filterSize + j];
+        }
+        //FIXME dstFilter
+
+        (*filterPos)[i]+= (filterSize-1)/2 - (filter2Size-1)/2;
+    }
+    av_freep(&amp;filter);
+
+    /* try to reduce the filter-size (step1 find size and shift left) */
+    // Assume it is near normalized (*0.5 or *2.0 is OK but * 0.001 is not).
+    minFilterSize= 0;
+    for (i=dstW-1; i&gt;=0; i--) {
+        int min= filter2Size;
+        int j;
+        int64_t cutOff=0.0;
+
+        /* get rid of near zero elements on the left by shifting left */
+        for (j=0; j&lt;filter2Size; j++) {
+            int k;
+            cutOff += FFABS(filter2[i*filter2Size]);
+
+            if (cutOff &gt; SWS_MAX_REDUCE_CUTOFF*fone) break;
+
+            /* preserve monotonicity because the core can't handle the filter otherwise */
+            if (i&lt;dstW-1 &amp;&amp; (*filterPos)[i] &gt;= (*filterPos)[i+1]) break;
+
+            // move filter coefficients left
+            for (k=1; k&lt;filter2Size; k++)
+                filter2[i*filter2Size + k - 1]= filter2[i*filter2Size + k];
+            filter2[i*filter2Size + k - 1]= 0;
+            (*filterPos)[i]++;
+        }
+
+        cutOff=0;
+        /* count near zeros on the right */
+        for (j=filter2Size-1; j&gt;0; j--) {
+            cutOff += FFABS(filter2[i*filter2Size + j]);
+
+            if (cutOff &gt; SWS_MAX_REDUCE_CUTOFF*fone) break;
+            min--;
+        }
+
+        if (min&gt;minFilterSize) minFilterSize= min;
+    }
+
+    if (flags &amp; SWS_CPU_CAPS_ALTIVEC) {
+        // we can handle the special case 4,
+        // so we don't want to go to the full 8
+        if (minFilterSize &lt; 5)
+            filterAlign = 4;
+
+        // We really don't want to waste our time
+        // doing useless computation, so fall back on
+        // the scalar C code for very small filters.
+        // Vectorizing is worth it only if you have a
+        // decent-sized vector.
+        if (minFilterSize &lt; 3)
+            filterAlign = 1;
+    }
+
+    if (flags &amp; SWS_CPU_CAPS_MMX) {
+        // special case for unscaled vertical filtering
+        if (minFilterSize == 1 &amp;&amp; filterAlign == 2)
+            filterAlign= 1;
+    }
+
+    assert(minFilterSize &gt; 0);
+    filterSize= (minFilterSize +(filterAlign-1)) &amp; (~(filterAlign-1));
+    assert(filterSize &gt; 0);
+    filter= av_malloc(filterSize*dstW*sizeof(*filter));
+    if (filterSize &gt;= MAX_FILTER_SIZE*16/((flags&amp;SWS_ACCURATE_RND) ? APCK_SIZE : 16) || !filter)
+        goto fail;
+    *outFilterSize= filterSize;
+
+    if (flags&amp;SWS_PRINT_INFO)
+        av_log(NULL, AV_LOG_VERBOSE, &quot;SwScaler: reducing / aligning filtersize %d -&gt; %d\n&quot;, filter2Size, filterSize);
+    /* try to reduce the filter-size (step2 reduce it) */
+    for (i=0; i&lt;dstW; i++) {
+        int j;
+
+        for (j=0; j&lt;filterSize; j++) {
+            if (j&gt;=filter2Size) filter[i*filterSize + j]= 0;
+            else               filter[i*filterSize + j]= filter2[i*filter2Size + j];
+            if((flags &amp; SWS_BITEXACT) &amp;&amp; j&gt;=minFilterSize)
+                filter[i*filterSize + j]= 0;
+        }
+    }
+
+    //FIXME try to align filterPos if possible
+
+    //fix borders
+    for (i=0; i&lt;dstW; i++) {
+        int j;
+        if ((*filterPos)[i] &lt; 0) {
+            // move filter coefficients left to compensate for filterPos
+            for (j=1; j&lt;filterSize; j++) {
+                int left= FFMAX(j + (*filterPos)[i], 0);
+                filter[i*filterSize + left] += filter[i*filterSize + j];
+                filter[i*filterSize + j]=0;
+            }
+            (*filterPos)[i]= 0;
+        }
+
+        if ((*filterPos)[i] + filterSize &gt; srcW) {
+            int shift= (*filterPos)[i] + filterSize - srcW;
+            // move filter coefficients right to compensate for filterPos
+            for (j=filterSize-2; j&gt;=0; j--) {
+                int right= FFMIN(j + shift, filterSize-1);
+                filter[i*filterSize +right] += filter[i*filterSize +j];
+                filter[i*filterSize +j]=0;
+            }
+            (*filterPos)[i]= srcW - filterSize;
+        }
+    }
+
+    // Note the +1 is for the MMX scaler which reads over the end
+    /* align at 16 for AltiVec (needed by hScale_altivec_real) */
+    FF_ALLOCZ_OR_GOTO(NULL, *outFilter, *outFilterSize*(dstW+1)*sizeof(int16_t), fail);
+
+    /* normalize &amp; store in outFilter */
+    for (i=0; i&lt;dstW; i++) {
+        int j;
+        int64_t error=0;
+        int64_t sum=0;
+
+        for (j=0; j&lt;filterSize; j++) {
+            sum+= filter[i*filterSize + j];
+        }
+        sum= (sum + one/2)/ one;
+        for (j=0; j&lt;*outFilterSize; j++) {
+            int64_t v= filter[i*filterSize + j] + error;
+            int intV= ROUNDED_DIV(v, sum);
+            (*outFilter)[i*(*outFilterSize) + j]= intV;
+            error= v - intV*sum;
+        }
+    }
+
+    (*filterPos)[dstW]= (*filterPos)[dstW-1]; // the MMX scaler will read over the end
+    for (i=0; i&lt;*outFilterSize; i++) {
+        int j= dstW*(*outFilterSize);
+        (*outFilter)[j + i]= (*outFilter)[j + i - (*outFilterSize)];
+    }
+
+    ret=0;
+fail:
+    av_free(filter);
+    av_free(filter2);
+    return ret;
+}
+
+#if ARCH_X86 &amp;&amp; (HAVE_MMX2 || CONFIG_RUNTIME_CPUDETECT) &amp;&amp; CONFIG_GPL
+static int initMMX2HScaler(int dstW, int xInc, uint8_t *filterCode, int16_t *filter, int32_t *filterPos, int numSplits)
+{
+    uint8_t *fragmentA;
+    x86_reg imm8OfPShufW1A;
+    x86_reg imm8OfPShufW2A;
+    x86_reg fragmentLengthA;
+    uint8_t *fragmentB;
+    x86_reg imm8OfPShufW1B;
+    x86_reg imm8OfPShufW2B;
+    x86_reg fragmentLengthB;
+    int fragmentPos;
+
+    int xpos, i;
+
+    // create an optimized horizontal scaling routine
+    /* This scaler is made of runtime-generated MMX2 code using specially
+     * tuned pshufw instructions. For every four output pixels, if four
+     * input pixels are enough for the fast bilinear scaling, then a chunk
+     * of fragmentB is used. If five input pixels are needed, then a chunk
+     * of fragmentA is used.
+     */
+
+    //code fragment
+
+    __asm__ volatile(
+        &quot;jmp                         9f                 \n\t&quot;
+    // Begin
+        &quot;0:                                             \n\t&quot;
+        &quot;movq    (%%&quot;REG_d&quot;, %%&quot;REG_a&quot;), %%mm3          \n\t&quot;
+        &quot;movd    (%%&quot;REG_c&quot;, %%&quot;REG_S&quot;), %%mm0          \n\t&quot;
+        &quot;movd   1(%%&quot;REG_c&quot;, %%&quot;REG_S&quot;), %%mm1          \n\t&quot;
+        &quot;punpcklbw                %%mm7, %%mm1          \n\t&quot;
+        &quot;punpcklbw                %%mm7, %%mm0          \n\t&quot;
+        &quot;pshufw                   $0xFF, %%mm1, %%mm1   \n\t&quot;
+        &quot;1:                                             \n\t&quot;
+        &quot;pshufw                   $0xFF, %%mm0, %%mm0   \n\t&quot;
+        &quot;2:                                             \n\t&quot;
+        &quot;psubw                    %%mm1, %%mm0          \n\t&quot;
+        &quot;movl   8(%%&quot;REG_b&quot;, %%&quot;REG_a&quot;), %%esi          \n\t&quot;
+        &quot;pmullw                   %%mm3, %%mm0          \n\t&quot;
+        &quot;psllw                       $7, %%mm1          \n\t&quot;
+        &quot;paddw                    %%mm1, %%mm0          \n\t&quot;
+
+        &quot;movq                     %%mm0, (%%&quot;REG_D&quot;, %%&quot;REG_a&quot;) \n\t&quot;
+
+        &quot;add                         $8, %%&quot;REG_a&quot;      \n\t&quot;
+    // End
+        &quot;9:                                             \n\t&quot;
+//        &quot;int $3                                         \n\t&quot;
+        &quot;lea                 &quot; LOCAL_MANGLE(0b) &quot;, %0   \n\t&quot;
+        &quot;lea                 &quot; LOCAL_MANGLE(1b) &quot;, %1   \n\t&quot;
+        &quot;lea                 &quot; LOCAL_MANGLE(2b) &quot;, %2   \n\t&quot;
+        &quot;dec                         %1                 \n\t&quot;
+        &quot;dec                         %2                 \n\t&quot;
+        &quot;sub                         %0, %1             \n\t&quot;
+        &quot;sub                         %0, %2             \n\t&quot;
+        &quot;lea                 &quot; LOCAL_MANGLE(9b) &quot;, %3   \n\t&quot;
+        &quot;sub                         %0, %3             \n\t&quot;
+
+
+        :&quot;=r&quot; (fragmentA), &quot;=r&quot; (imm8OfPShufW1A), &quot;=r&quot; (imm8OfPShufW2A),
+        &quot;=r&quot; (fragmentLengthA)
+    );
+
+    __asm__ volatile(
+        &quot;jmp                         9f                 \n\t&quot;
+    // Begin
+        &quot;0:                                             \n\t&quot;
+        &quot;movq    (%%&quot;REG_d&quot;, %%&quot;REG_a&quot;), %%mm3          \n\t&quot;
+        &quot;movd    (%%&quot;REG_c&quot;, %%&quot;REG_S&quot;), %%mm0          \n\t&quot;
+        &quot;punpcklbw                %%mm7, %%mm0          \n\t&quot;
+        &quot;pshufw                   $0xFF, %%mm0, %%mm1   \n\t&quot;
+        &quot;1:                                             \n\t&quot;
+        &quot;pshufw                   $0xFF, %%mm0, %%mm0   \n\t&quot;
+        &quot;2:                                             \n\t&quot;
+        &quot;psubw                    %%mm1, %%mm0          \n\t&quot;
+        &quot;movl   8(%%&quot;REG_b&quot;, %%&quot;REG_a&quot;), %%esi          \n\t&quot;
+        &quot;pmullw                   %%mm3, %%mm0          \n\t&quot;
+        &quot;psllw                       $7, %%mm1          \n\t&quot;
+        &quot;paddw                    %%mm1, %%mm0          \n\t&quot;
+
+        &quot;movq                     %%mm0, (%%&quot;REG_D&quot;, %%&quot;REG_a&quot;) \n\t&quot;
+
+        &quot;add                         $8, %%&quot;REG_a&quot;      \n\t&quot;
+    // End
+        &quot;9:                                             \n\t&quot;
+//        &quot;int                       $3                   \n\t&quot;
+        &quot;lea                 &quot; LOCAL_MANGLE(0b) &quot;, %0   \n\t&quot;
+        &quot;lea                 &quot; LOCAL_MANGLE(1b) &quot;, %1   \n\t&quot;
+        &quot;lea                 &quot; LOCAL_MANGLE(2b) &quot;, %2   \n\t&quot;
+        &quot;dec                         %1                 \n\t&quot;
+        &quot;dec                         %2                 \n\t&quot;
+        &quot;sub                         %0, %1             \n\t&quot;
+        &quot;sub                         %0, %2             \n\t&quot;
+        &quot;lea                 &quot; LOCAL_MANGLE(9b) &quot;, %3   \n\t&quot;
+        &quot;sub                         %0, %3             \n\t&quot;
+
+
+        :&quot;=r&quot; (fragmentB), &quot;=r&quot; (imm8OfPShufW1B), &quot;=r&quot; (imm8OfPShufW2B),
+        &quot;=r&quot; (fragmentLengthB)
+    );
+
+    xpos= 0; //lumXInc/2 - 0x8000; // difference between pixel centers
+    fragmentPos=0;
+
+    for (i=0; i&lt;dstW/numSplits; i++) {
+        int xx=xpos&gt;&gt;16;
+
+        if ((i&amp;3) == 0) {
+            int a=0;
+            int b=((xpos+xInc)&gt;&gt;16) - xx;
+            int c=((xpos+xInc*2)&gt;&gt;16) - xx;
+            int d=((xpos+xInc*3)&gt;&gt;16) - xx;
+            int inc                = (d+1&lt;4);
+            uint8_t *fragment      = (d+1&lt;4) ? fragmentB       : fragmentA;
+            x86_reg imm8OfPShufW1  = (d+1&lt;4) ? imm8OfPShufW1B  : imm8OfPShufW1A;
+            x86_reg imm8OfPShufW2  = (d+1&lt;4) ? imm8OfPShufW2B  : imm8OfPShufW2A;
+            x86_reg fragmentLength = (d+1&lt;4) ? fragmentLengthB : fragmentLengthA;
+            int maxShift= 3-(d+inc);
+            int shift=0;
+
+            if (filterCode) {
+                filter[i  ] = (( xpos         &amp; 0xFFFF) ^ 0xFFFF)&gt;&gt;9;
+                filter[i+1] = (((xpos+xInc  ) &amp; 0xFFFF) ^ 0xFFFF)&gt;&gt;9;
+                filter[i+2] = (((xpos+xInc*2) &amp; 0xFFFF) ^ 0xFFFF)&gt;&gt;9;
+                filter[i+3] = (((xpos+xInc*3) &amp; 0xFFFF) ^ 0xFFFF)&gt;&gt;9;
+                filterPos[i/2]= xx;
+
+                memcpy(filterCode + fragmentPos, fragment, fragmentLength);
+
+                filterCode[fragmentPos + imm8OfPShufW1]=
+                    (a+inc) | ((b+inc)&lt;&lt;2) | ((c+inc)&lt;&lt;4) | ((d+inc)&lt;&lt;6);
+                filterCode[fragmentPos + imm8OfPShufW2]=
+                    a | (b&lt;&lt;2) | (c&lt;&lt;4) | (d&lt;&lt;6);
+
+                if (i+4-inc&gt;=dstW) shift=maxShift; //avoid overread
+                else if ((filterPos[i/2]&amp;3) &lt;= maxShift) shift=filterPos[i/2]&amp;3; //Align
+
+                if (shift &amp;&amp; i&gt;=shift) {
+                    filterCode[fragmentPos + imm8OfPShufW1]+= 0x55*shift;
+                    filterCode[fragmentPos + imm8OfPShufW2]+= 0x55*shift;
+                    filterPos[i/2]-=shift;
+                }
+            }
+
+            fragmentPos+= fragmentLength;
+
+            if (filterCode)
+                filterCode[fragmentPos]= RET;
+        }
+        xpos+=xInc;
+    }
+    if (filterCode)
+        filterPos[((i/2)+1)&amp;(~1)]= xpos&gt;&gt;16; // needed to jump to the next part
+
+    return fragmentPos + 1;
+}
+#endif /* ARCH_X86 &amp;&amp; (HAVE_MMX2 || CONFIG_RUNTIME_CPUDETECT) &amp;&amp; CONFIG_GPL */
+
+static void getSubSampleFactors(int *h, int *v, enum PixelFormat format)
+{
+    *h = av_pix_fmt_descriptors[format].log2_chroma_w;
+    *v = av_pix_fmt_descriptors[format].log2_chroma_h;
+}
+
+static uint16_t roundToInt16(int64_t f)
+{
+    int r= (f + (1&lt;&lt;15))&gt;&gt;16;
+         if (r&lt;-0x7FFF) return 0x8000;
+    else if (r&gt; 0x7FFF) return 0x7FFF;
+    else                return r;
+}
+
+int sws_setColorspaceDetails(SwsContext *c, const int inv_table[4], int srcRange, const int table[4], int dstRange, int brightness, int contrast, int saturation)
+{
+    int64_t crv =  inv_table[0];
+    int64_t cbu =  inv_table[1];
+    int64_t cgu = -inv_table[2];
+    int64_t cgv = -inv_table[3];
+    int64_t cy  = 1&lt;&lt;16;
+    int64_t oy  = 0;
+
+    memcpy(c-&gt;srcColorspaceTable, inv_table, sizeof(int)*4);
+    memcpy(c-&gt;dstColorspaceTable,     table, sizeof(int)*4);
+
+    c-&gt;brightness= brightness;
+    c-&gt;contrast  = contrast;
+    c-&gt;saturation= saturation;
+    c-&gt;srcRange  = srcRange;
+    c-&gt;dstRange  = dstRange;
+    if (isYUV(c-&gt;dstFormat) || isGray(c-&gt;dstFormat)) return -1;
+
+    c-&gt;uOffset=   0x0400040004000400LL;
+    c-&gt;vOffset=   0x0400040004000400LL;
+
+    if (!srcRange) {
+        cy= (cy*255) / 219;
+        oy= 16&lt;&lt;16;
+    } else {
+        crv= (crv*224) / 255;
+        cbu= (cbu*224) / 255;
+        cgu= (cgu*224) / 255;
+        cgv= (cgv*224) / 255;
+    }
+
+    cy = (cy *contrast             )&gt;&gt;16;
+    crv= (crv*contrast * saturation)&gt;&gt;32;
+    cbu= (cbu*contrast * saturation)&gt;&gt;32;
+    cgu= (cgu*contrast * saturation)&gt;&gt;32;
+    cgv= (cgv*contrast * saturation)&gt;&gt;32;
+
+    oy -= 256*brightness;
+
+    c-&gt;yCoeff=    roundToInt16(cy *8192) * 0x0001000100010001ULL;
+    c-&gt;vrCoeff=   roundToInt16(crv*8192) * 0x0001000100010001ULL;
+    c-&gt;ubCoeff=   roundToInt16(cbu*8192) * 0x0001000100010001ULL;
+    c-&gt;vgCoeff=   roundToInt16(cgv*8192) * 0x0001000100010001ULL;
+    c-&gt;ugCoeff=   roundToInt16(cgu*8192) * 0x0001000100010001ULL;
+    c-&gt;yOffset=   roundToInt16(oy *   8) * 0x0001000100010001ULL;
+
+    c-&gt;yuv2rgb_y_coeff  = (int16_t)roundToInt16(cy &lt;&lt;13);
+    c-&gt;yuv2rgb_y_offset = (int16_t)roundToInt16(oy &lt;&lt; 9);
+    c-&gt;yuv2rgb_v2r_coeff= (int16_t)roundToInt16(crv&lt;&lt;13);
+    c-&gt;yuv2rgb_v2g_coeff= (int16_t)roundToInt16(cgv&lt;&lt;13);
+    c-&gt;yuv2rgb_u2g_coeff= (int16_t)roundToInt16(cgu&lt;&lt;13);
+    c-&gt;yuv2rgb_u2b_coeff= (int16_t)roundToInt16(cbu&lt;&lt;13);
+
+    ff_yuv2rgb_c_init_tables(c, inv_table, srcRange, brightness, contrast, saturation);
+    //FIXME factorize
+
+#if ARCH_PPC &amp;&amp; (HAVE_ALTIVEC || CONFIG_RUNTIME_CPUDETECT)
+    if (c-&gt;flags &amp; SWS_CPU_CAPS_ALTIVEC)
+        ff_yuv2rgb_init_tables_altivec(c, inv_table, brightness, contrast, saturation);
+#endif
+    return 0;
+}
+
+int sws_getColorspaceDetails(SwsContext *c, int **inv_table, int *srcRange, int **table, int *dstRange, int *brightness, int *contrast, int *saturation)
+{
+    if (isYUV(c-&gt;dstFormat) || isGray(c-&gt;dstFormat)) return -1;
+
+    *inv_table = c-&gt;srcColorspaceTable;
+    *table     = c-&gt;dstColorspaceTable;
+    *srcRange  = c-&gt;srcRange;
+    *dstRange  = c-&gt;dstRange;
+    *brightness= c-&gt;brightness;
+    *contrast  = c-&gt;contrast;
+    *saturation= c-&gt;saturation;
+
+    return 0;
+}
+
+static int handle_jpeg(enum PixelFormat *format)
+{
+    switch (*format) {
+    case PIX_FMT_YUVJ420P:
+        *format = PIX_FMT_YUV420P;
+        return 1;
+    case PIX_FMT_YUVJ422P:
+        *format = PIX_FMT_YUV422P;
+        return 1;
+    case PIX_FMT_YUVJ444P:
+        *format = PIX_FMT_YUV444P;
+        return 1;
+    case PIX_FMT_YUVJ440P:
+        *format = PIX_FMT_YUV440P;
+        return 1;
+    default:
+        return 0;
+    }
+}
+
+SwsContext *sws_getContext(int srcW, int srcH, enum PixelFormat srcFormat,
+                           int dstW, int dstH, enum PixelFormat dstFormat, int flags,
+                           SwsFilter *srcFilter, SwsFilter *dstFilter, const double *param)
+{
+
+    SwsContext *c;
+    int i;
+    int usesVFilter, usesHFilter;
+    int unscaled;
+    int srcRange, dstRange;
+    SwsFilter dummyFilter= {NULL, NULL, NULL, NULL};
+#if ARCH_X86
+    if (flags &amp; SWS_CPU_CAPS_MMX)
+        __asm__ volatile(&quot;emms\n\t&quot;::: &quot;memory&quot;);
+#endif
+
+#if !CONFIG_RUNTIME_CPUDETECT //ensure that the flags match the compiled variant if cpudetect is off
+    flags &amp;= ~(SWS_CPU_CAPS_MMX|SWS_CPU_CAPS_MMX2|SWS_CPU_CAPS_3DNOW|SWS_CPU_CAPS_ALTIVEC|SWS_CPU_CAPS_BFIN);
+    flags |= ff_hardcodedcpuflags();
+#endif /* CONFIG_RUNTIME_CPUDETECT */
+    if (!rgb15to16) sws_rgb2rgb_init(flags);
+
+    unscaled = (srcW == dstW &amp;&amp; srcH == dstH);
+
+    srcRange = handle_jpeg(&amp;srcFormat);
+    dstRange = handle_jpeg(&amp;dstFormat);
+
+    if (!isSupportedIn(srcFormat)) {
+        av_log(NULL, AV_LOG_ERROR, &quot;swScaler: %s is not supported as input pixel format\n&quot;, sws_format_name(srcFormat));
+        return NULL;
+    }
+    if (!isSupportedOut(dstFormat)) {
+        av_log(NULL, AV_LOG_ERROR, &quot;swScaler: %s is not supported as output pixel format\n&quot;, sws_format_name(dstFormat));
+        return NULL;
+    }
+
+    i= flags &amp; ( SWS_POINT
+                |SWS_AREA
+                |SWS_BILINEAR
+                |SWS_FAST_BILINEAR
+                |SWS_BICUBIC
+                |SWS_X
+                |SWS_GAUSS
+                |SWS_LANCZOS
+                |SWS_SINC
+                |SWS_SPLINE
+                |SWS_BICUBLIN);
+    if(!i || (i &amp; (i-1))) {
+        av_log(NULL, AV_LOG_ERROR, &quot;swScaler: Exactly one scaler algorithm must be chosen\n&quot;);
+        return NULL;
+    }
+
+    /* sanity check */
+    if (srcW&lt;4 || srcH&lt;1 || dstW&lt;8 || dstH&lt;1) { //FIXME check if these are enough and try to lowwer them after fixing the relevant parts of the code
+        av_log(NULL, AV_LOG_ERROR, &quot;swScaler: %dx%d -&gt; %dx%d is invalid scaling dimension\n&quot;,
+               srcW, srcH, dstW, dstH);
+        return NULL;
+    }
+    if(srcW &gt; VOFW || dstW &gt; VOFW) {
+        av_log(NULL, AV_LOG_ERROR, &quot;swScaler: Compile-time maximum width is &quot;AV_STRINGIFY(VOFW)&quot; change VOF/VOFW and recompile\n&quot;);
+        return NULL;
+    }
+
+    if (!dstFilter) dstFilter= &dummyFilter;
+    if (!srcFilter) srcFilter= &dummyFilter;
+
+    FF_ALLOCZ_OR_GOTO(NULL, c, sizeof(SwsContext), fail);
+
+    c-&gt;av_class = &amp;sws_context_class;
+    c-&gt;srcW= srcW;
+    c-&gt;srcH= srcH;
+    c-&gt;dstW= dstW;
+    c-&gt;dstH= dstH;
+    c-&gt;lumXInc= ((srcW&lt;&lt;16) + (dstW&gt;&gt;1))/dstW;
+    c-&gt;lumYInc= ((srcH&lt;&lt;16) + (dstH&gt;&gt;1))/dstH;
+    c-&gt;flags= flags;
+    c-&gt;dstFormat= dstFormat;
+    c-&gt;srcFormat= srcFormat;
+    c-&gt;dstFormatBpp = av_get_bits_per_pixel(&amp;av_pix_fmt_descriptors[dstFormat]);
+    c-&gt;srcFormatBpp = av_get_bits_per_pixel(&amp;av_pix_fmt_descriptors[srcFormat]);
+    c-&gt;vRounder= 4* 0x0001000100010001ULL;
+
+    usesVFilter = (srcFilter-&gt;lumV &amp;&amp; srcFilter-&gt;lumV-&gt;length&gt;1) ||
+                  (srcFilter-&gt;chrV &amp;&amp; srcFilter-&gt;chrV-&gt;length&gt;1) ||
+                  (dstFilter-&gt;lumV &amp;&amp; dstFilter-&gt;lumV-&gt;length&gt;1) ||
+                  (dstFilter-&gt;chrV &amp;&amp; dstFilter-&gt;chrV-&gt;length&gt;1);
+    usesHFilter = (srcFilter-&gt;lumH &amp;&amp; srcFilter-&gt;lumH-&gt;length&gt;1) ||
+                  (srcFilter-&gt;chrH &amp;&amp; srcFilter-&gt;chrH-&gt;length&gt;1) ||
+                  (dstFilter-&gt;lumH &amp;&amp; dstFilter-&gt;lumH-&gt;length&gt;1) ||
+                  (dstFilter-&gt;chrH &amp;&amp; dstFilter-&gt;chrH-&gt;length&gt;1);
+
+    getSubSampleFactors(&amp;c-&gt;chrSrcHSubSample, &amp;c-&gt;chrSrcVSubSample, srcFormat);
+    getSubSampleFactors(&amp;c-&gt;chrDstHSubSample, &amp;c-&gt;chrDstVSubSample, dstFormat);
+
+    // reuse chroma for 2 pixels RGB/BGR unless user wants full chroma interpolation
+    if (isAnyRGB(dstFormat) &amp;&amp; !(flags&amp;SWS_FULL_CHR_H_INT)) c-&gt;chrDstHSubSample=1;
+
+    // drop some chroma lines if the user wants it
+    c-&gt;vChrDrop= (flags&amp;SWS_SRC_V_CHR_DROP_MASK)&gt;&gt;SWS_SRC_V_CHR_DROP_SHIFT;
+    c-&gt;chrSrcVSubSample+= c-&gt;vChrDrop;
+
+    // drop every other pixel for chroma calculation unless user wants full chroma
+    if (isAnyRGB(srcFormat) &amp;&amp; !(flags&amp;SWS_FULL_CHR_H_INP)
+      &amp;&amp; srcFormat!=PIX_FMT_RGB8      &amp;&amp; srcFormat!=PIX_FMT_BGR8
+      &amp;&amp; srcFormat!=PIX_FMT_RGB4      &amp;&amp; srcFormat!=PIX_FMT_BGR4
+      &amp;&amp; srcFormat!=PIX_FMT_RGB4_BYTE &amp;&amp; srcFormat!=PIX_FMT_BGR4_BYTE
+      &amp;&amp; ((dstW&gt;&gt;c-&gt;chrDstHSubSample) &lt;= (srcW&gt;&gt;1) || (flags&amp;(SWS_FAST_BILINEAR|SWS_POINT))))
+        c-&gt;chrSrcHSubSample=1;
+
+    if (param) {
+        c-&gt;param[0] = param[0];
+        c-&gt;param[1] = param[1];
+    } else {
+        c-&gt;param[0] =
+        c-&gt;param[1] = SWS_PARAM_DEFAULT;
+    }
+
+    // Note the -((-x)&gt;&gt;y) is so that we always round toward +inf.
+    c-&gt;chrSrcW= -((-srcW) &gt;&gt; c-&gt;chrSrcHSubSample);
+    c-&gt;chrSrcH= -((-srcH) &gt;&gt; c-&gt;chrSrcVSubSample);
+    c-&gt;chrDstW= -((-dstW) &gt;&gt; c-&gt;chrDstHSubSample);
+    c-&gt;chrDstH= -((-dstH) &gt;&gt; c-&gt;chrDstVSubSample);
+
+    sws_setColorspaceDetails(c, ff_yuv2rgb_coeffs[SWS_CS_DEFAULT], srcRange, ff_yuv2rgb_coeffs[SWS_CS_DEFAULT] /* FIXME*/, dstRange, 0, 1&lt;&lt;16, 1&lt;&lt;16);
+
+    /* unscaled special cases */
+    if (unscaled &amp;&amp; !usesHFilter &amp;&amp; !usesVFilter &amp;&amp; (srcRange == dstRange || isAnyRGB(dstFormat))) {
+        ff_get_unscaled_swscale(c);
+
+        if (c-&gt;swScale) {
+            if (flags&amp;SWS_PRINT_INFO)
+                av_log(c, AV_LOG_INFO, &quot;using unscaled %s -&gt; %s special converter\n&quot;,
+                       sws_format_name(srcFormat), sws_format_name(dstFormat));
+            return c;
+        }
+    }
+
+    if (flags &amp; SWS_CPU_CAPS_MMX2) {
+        c-&gt;canMMX2BeUsed= (dstW &gt;=srcW &amp;&amp; (dstW&amp;31)==0 &amp;&amp; (srcW&amp;15)==0) ? 1 : 0;
+        if (!c-&gt;canMMX2BeUsed &amp;&amp; dstW &gt;=srcW &amp;&amp; (srcW&amp;15)==0 &amp;&amp; (flags&amp;SWS_FAST_BILINEAR)) {
+            if (flags&amp;SWS_PRINT_INFO)
+                av_log(c, AV_LOG_INFO, &quot;output width is not a multiple of 32 -&gt; no MMX2 scaler\n&quot;);
+        }
+        if (usesHFilter) c-&gt;canMMX2BeUsed=0;
+    }
+    else
+        c-&gt;canMMX2BeUsed=0;
+
+    c-&gt;chrXInc= ((c-&gt;chrSrcW&lt;&lt;16) + (c-&gt;chrDstW&gt;&gt;1))/c-&gt;chrDstW;
+    c-&gt;chrYInc= ((c-&gt;chrSrcH&lt;&lt;16) + (c-&gt;chrDstH&gt;&gt;1))/c-&gt;chrDstH;
+
+    // match pixel 0 of the src to pixel 0 of dst and match pixel n-2 of src to pixel n-2 of dst
+    // but only for the FAST_BILINEAR mode otherwise do correct scaling
+    // n-2 is the last chrominance sample available
+    // this is not perfect, but no one should notice the difference, the more correct variant
+    // would be like the vertical one, but that would require some special code for the
+    // first and last pixel
+    if (flags&amp;SWS_FAST_BILINEAR) {
+        if (c-&gt;canMMX2BeUsed) {
+            c-&gt;lumXInc+= 20;
+            c-&gt;chrXInc+= 20;
+        }
+        //we don't use the x86 asm scaler if MMX is available
+        else if (flags &amp; SWS_CPU_CAPS_MMX) {
+            c-&gt;lumXInc = ((srcW-2)&lt;&lt;16)/(dstW-2) - 20;
+            c-&gt;chrXInc = ((c-&gt;chrSrcW-2)&lt;&lt;16)/(c-&gt;chrDstW-2) - 20;
+        }
+    }
+
+    /* precalculate horizontal scaler filter coefficients */
+    {
+#if ARCH_X86 &amp;&amp; (HAVE_MMX2 || CONFIG_RUNTIME_CPUDETECT) &amp;&amp; CONFIG_GPL
+// can't downscale !!!
+        if (c-&gt;canMMX2BeUsed &amp;&amp; (flags &amp; SWS_FAST_BILINEAR)) {
+            c-&gt;lumMmx2FilterCodeSize = initMMX2HScaler(      dstW, c-&gt;lumXInc, NULL, NULL, NULL, 8);
+            c-&gt;chrMmx2FilterCodeSize = initMMX2HScaler(c-&gt;chrDstW, c-&gt;chrXInc, NULL, NULL, NULL, 4);
+
+#ifdef MAP_ANONYMOUS
+            c-&gt;lumMmx2FilterCode = mmap(NULL, c-&gt;lumMmx2FilterCodeSize, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS, 0, 0);
+            c-&gt;chrMmx2FilterCode = mmap(NULL, c-&gt;chrMmx2FilterCodeSize, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS, 0, 0);
+#elif HAVE_VIRTUALALLOC
+            c-&gt;lumMmx2FilterCode = VirtualAlloc(NULL, c-&gt;lumMmx2FilterCodeSize, MEM_COMMIT, PAGE_EXECUTE_READWRITE);
+            c-&gt;chrMmx2FilterCode = VirtualAlloc(NULL, c-&gt;chrMmx2FilterCodeSize, MEM_COMMIT, PAGE_EXECUTE_READWRITE);
+#else
+            c-&gt;lumMmx2FilterCode = av_malloc(c-&gt;lumMmx2FilterCodeSize);
+            c-&gt;chrMmx2FilterCode = av_malloc(c-&gt;chrMmx2FilterCodeSize);
+#endif
+
+            FF_ALLOCZ_OR_GOTO(c, c-&gt;hLumFilter   , (dstW        /8+8)*sizeof(int16_t), fail);
+            FF_ALLOCZ_OR_GOTO(c, c-&gt;hChrFilter   , (c-&gt;chrDstW  /4+8)*sizeof(int16_t), fail);
+            FF_ALLOCZ_OR_GOTO(c, c-&gt;hLumFilterPos, (dstW      /2/8+8)*sizeof(int32_t), fail);
+            FF_ALLOCZ_OR_GOTO(c, c-&gt;hChrFilterPos, (c-&gt;chrDstW/2/4+8)*sizeof(int32_t), fail);
+
+            initMMX2HScaler(      dstW, c-&gt;lumXInc, c-&gt;lumMmx2FilterCode, c-&gt;hLumFilter, c-&gt;hLumFilterPos, 8);
+            initMMX2HScaler(c-&gt;chrDstW, c-&gt;chrXInc, c-&gt;chrMmx2FilterCode, c-&gt;hChrFilter, c-&gt;hChrFilterPos, 4);
+
+#ifdef MAP_ANONYMOUS
+            mprotect(c-&gt;lumMmx2FilterCode, c-&gt;lumMmx2FilterCodeSize, PROT_EXEC | PROT_READ);
+            mprotect(c-&gt;chrMmx2FilterCode, c-&gt;chrMmx2FilterCodeSize, PROT_EXEC | PROT_READ);
+#endif
+        } else
+#endif /* ARCH_X86 &amp;&amp; (HAVE_MMX2 || CONFIG_RUNTIME_CPUDETECT) &amp;&amp; CONFIG_GPL */
+        {
+            const int filterAlign=
+                (flags &amp; SWS_CPU_CAPS_MMX) ? 4 :
+                (flags &amp; SWS_CPU_CAPS_ALTIVEC) ? 8 :
+                1;
+
+            if (initFilter(&amp;c-&gt;hLumFilter, &amp;c-&gt;hLumFilterPos, &amp;c-&gt;hLumFilterSize, c-&gt;lumXInc,
+                           srcW      ,       dstW, filterAlign, 1&lt;&lt;14,
+                           (flags&amp;SWS_BICUBLIN) ? (flags|SWS_BICUBIC)  : flags,
+                           srcFilter-&gt;lumH, dstFilter-&gt;lumH, c-&gt;param) &lt; 0)
+                goto fail;
+            if (initFilter(&amp;c-&gt;hChrFilter, &amp;c-&gt;hChrFilterPos, &amp;c-&gt;hChrFilterSize, c-&gt;chrXInc,
+                           c-&gt;chrSrcW, c-&gt;chrDstW, filterAlign, 1&lt;&lt;14,
+                           (flags&amp;SWS_BICUBLIN) ? (flags|SWS_BILINEAR) : flags,
+                           srcFilter-&gt;chrH, dstFilter-&gt;chrH, c-&gt;param) &lt; 0)
+                goto fail;
+        }
+    } // initialize horizontal stuff
+
+    /* precalculate vertical scaler filter coefficients */
+    {
+        const int filterAlign=
+            (flags &amp; SWS_CPU_CAPS_MMX) &amp;&amp; (flags &amp; SWS_ACCURATE_RND) ? 2 :
+            (flags &amp; SWS_CPU_CAPS_ALTIVEC) ? 8 :
+            1;
+
+        if (initFilter(&amp;c-&gt;vLumFilter, &amp;c-&gt;vLumFilterPos, &amp;c-&gt;vLumFilterSize, c-&gt;lumYInc,
+                       srcH      ,        dstH, filterAlign, (1&lt;&lt;12),
+                       (flags&amp;SWS_BICUBLIN) ? (flags|SWS_BICUBIC)  : flags,
+                       srcFilter-&gt;lumV, dstFilter-&gt;lumV, c-&gt;param) &lt; 0)
+            goto fail;
+        if (initFilter(&amp;c-&gt;vChrFilter, &amp;c-&gt;vChrFilterPos, &amp;c-&gt;vChrFilterSize, c-&gt;chrYInc,
+                       c-&gt;chrSrcH, c-&gt;chrDstH, filterAlign, (1&lt;&lt;12),
+                       (flags&amp;SWS_BICUBLIN) ? (flags|SWS_BILINEAR) : flags,
+                       srcFilter-&gt;chrV, dstFilter-&gt;chrV, c-&gt;param) &lt; 0)
+            goto fail;
+
+#if ARCH_PPC &amp;&amp; (HAVE_ALTIVEC || CONFIG_RUNTIME_CPUDETECT)
+        FF_ALLOC_OR_GOTO(c, c-&gt;vYCoeffsBank, sizeof (vector signed short)*c-&gt;vLumFilterSize*c-&gt;dstH, fail);
+        FF_ALLOC_OR_GOTO(c, c-&gt;vCCoeffsBank, sizeof (vector signed short)*c-&gt;vChrFilterSize*c-&gt;chrDstH, fail);
+
+        for (i=0;i&lt;c-&gt;vLumFilterSize*c-&gt;dstH;i++) {
+            int j;
+            short *p = (short *)&amp;c-&gt;vYCoeffsBank[i];
+            for (j=0;j&lt;8;j++)
+                p[j] = c-&gt;vLumFilter[i];
+        }
+
+        for (i=0;i&lt;c-&gt;vChrFilterSize*c-&gt;chrDstH;i++) {
+            int j;
+            short *p = (short *)&amp;c-&gt;vCCoeffsBank[i];
+            for (j=0;j&lt;8;j++)
+                p[j] = c-&gt;vChrFilter[i];
+        }
+#endif
+    }
+
+    // calculate buffer sizes so that they won't run out while handling these damn slices
+    c-&gt;vLumBufSize= c-&gt;vLumFilterSize;
+    c-&gt;vChrBufSize= c-&gt;vChrFilterSize;
+    for (i=0; i&lt;dstH; i++) {
+        int chrI= i*c-&gt;chrDstH / dstH;
+        int nextSlice= FFMAX(c-&gt;vLumFilterPos[i   ] + c-&gt;vLumFilterSize - 1,
+                           ((c-&gt;vChrFilterPos[chrI] + c-&gt;vChrFilterSize - 1)&lt;&lt;c-&gt;chrSrcVSubSample));
+
+        nextSlice&gt;&gt;= c-&gt;chrSrcVSubSample;
+        nextSlice&lt;&lt;= c-&gt;chrSrcVSubSample;
+        if (c-&gt;vLumFilterPos[i   ] + c-&gt;vLumBufSize &lt; nextSlice)
+            c-&gt;vLumBufSize= nextSlice - c-&gt;vLumFilterPos[i];
+        if (c-&gt;vChrFilterPos[chrI] + c-&gt;vChrBufSize &lt; (nextSlice&gt;&gt;c-&gt;chrSrcVSubSample))
+            c-&gt;vChrBufSize= (nextSlice&gt;&gt;c-&gt;chrSrcVSubSample) - c-&gt;vChrFilterPos[chrI];
+    }
+
+    // allocate pixbufs (we use dynamic allocation because otherwise we would need to
+    // allocate several megabytes to handle all possible cases)
+    FF_ALLOC_OR_GOTO(c, c-&gt;lumPixBuf, c-&gt;vLumBufSize*2*sizeof(int16_t*), fail);
+    FF_ALLOC_OR_GOTO(c, c-&gt;chrPixBuf, c-&gt;vChrBufSize*2*sizeof(int16_t*), fail);
+    if (CONFIG_SWSCALE_ALPHA &amp;&amp; isALPHA(c-&gt;srcFormat) &amp;&amp; isALPHA(c-&gt;dstFormat))
+        FF_ALLOCZ_OR_GOTO(c, c-&gt;alpPixBuf, c-&gt;vLumBufSize*2*sizeof(int16_t*), fail);
+    //Note we need at least one pixel more at the end because of the MMX code (just in case someone wanna replace the 4000/8000)
+    /* align at 16 bytes for AltiVec */
+    for (i=0; i&lt;c-&gt;vLumBufSize; i++) {
+        FF_ALLOCZ_OR_GOTO(c, c-&gt;lumPixBuf[i+c-&gt;vLumBufSize], VOF+1, fail);
+        c-&gt;lumPixBuf[i] = c-&gt;lumPixBuf[i+c-&gt;vLumBufSize];
+    }
+    for (i=0; i&lt;c-&gt;vChrBufSize; i++) {
+        FF_ALLOC_OR_GOTO(c, c-&gt;chrPixBuf[i+c-&gt;vChrBufSize], (VOF+1)*2, fail);
+        c-&gt;chrPixBuf[i] = c-&gt;chrPixBuf[i+c-&gt;vChrBufSize];
+    }
+    if (CONFIG_SWSCALE_ALPHA &amp;&amp; c-&gt;alpPixBuf)
+        for (i=0; i&lt;c-&gt;vLumBufSize; i++) {
+            FF_ALLOCZ_OR_GOTO(c, c-&gt;alpPixBuf[i+c-&gt;vLumBufSize], VOF+1, fail);
+            c-&gt;alpPixBuf[i] = c-&gt;alpPixBuf[i+c-&gt;vLumBufSize];
+        }
+
+    //try to avoid drawing green stuff between the right end and the stride end
+    for (i=0; i&lt;c-&gt;vChrBufSize; i++) memset(c-&gt;chrPixBuf[i], 64, (VOF+1)*2);
+
+    assert(2*VOFW == VOF);
+
+    assert(c-&gt;chrDstH &lt;= dstH);
+
+    if (flags&amp;SWS_PRINT_INFO) {
+        if (flags&amp;SWS_FAST_BILINEAR)
+            av_log(c, AV_LOG_INFO, &quot;FAST_BILINEAR scaler, &quot;);
+        else if (flags&amp;SWS_BILINEAR)
+            av_log(c, AV_LOG_INFO, &quot;BILINEAR scaler, &quot;);
+        else if (flags&amp;SWS_BICUBIC)
+            av_log(c, AV_LOG_INFO, &quot;BICUBIC scaler, &quot;);
+        else if (flags&amp;SWS_X)
+            av_log(c, AV_LOG_INFO, &quot;Experimental scaler, &quot;);
+        else if (flags&amp;SWS_POINT)
+            av_log(c, AV_LOG_INFO, &quot;Nearest Neighbor / POINT scaler, &quot;);
+        else if (flags&amp;SWS_AREA)
+            av_log(c, AV_LOG_INFO, &quot;Area Averaging scaler, &quot;);
+        else if (flags&amp;SWS_BICUBLIN)
+            av_log(c, AV_LOG_INFO, &quot;luma BICUBIC / chroma BILINEAR scaler, &quot;);
+        else if (flags&amp;SWS_GAUSS)
+            av_log(c, AV_LOG_INFO, &quot;Gaussian scaler, &quot;);
+        else if (flags&amp;SWS_SINC)
+            av_log(c, AV_LOG_INFO, &quot;Sinc scaler, &quot;);
+        else if (flags&amp;SWS_LANCZOS)
+            av_log(c, AV_LOG_INFO, &quot;Lanczos scaler, &quot;);
+        else if (flags&amp;SWS_SPLINE)
+            av_log(c, AV_LOG_INFO, &quot;Bicubic spline scaler, &quot;);
+        else
+            av_log(c, AV_LOG_INFO, &quot;ehh flags invalid?! &quot;);
+
+        av_log(c, AV_LOG_INFO, &quot;from %s to %s%s &quot;,
+               sws_format_name(srcFormat),
+#ifdef DITHER1XBPP
+               dstFormat == PIX_FMT_BGR555 || dstFormat == PIX_FMT_BGR565 ? &quot;dithered &quot; : &quot;&quot;,
+#else
+               &quot;&quot;,
+#endif
+               sws_format_name(dstFormat));
+
+        if (flags &amp; SWS_CPU_CAPS_MMX2)
+            av_log(c, AV_LOG_INFO, &quot;using MMX2\n&quot;);
+        else if (flags &amp; SWS_CPU_CAPS_3DNOW)
+            av_log(c, AV_LOG_INFO, &quot;using 3DNOW\n&quot;);
+        else if (flags &amp; SWS_CPU_CAPS_MMX)
+            av_log(c, AV_LOG_INFO, &quot;using MMX\n&quot;);
+        else if (flags &amp; SWS_CPU_CAPS_ALTIVEC)
+            av_log(c, AV_LOG_INFO, &quot;using AltiVec\n&quot;);
+        else
+            av_log(c, AV_LOG_INFO, &quot;using C\n&quot;);
+
+        if (flags &amp; SWS_CPU_CAPS_MMX) {
+            if (c-&gt;canMMX2BeUsed &amp;&amp; (flags&amp;SWS_FAST_BILINEAR))
+                av_log(c, AV_LOG_VERBOSE, &quot;using FAST_BILINEAR MMX2 scaler for horizontal scaling\n&quot;);
+            else {
+                if (c-&gt;hLumFilterSize==4)
+                    av_log(c, AV_LOG_VERBOSE, &quot;using 4-tap MMX scaler for horizontal luminance scaling\n&quot;);
+                else if (c-&gt;hLumFilterSize==8)
+                    av_log(c, AV_LOG_VERBOSE, &quot;using 8-tap MMX scaler for horizontal luminance scaling\n&quot;);
+                else
+                    av_log(c, AV_LOG_VERBOSE, &quot;using n-tap MMX scaler for horizontal luminance scaling\n&quot;);
+
+                if (c-&gt;hChrFilterSize==4)
+                    av_log(c, AV_LOG_VERBOSE, &quot;using 4-tap MMX scaler for horizontal chrominance scaling\n&quot;);
+                else if (c-&gt;hChrFilterSize==8)
+                    av_log(c, AV_LOG_VERBOSE, &quot;using 8-tap MMX scaler for horizontal chrominance scaling\n&quot;);
+                else
+                    av_log(c, AV_LOG_VERBOSE, &quot;using n-tap MMX scaler for horizontal chrominance scaling\n&quot;);
+            }
+        } else {
+#if ARCH_X86
+            av_log(c, AV_LOG_VERBOSE, &quot;using x86 asm scaler for horizontal scaling\n&quot;);
+#else
+            if (flags &amp; SWS_FAST_BILINEAR)
+                av_log(c, AV_LOG_VERBOSE, &quot;using FAST_BILINEAR C scaler for horizontal scaling\n&quot;);
+            else
+                av_log(c, AV_LOG_VERBOSE, &quot;using C scaler for horizontal scaling\n&quot;);
+#endif
+        }
+        if (isPlanarYUV(dstFormat)) {
+            if (c-&gt;vLumFilterSize==1)
+                av_log(c, AV_LOG_VERBOSE, &quot;using 1-tap %s \&quot;scaler\&quot; for vertical scaling (YV12 like)\n&quot;, (flags &amp; SWS_CPU_CAPS_MMX) ? &quot;MMX&quot; : &quot;C&quot;);
+            else
+                av_log(c, AV_LOG_VERBOSE, &quot;using n-tap %s scaler for vertical scaling (YV12 like)\n&quot;, (flags &amp; SWS_CPU_CAPS_MMX) ? &quot;MMX&quot; : &quot;C&quot;);
+        } else {
+            if (c-&gt;vLumFilterSize==1 &amp;&amp; c-&gt;vChrFilterSize==2)
+                av_log(c, AV_LOG_VERBOSE, &quot;using 1-tap %s \&quot;scaler\&quot; for vertical luminance scaling (BGR)\n&quot;
+                       &quot;      2-tap scaler for vertical chrominance scaling (BGR)\n&quot;, (flags &amp; SWS_CPU_CAPS_MMX) ? &quot;MMX&quot; : &quot;C&quot;);
+            else if (c-&gt;vLumFilterSize==2 &amp;&amp; c-&gt;vChrFilterSize==2)
+                av_log(c, AV_LOG_VERBOSE, &quot;using 2-tap linear %s scaler for vertical scaling (BGR)\n&quot;, (flags &amp; SWS_CPU_CAPS_MMX) ? &quot;MMX&quot; : &quot;C&quot;);
+            else
+                av_log(c, AV_LOG_VERBOSE, &quot;using n-tap %s scaler for vertical scaling (BGR)\n&quot;, (flags &amp; SWS_CPU_CAPS_MMX) ? &quot;MMX&quot; : &quot;C&quot;);
+        }
+
+        if (dstFormat==PIX_FMT_BGR24)
+            av_log(c, AV_LOG_VERBOSE, &quot;using %s YV12-&gt;BGR24 converter\n&quot;,
+                   (flags &amp; SWS_CPU_CAPS_MMX2) ? &quot;MMX2&quot; : ((flags &amp; SWS_CPU_CAPS_MMX) ? &quot;MMX&quot; : &quot;C&quot;));
+        else if (dstFormat==PIX_FMT_RGB32)
+            av_log(c, AV_LOG_VERBOSE, &quot;using %s YV12-&gt;BGR32 converter\n&quot;, (flags &amp; SWS_CPU_CAPS_MMX) ? &quot;MMX&quot; : &quot;C&quot;);
+        else if (dstFormat==PIX_FMT_BGR565)
+            av_log(c, AV_LOG_VERBOSE, &quot;using %s YV12-&gt;BGR16 converter\n&quot;, (flags &amp; SWS_CPU_CAPS_MMX) ? &quot;MMX&quot; : &quot;C&quot;);
+        else if (dstFormat==PIX_FMT_BGR555)
+            av_log(c, AV_LOG_VERBOSE, &quot;using %s YV12-&gt;BGR15 converter\n&quot;, (flags &amp; SWS_CPU_CAPS_MMX) ? &quot;MMX&quot; : &quot;C&quot;);
+
+        av_log(c, AV_LOG_VERBOSE, &quot;%dx%d -&gt; %dx%d\n&quot;, srcW, srcH, dstW, dstH);
+        av_log(c, AV_LOG_DEBUG, &quot;lum srcW=%d srcH=%d dstW=%d dstH=%d xInc=%d yInc=%d\n&quot;,
+               c-&gt;srcW, c-&gt;srcH, c-&gt;dstW, c-&gt;dstH, c-&gt;lumXInc, c-&gt;lumYInc);
+        av_log(c, AV_LOG_DEBUG, &quot;chr srcW=%d srcH=%d dstW=%d dstH=%d xInc=%d yInc=%d\n&quot;,
+               c-&gt;chrSrcW, c-&gt;chrSrcH, c-&gt;chrDstW, c-&gt;chrDstH, c-&gt;chrXInc, c-&gt;chrYInc);
+    }
+
+    c-&gt;swScale= ff_getSwsFunc(c);
+    return c;
+
+fail:
+    sws_freeContext(c);
+    return NULL;
+}
+
+SwsFilter *sws_getDefaultFilter(float lumaGBlur, float chromaGBlur,
+                                float lumaSharpen, float chromaSharpen,
+                                float chromaHShift, float chromaVShift,
+                                int verbose)
+{
+    SwsFilter *filter= av_malloc(sizeof(SwsFilter));
+    if (!filter)
+        return NULL;
+
+    if (lumaGBlur!=0.0) {
+        filter-&gt;lumH= sws_getGaussianVec(lumaGBlur, 3.0);
+        filter-&gt;lumV= sws_getGaussianVec(lumaGBlur, 3.0);
+    } else {
+        filter-&gt;lumH= sws_getIdentityVec();
+        filter-&gt;lumV= sws_getIdentityVec();
+    }
+
+    if (chromaGBlur!=0.0) {
+        filter-&gt;chrH= sws_getGaussianVec(chromaGBlur, 3.0);
+        filter-&gt;chrV= sws_getGaussianVec(chromaGBlur, 3.0);
+    } else {
+        filter-&gt;chrH= sws_getIdentityVec();
+        filter-&gt;chrV= sws_getIdentityVec();
+    }
+
+    if (chromaSharpen!=0.0) {
+        SwsVector *id= sws_getIdentityVec();
+        sws_scaleVec(filter-&gt;chrH, -chromaSharpen);
+        sws_scaleVec(filter-&gt;chrV, -chromaSharpen);
+        sws_addVec(filter-&gt;chrH, id);
+        sws_addVec(filter-&gt;chrV, id);
+        sws_freeVec(id);
+    }
+
+    if (lumaSharpen!=0.0) {
+        SwsVector *id= sws_getIdentityVec();
+        sws_scaleVec(filter-&gt;lumH, -lumaSharpen);
+        sws_scaleVec(filter-&gt;lumV, -lumaSharpen);
+        sws_addVec(filter-&gt;lumH, id);
+        sws_addVec(filter-&gt;lumV, id);
+        sws_freeVec(id);
+    }
+
+    if (chromaHShift != 0.0)
+        sws_shiftVec(filter-&gt;chrH, (int)(chromaHShift+0.5));
+
+    if (chromaVShift != 0.0)
+        sws_shiftVec(filter-&gt;chrV, (int)(chromaVShift+0.5));
+
+    sws_normalizeVec(filter-&gt;chrH, 1.0);
+    sws_normalizeVec(filter-&gt;chrV, 1.0);
+    sws_normalizeVec(filter-&gt;lumH, 1.0);
+    sws_normalizeVec(filter-&gt;lumV, 1.0);
+
+    if (verbose) sws_printVec2(filter-&gt;chrH, NULL, AV_LOG_DEBUG);
+    if (verbose) sws_printVec2(filter-&gt;lumH, NULL, AV_LOG_DEBUG);
+
+    return filter;
+}
+
+SwsVector *sws_allocVec(int length)
+{
+    SwsVector *vec = av_malloc(sizeof(SwsVector));
+    if (!vec)
+        return NULL;
+    vec-&gt;length = length;
+    vec-&gt;coeff  = av_malloc(sizeof(double) * length);
+    if (!vec-&gt;coeff)
+        av_freep(&amp;vec);
+    return vec;
+}
+
+SwsVector *sws_getGaussianVec(double variance, double quality)
+{
+    const int length= (int)(variance*quality + 0.5) | 1;
+    int i;
+    double middle= (length-1)*0.5;
+    SwsVector *vec= sws_allocVec(length);
+
+    if (!vec)
+        return NULL;
+
+    for (i=0; i&lt;length; i++) {
+        double dist= i-middle;
+        vec-&gt;coeff[i]= exp(-dist*dist/(2*variance*variance)) / sqrt(2*variance*M_PI);
+    }
+
+    sws_normalizeVec(vec, 1.0);
+
+    return vec;
+}
+
+SwsVector *sws_getConstVec(double c, int length)
+{
+    int i;
+    SwsVector *vec= sws_allocVec(length);
+
+    if (!vec)
+        return NULL;
+
+    for (i=0; i&lt;length; i++)
+        vec-&gt;coeff[i]= c;
+
+    return vec;
+}
+
+SwsVector *sws_getIdentityVec(void)
+{
+    return sws_getConstVec(1.0, 1);
+}
+
+double sws_dcVec(SwsVector *a)
+{
+    int i;
+    double sum=0;
+
+    for (i=0; i&lt;a-&gt;length; i++)
+        sum+= a-&gt;coeff[i];
+
+    return sum;
+}
+
+void sws_scaleVec(SwsVector *a, double scalar)
+{
+    int i;
+
+    for (i=0; i&lt;a-&gt;length; i++)
+        a-&gt;coeff[i]*= scalar;
+}
+
+void sws_normalizeVec(SwsVector *a, double height)
+{
+    sws_scaleVec(a, height/sws_dcVec(a));
+}
+
+static SwsVector *sws_getConvVec(SwsVector *a, SwsVector *b)
+{
+    int length= a-&gt;length + b-&gt;length - 1;
+    int i, j;
+    SwsVector *vec= sws_getConstVec(0.0, length);
+
+    if (!vec)
+        return NULL;
+
+    for (i=0; i&lt;a-&gt;length; i++) {
+        for (j=0; j&lt;b-&gt;length; j++) {
+            vec-&gt;coeff[i+j]+= a-&gt;coeff[i]*b-&gt;coeff[j];
+        }
+    }
+
+    return vec;
+}
+
+static SwsVector *sws_sumVec(SwsVector *a, SwsVector *b)
+{
+    int length= FFMAX(a-&gt;length, b-&gt;length);
+    int i;
+    SwsVector *vec= sws_getConstVec(0.0, length);
+
+    if (!vec)
+        return NULL;
+
+    for (i=0; i&lt;a-&gt;length; i++) vec-&gt;coeff[i + (length-1)/2 - (a-&gt;length-1)/2]+= a-&gt;coeff[i];
+    for (i=0; i&lt;b-&gt;length; i++) vec-&gt;coeff[i + (length-1)/2 - (b-&gt;length-1)/2]+= b-&gt;coeff[i];
+
+    return vec;
+}
+
+static SwsVector *sws_diffVec(SwsVector *a, SwsVector *b)
+{
+    int length= FFMAX(a-&gt;length, b-&gt;length);
+    int i;
+    SwsVector *vec= sws_getConstVec(0.0, length);
+
+    if (!vec)
+        return NULL;
+
+    for (i=0; i&lt;a-&gt;length; i++) vec-&gt;coeff[i + (length-1)/2 - (a-&gt;length-1)/2]+= a-&gt;coeff[i];
+    for (i=0; i&lt;b-&gt;length; i++) vec-&gt;coeff[i + (length-1)/2 - (b-&gt;length-1)/2]-= b-&gt;coeff[i];
+
+    return vec;
+}
+
+/* shift left / or right if &quot;shift&quot; is negative */
+static SwsVector *sws_getShiftedVec(SwsVector *a, int shift)
+{
+    int length= a-&gt;length + FFABS(shift)*2;
+    int i;
+    SwsVector *vec= sws_getConstVec(0.0, length);
+
+    if (!vec)
+        return NULL;
+
+    for (i=0; i&lt;a-&gt;length; i++) {
+        vec-&gt;coeff[i + (length-1)/2 - (a-&gt;length-1)/2 - shift]= a-&gt;coeff[i];
+    }
+
+    return vec;
+}
+
+void sws_shiftVec(SwsVector *a, int shift)
+{
+    SwsVector *shifted= sws_getShiftedVec(a, shift);
+    av_free(a-&gt;coeff);
+    a-&gt;coeff= shifted-&gt;coeff;
+    a-&gt;length= shifted-&gt;length;
+    av_free(shifted);
+}
+
+void sws_addVec(SwsVector *a, SwsVector *b)
+{
+    SwsVector *sum= sws_sumVec(a, b);
+    av_free(a-&gt;coeff);
+    a-&gt;coeff= sum-&gt;coeff;
+    a-&gt;length= sum-&gt;length;
+    av_free(sum);
+}
+
+void sws_subVec(SwsVector *a, SwsVector *b)
+{
+    SwsVector *diff= sws_diffVec(a, b);
+    av_free(a-&gt;coeff);
+    a-&gt;coeff= diff-&gt;coeff;
+    a-&gt;length= diff-&gt;length;
+    av_free(diff);
+}
+
+void sws_convVec(SwsVector *a, SwsVector *b)
+{
+    SwsVector *conv= sws_getConvVec(a, b);
+    av_free(a-&gt;coeff);
+    a-&gt;coeff= conv-&gt;coeff;
+    a-&gt;length= conv-&gt;length;
+    av_free(conv);
+}
+
+SwsVector *sws_cloneVec(SwsVector *a)
+{
+    int i;
+    SwsVector *vec= sws_allocVec(a-&gt;length);
+
+    if (!vec)
+        return NULL;
+
+    for (i=0; i&lt;a-&gt;length; i++) vec-&gt;coeff[i]= a-&gt;coeff[i];
+
+    return vec;
+}
+
+void sws_printVec2(SwsVector *a, AVClass *log_ctx, int log_level)
+{
+    int i;
+    double max=0;
+    double min=0;
+    double range;
+
+    for (i=0; i&lt;a-&gt;length; i++)
+        if (a-&gt;coeff[i]&gt;max) max= a-&gt;coeff[i];
+
+    for (i=0; i&lt;a-&gt;length; i++)
+        if (a-&gt;coeff[i]&lt;min) min= a-&gt;coeff[i];
+
+    range= max - min;
+
+    for (i=0; i&lt;a-&gt;length; i++) {
+        int x= (int)((a-&gt;coeff[i]-min)*60.0/range +0.5);
+        av_log(log_ctx, log_level, &quot;%1.3f &quot;, a-&gt;coeff[i]);
+        for (;x&gt;0; x--) av_log(log_ctx, log_level, &quot; &quot;);
+        av_log(log_ctx, log_level, &quot;|\n&quot;);
+    }
+}
+
+#if LIBSWSCALE_VERSION_MAJOR &lt; 1
+void sws_printVec(SwsVector *a)
+{
+    sws_printVec2(a, NULL, AV_LOG_DEBUG);
+}
+#endif
+
+void sws_freeVec(SwsVector *a)
+{
+    if (!a) return;
+    av_freep(&amp;a-&gt;coeff);
+    a-&gt;length=0;
+    av_free(a);
+}
+
+void sws_freeFilter(SwsFilter *filter)
+{
+    if (!filter) return;
+
+    if (filter-&gt;lumH) sws_freeVec(filter-&gt;lumH);
+    if (filter-&gt;lumV) sws_freeVec(filter-&gt;lumV);
+    if (filter-&gt;chrH) sws_freeVec(filter-&gt;chrH);
+    if (filter-&gt;chrV) sws_freeVec(filter-&gt;chrV);
+    av_free(filter);
+}
+
+void sws_freeContext(SwsContext *c)
+{
+    int i;
+    if (!c) return;
+
+    if (c-&gt;lumPixBuf) {
+        for (i=0; i&lt;c-&gt;vLumBufSize; i++)
+            av_freep(&amp;c-&gt;lumPixBuf[i]);
+        av_freep(&amp;c-&gt;lumPixBuf);
+    }
+
+    if (c-&gt;chrPixBuf) {
+        for (i=0; i&lt;c-&gt;vChrBufSize; i++)
+            av_freep(&amp;c-&gt;chrPixBuf[i]);
+        av_freep(&amp;c-&gt;chrPixBuf);
+    }
+
+    if (CONFIG_SWSCALE_ALPHA &amp;&amp; c-&gt;alpPixBuf) {
+        for (i=0; i&lt;c-&gt;vLumBufSize; i++)
+            av_freep(&amp;c-&gt;alpPixBuf[i]);
+        av_freep(&amp;c-&gt;alpPixBuf);
+    }
+
+    av_freep(&amp;c-&gt;vLumFilter);
+    av_freep(&amp;c-&gt;vChrFilter);
+    av_freep(&amp;c-&gt;hLumFilter);
+    av_freep(&amp;c-&gt;hChrFilter);
+#if ARCH_PPC &amp;&amp; (HAVE_ALTIVEC || CONFIG_RUNTIME_CPUDETECT)
+    av_freep(&amp;c-&gt;vYCoeffsBank);
+    av_freep(&amp;c-&gt;vCCoeffsBank);
+#endif
+
+    av_freep(&amp;c-&gt;vLumFilterPos);
+    av_freep(&amp;c-&gt;vChrFilterPos);
+    av_freep(&amp;c-&gt;hLumFilterPos);
+    av_freep(&amp;c-&gt;hChrFilterPos);
+
+#if ARCH_X86 &amp;&amp; CONFIG_GPL
+#ifdef MAP_ANONYMOUS
+    if (c-&gt;lumMmx2FilterCode) munmap(c-&gt;lumMmx2FilterCode, c-&gt;lumMmx2FilterCodeSize);
+    if (c-&gt;chrMmx2FilterCode) munmap(c-&gt;chrMmx2FilterCode, c-&gt;chrMmx2FilterCodeSize);
+#elif HAVE_VIRTUALALLOC
+    if (c-&gt;lumMmx2FilterCode) VirtualFree(c-&gt;lumMmx2FilterCode, c-&gt;lumMmx2FilterCodeSize, MEM_RELEASE);
+    if (c-&gt;chrMmx2FilterCode) VirtualFree(c-&gt;chrMmx2FilterCode, c-&gt;chrMmx2FilterCodeSize, MEM_RELEASE);
+#else
+    av_free(c-&gt;lumMmx2FilterCode);
+    av_free(c-&gt;chrMmx2FilterCode);
+#endif
+    c-&gt;lumMmx2FilterCode=NULL;
+    c-&gt;chrMmx2FilterCode=NULL;
+#endif /* ARCH_X86 &amp;&amp; CONFIG_GPL */
+
+    av_freep(&amp;c-&gt;yuvTable);
+
+    av_free(c);
+}
+
+struct SwsContext *sws_getCachedContext(struct SwsContext *context,
+                                        int srcW, int srcH, enum PixelFormat srcFormat,
+                                        int dstW, int dstH, enum PixelFormat dstFormat, int flags,
+                                        SwsFilter *srcFilter, SwsFilter *dstFilter, const double *param)
+{
+    static const double default_param[2] = {SWS_PARAM_DEFAULT, SWS_PARAM_DEFAULT};
+
+    if (!param)
+        param = default_param;
+
+    if (context &amp;&amp;
+        (context-&gt;srcW      != srcW      ||
+         context-&gt;srcH      != srcH      ||
+         context-&gt;srcFormat != srcFormat ||
+         context-&gt;dstW      != dstW      ||
+         context-&gt;dstH      != dstH      ||
+         context-&gt;dstFormat != dstFormat ||
+         context-&gt;flags     != flags     ||
+         context-&gt;param[0]  != param[0]  ||
+         context-&gt;param[1]  != param[1])) {
+        sws_freeContext(context);
+        context = NULL;
+    }
+
+    if (!context) {
+        return sws_getContext(srcW, srcH, srcFormat,
+                              dstW, dstH, dstFormat, flags,
+                              srcFilter, dstFilter, param);
+    }
+    return context;
+}
+

Modified: branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/x86/yuv2rgb_mmx.c
===================================================================
--- branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/x86/yuv2rgb_mmx.c	2010-05-26 05:26:42 UTC (rev 6237)
+++ branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/x86/yuv2rgb_mmx.c	2010-05-26 05:26:46 UTC (rev 6238)
@@ -72,7 +72,8 @@
                 if (HAVE_7REGS) return yuva420_bgr32_MMX2;
                 break;
             } else return yuv420_bgr32_MMX2;
-        case PIX_FMT_BGR24:  return yuv420_rgb24_MMX2;
+        case PIX_FMT_RGB24:  return yuv420_rgb24_MMX2;
+        case PIX_FMT_BGR24:  return yuv420_bgr24_MMX2;
         case PIX_FMT_RGB565: return yuv420_rgb16_MMX2;
         case PIX_FMT_RGB555: return yuv420_rgb15_MMX2;
         }
@@ -89,7 +90,8 @@
                 if (HAVE_7REGS) return yuva420_bgr32_MMX;
                 break;
             } else return yuv420_bgr32_MMX;
-        case PIX_FMT_BGR24:  return yuv420_rgb24_MMX;
+        case PIX_FMT_RGB24:  return yuv420_rgb24_MMX;
+        case PIX_FMT_BGR24:  return yuv420_bgr24_MMX;
         case PIX_FMT_RGB565: return yuv420_rgb16_MMX;
         case PIX_FMT_RGB555: return yuv420_rgb15_MMX;
         }

Modified: branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/x86/yuv2rgb_template.c
===================================================================
--- branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/x86/yuv2rgb_template.c	2010-05-26 05:26:42 UTC (rev 6237)
+++ branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/x86/yuv2rgb_template.c	2010-05-26 05:26:46 UTC (rev 6238)
@@ -42,7 +42,7 @@
 #define SFENCE &quot;sfence&quot;
 #else
 #define MOVNTQ &quot;movq&quot;
-#define SFENCE &quot;/nop&quot;
+#define SFENCE &quot; # nop&quot;
 #endif
 
 #define YUV2RGB \
@@ -134,9 +134,9 @@
     __asm__ volatile (&quot;pxor %mm4, %mm4;&quot; /* zero mm4 */ );    \
     for (y= 0; y&lt;srcSliceH; y++ ) {                           \
         uint8_t *image = dst[0] + (y+srcSliceY)*dstStride[0]; \
-        uint8_t *py = src[0] + y*srcStride[0];                \
-        uint8_t *pu = src[1] + (y&gt;&gt;1)*srcStride[1];           \
-        uint8_t *pv = src[2] + (y&gt;&gt;1)*srcStride[2];           \
+        const uint8_t *py = src[0] + y*srcStride[0];          \
+        const uint8_t *pu = src[1] + (y&gt;&gt;1)*srcStride[1];     \
+        const uint8_t *pv = src[2] + (y&gt;&gt;1)*srcStride[2];     \
         x86_reg index= -h_size/2;                                \
 
 #define YUV2RGB_INIT                                                       \
@@ -168,7 +168,7 @@
         : &quot;r&quot; (pu - index), &quot;r&quot; (pv - index), &quot;r&quot;(&amp;c-&gt;redDither), &quot;r&quot; (py - 2*index) \
         ); \
     } \
-    __asm__ volatile (EMMS); \
+    __asm__ volatile (SFENCE&quot;\n\t&quot;EMMS); \
     return srcSliceH; \
 
 #define YUV2RGB_OPERANDS_ALPHA \
@@ -176,10 +176,10 @@
         : &quot;r&quot; (pu - index), &quot;r&quot; (pv - index), &quot;r&quot;(&amp;c-&gt;redDither), &quot;r&quot; (py - 2*index), &quot;r&quot; (pa - 2*index) \
         ); \
     } \
-    __asm__ volatile (EMMS); \
+    __asm__ volatile (SFENCE&quot;\n\t&quot;EMMS); \
     return srcSliceH; \
 
-static inline int RENAME(yuv420_rgb16)(SwsContext *c, uint8_t* src[], int srcStride[], int srcSliceY,
+static inline int RENAME(yuv420_rgb16)(SwsContext *c, const uint8_t* src[], int srcStride[], int srcSliceY,
                                        int srcSliceH, uint8_t* dst[], int dstStride[])
 {
     int y, h_size;
@@ -236,7 +236,7 @@
     YUV2RGB_OPERANDS
 }
 
-static inline int RENAME(yuv420_rgb15)(SwsContext *c, uint8_t* src[], int srcStride[], int srcSliceY,
+static inline int RENAME(yuv420_rgb15)(SwsContext *c, const uint8_t* src[], int srcStride[], int srcSliceY,
                                        int srcSliceH, uint8_t* dst[], int dstStride[])
 {
     int y, h_size;
@@ -295,7 +295,108 @@
     YUV2RGB_OPERANDS
 }
 
-static inline int RENAME(yuv420_rgb24)(SwsContext *c, uint8_t* src[], int srcStride[], int srcSliceY,
+#undef RGB_PLANAR2PACKED24
+#if HAVE_MMX2
+#define RGB_PLANAR2PACKED24(red, blue)\
+        &quot;movq &quot;MANGLE(ff_M24A)&quot;, %%mm4     \n\t&quot;\
+        &quot;movq &quot;MANGLE(ff_M24C)&quot;, %%mm7     \n\t&quot;\
+        &quot;pshufw $0x50, %%mm&quot;blue&quot;, %%mm5   \n\t&quot; /* B3 B2 B3 B2  B1 B0 B1 B0 */\
+        &quot;pshufw $0x50, %%mm2, %%mm3     \n\t&quot; /* G3 G2 G3 G2  G1 G0 G1 G0 */\
+        &quot;pshufw $0x00, %%mm&quot;red&quot;, %%mm6 \n\t&quot; /* R1 R0 R1 R0  R1 R0 R1 R0 */\
+\
+        &quot;pand   %%mm4, %%mm5            \n\t&quot; /*    B2        B1       B0 */\
+        &quot;pand   %%mm4, %%mm3            \n\t&quot; /*    G2        G1       G0 */\
+        &quot;pand   %%mm7, %%mm6            \n\t&quot; /*       R1        R0       */\
+\
+        &quot;psllq     $8, %%mm3            \n\t&quot; /* G2        G1       G0    */\
+        &quot;por    %%mm5, %%mm6            \n\t&quot;\
+        &quot;por    %%mm3, %%mm6            \n\t&quot;\
+        MOVNTQ&quot; %%mm6, (%1)             \n\t&quot;\
+\
+        &quot;psrlq     $8, %%mm2            \n\t&quot; /* 00 G7 G6 G5  G4 G3 G2 G1 */\
+        &quot;pshufw $0xA5, %%mm&quot;blue&quot;, %%mm5\n\t&quot; /* B5 B4 B5 B4  B3 B2 B3 B2 */\
+        &quot;pshufw $0x55, %%mm2, %%mm3     \n\t&quot; /* G4 G3 G4 G3  G4 G3 G4 G3 */\
+        &quot;pshufw $0xA5, %%mm&quot;red&quot;, %%mm6 \n\t&quot; /* R5 R4 R5 R4  R3 R2 R3 R2 */\
+\
+        &quot;pand &quot;MANGLE(ff_M24B)&quot;, %%mm5  \n\t&quot; /* B5       B4        B3    */\
+        &quot;pand          %%mm7, %%mm3     \n\t&quot; /*       G4        G3       */\
+        &quot;pand          %%mm4, %%mm6     \n\t&quot; /*    R4        R3       R2 */\
+\
+        &quot;por    %%mm5, %%mm3            \n\t&quot; /* B5    G4 B4     G3 B3    */\
+        &quot;por    %%mm3, %%mm6            \n\t&quot;\
+        MOVNTQ&quot; %%mm6, 8(%1)            \n\t&quot;\
+\
+        &quot;pshufw $0xFF, %%mm&quot;blue&quot;, %%mm5\n\t&quot; /* B7 B6 B7 B6  B7 B6 B6 B7 */\
+        &quot;pshufw $0xFA, %%mm2, %%mm3     \n\t&quot; /* 00 G7 00 G7  G6 G5 G6 G5 */\
+        &quot;pshufw $0xFA, %%mm&quot;red&quot;, %%mm6 \n\t&quot; /* R7 R6 R7 R6  R5 R4 R5 R4 */\
+        &quot;movd 4 (%2, %0), %%mm0;&quot; /* Load 4 Cb 00 00 00 00 u3 u2 u1 u0 */\
+\
+        &quot;pand          %%mm7, %%mm5     \n\t&quot; /*       B7        B6       */\
+        &quot;pand          %%mm4, %%mm3     \n\t&quot; /*    G7        G6       G5 */\
+        &quot;pand &quot;MANGLE(ff_M24B)&quot;, %%mm6  \n\t&quot; /* R7       R6        R5    */\
+        &quot;movd 4 (%3, %0), %%mm1;&quot; /* Load 4 Cr 00 00 00 00 v3 v2 v1 v0 */\
+\
+        &quot;por          %%mm5, %%mm3      \n\t&quot;\
+        &quot;por          %%mm3, %%mm6      \n\t&quot;\
+        MOVNTQ&quot;       %%mm6, 16(%1)     \n\t&quot;\
+        &quot;movq 8 (%5, %0, 2), %%mm6;&quot; /* Load 8 Y Y7 Y6 Y5 Y4 Y3 Y2 Y1 Y0 */\
+        &quot;pxor         %%mm4, %%mm4      \n\t&quot;
+#else
+#define RGB_PLANAR2PACKED24(red, blue)\
+        &quot;pxor      %%mm4, %%mm4     \n\t&quot;\
+        &quot;movq      %%mm&quot;blue&quot;, %%mm5\n\t&quot; /* B */\
+        &quot;movq      %%mm&quot;red&quot;, %%mm6 \n\t&quot; /* R */\
+        &quot;punpcklbw %%mm2, %%mm&quot;blue&quot;\n\t&quot; /* GBGBGBGB 0 */\
+        &quot;punpcklbw %%mm4, %%mm&quot;red&quot; \n\t&quot; /* 0R0R0R0R 0 */\
+        &quot;punpckhbw %%mm2, %%mm5     \n\t&quot; /* GBGBGBGB 2 */\
+        &quot;punpckhbw %%mm4, %%mm6     \n\t&quot; /* 0R0R0R0R 2 */\
+        &quot;movq      %%mm&quot;blue&quot;, %%mm7\n\t&quot; /* GBGBGBGB 0 */\
+        &quot;movq      %%mm5, %%mm3     \n\t&quot; /* GBGBGBGB 2 */\
+        &quot;punpcklwd %%mm&quot;red&quot;, %%mm7 \n\t&quot; /* 0RGB0RGB 0 */\
+        &quot;punpckhwd %%mm&quot;red&quot;, %%mm&quot;blue&quot;\n\t&quot; /* 0RGB0RGB 1 */\
+        &quot;punpcklwd %%mm6, %%mm5     \n\t&quot; /* 0RGB0RGB 2 */\
+        &quot;punpckhwd %%mm6, %%mm3     \n\t&quot; /* 0RGB0RGB 3 */\
+\
+        &quot;movq      %%mm7, %%mm2     \n\t&quot; /* 0RGB0RGB 0 */\
+        &quot;movq      %%mm&quot;blue&quot;, %%mm6\n\t&quot; /* 0RGB0RGB 1 */\
+        &quot;movq      %%mm5, %%mm&quot;red&quot; \n\t&quot; /* 0RGB0RGB 2 */\
+        &quot;movq      %%mm3, %%mm4     \n\t&quot; /* 0RGB0RGB 3 */\
+\
+        &quot;psllq       $40, %%mm7     \n\t&quot; /* RGB00000 0 */\
+        &quot;psllq       $40, %%mm&quot;blue&quot;\n\t&quot; /* RGB00000 1 */\
+        &quot;psllq       $40, %%mm5     \n\t&quot; /* RGB00000 2 */\
+        &quot;psllq       $40, %%mm3     \n\t&quot; /* RGB00000 3 */\
+\
+        &quot;punpckhdq %%mm2, %%mm7     \n\t&quot; /* 0RGBRGB0 0 */\
+        &quot;punpckhdq %%mm6, %%mm&quot;blue&quot;\n\t&quot; /* 0RGBRGB0 1 */\
+        &quot;punpckhdq %%mm&quot;red&quot;, %%mm5 \n\t&quot; /* 0RGBRGB0 2 */\
+        &quot;punpckhdq %%mm4, %%mm3     \n\t&quot; /* 0RGBRGB0 3 */\
+\
+        &quot;psrlq        $8, %%mm7     \n\t&quot; /* 00RGBRGB 0 */\
+        &quot;movq      %%mm&quot;blue&quot;, %%mm6\n\t&quot; /* 0RGBRGB0 1 */\
+        &quot;psllq       $40, %%mm&quot;blue&quot;\n\t&quot; /* GB000000 1 */\
+        &quot;por       %%mm&quot;blue&quot;, %%mm7\n\t&quot; /* GBRGBRGB 0 */\
+        MOVNTQ&quot;    %%mm7, (%1)      \n\t&quot;\
+\
+        &quot;psrlq       $24, %%mm6     \n\t&quot; /* 0000RGBR 1 */\
+        &quot;movq      %%mm5, %%mm&quot;red&quot; \n\t&quot; /* 0RGBRGB0 2 */\
+        &quot;psllq       $24, %%mm5     \n\t&quot; /* BRGB0000 2 */\
+        &quot;por       %%mm5, %%mm6     \n\t&quot; /* BRGBRGBR 1 */\
+        MOVNTQ&quot;    %%mm6, 8(%1)     \n\t&quot;\
+\
+        &quot;movq 8 (%5, %0, 2), %%mm6;&quot; /* Load 8 Y Y7 Y6 Y5 Y4 Y3 Y2 Y1 Y0 */\
+\
+        &quot;psrlq       $40, %%mm&quot;red&quot; \n\t&quot; /* 000000RG 2 */\
+        &quot;psllq        $8, %%mm3     \n\t&quot; /* RGBRGB00 3 */\
+        &quot;por       %%mm3, %%mm&quot;red&quot; \n\t&quot; /* RGBRGBRG 2 */\
+        MOVNTQ&quot;    %%mm&quot;red&quot;, 16(%1)\n\t&quot;\
+\
+        &quot;movd 4 (%3, %0), %%mm1;&quot; /* Load 4 Cr 00 00 00 00 v3 v2 v1 v0 */\
+        &quot;movd 4 (%2, %0), %%mm0;&quot; /* Load 4 Cb 00 00 00 00 u3 u2 u1 u0 */\
+        &quot;pxor      %%mm4, %%mm4     \n\t&quot;
+#endif
+
+static inline int RENAME(yuv420_rgb24)(SwsContext *c, const uint8_t* src[], int srcStride[], int srcSliceY,
                                        int srcSliceH, uint8_t* dst[], int dstStride[])
 {
     int y, h_size;
@@ -306,107 +407,25 @@
         YUV2RGB_INIT
         YUV2RGB
         /* mm0=B, %%mm2=G, %%mm1=R */
-#if HAVE_MMX2
-        &quot;movq &quot;MANGLE(ff_M24A)&quot;, %%mm4     \n\t&quot;
-        &quot;movq &quot;MANGLE(ff_M24C)&quot;, %%mm7     \n\t&quot;
-        &quot;pshufw $0x50, %%mm0, %%mm5     \n\t&quot; /* B3 B2 B3 B2  B1 B0 B1 B0 */
-        &quot;pshufw $0x50, %%mm2, %%mm3     \n\t&quot; /* G3 G2 G3 G2  G1 G0 G1 G0 */
-        &quot;pshufw $0x00, %%mm1, %%mm6     \n\t&quot; /* R1 R0 R1 R0  R1 R0 R1 R0 */
+        RGB_PLANAR2PACKED24(&quot;0&quot;, &quot;1&quot;)
 
-        &quot;pand   %%mm4, %%mm5            \n\t&quot; /*    B2        B1       B0 */
-        &quot;pand   %%mm4, %%mm3            \n\t&quot; /*    G2        G1       G0 */
-        &quot;pand   %%mm7, %%mm6            \n\t&quot; /*       R1        R0       */
+    YUV2RGB_ENDLOOP(3)
+    YUV2RGB_OPERANDS
+}
 
-        &quot;psllq     $8, %%mm3            \n\t&quot; /* G2        G1       G0    */
-        &quot;por    %%mm5, %%mm6            \n\t&quot;
-        &quot;por    %%mm3, %%mm6            \n\t&quot;
-        MOVNTQ&quot; %%mm6, (%1)             \n\t&quot;
+static inline int RENAME(yuv420_bgr24)(SwsContext *c, const uint8_t* src[], int srcStride[], int srcSliceY,
+                                       int srcSliceH, uint8_t* dst[], int dstStride[])
+{
+    int y, h_size;
 
-        &quot;psrlq     $8, %%mm2            \n\t&quot; /* 00 G7 G6 G5  G4 G3 G2 G1 */
-        &quot;pshufw $0xA5, %%mm0, %%mm5     \n\t&quot; /* B5 B4 B5 B4  B3 B2 B3 B2 */
-        &quot;pshufw $0x55, %%mm2, %%mm3     \n\t&quot; /* G4 G3 G4 G3  G4 G3 G4 G3 */
-        &quot;pshufw $0xA5, %%mm1, %%mm6     \n\t&quot; /* R5 R4 R5 R4  R3 R2 R3 R2 */
+    YUV422_UNSHIFT
+    YUV2RGB_LOOP(3)
 
-        &quot;pand &quot;MANGLE(ff_M24B)&quot;, %%mm5     \n\t&quot; /* B5       B4        B3    */
-        &quot;pand          %%mm7, %%mm3     \n\t&quot; /*       G4        G3       */
-        &quot;pand          %%mm4, %%mm6     \n\t&quot; /*    R4        R3       R2 */
+        YUV2RGB_INIT
+        YUV2RGB
+        /* mm0=B, %%mm2=G, %%mm1=R */
+        RGB_PLANAR2PACKED24(&quot;1&quot;, &quot;0&quot;)
 
-        &quot;por    %%mm5, %%mm3            \n\t&quot; /* B5    G4 B4     G3 B3    */
-        &quot;por    %%mm3, %%mm6            \n\t&quot;
-        MOVNTQ&quot; %%mm6, 8(%1)            \n\t&quot;
-
-        &quot;pshufw $0xFF, %%mm0, %%mm5     \n\t&quot; /* B7 B6 B7 B6  B7 B6 B6 B7 */
-        &quot;pshufw $0xFA, %%mm2, %%mm3     \n\t&quot; /* 00 G7 00 G7  G6 G5 G6 G5 */
-        &quot;pshufw $0xFA, %%mm1, %%mm6     \n\t&quot; /* R7 R6 R7 R6  R5 R4 R5 R4 */
-        &quot;movd 4 (%2, %0), %%mm0;&quot; /* Load 4 Cb 00 00 00 00 u3 u2 u1 u0 */
-
-        &quot;pand          %%mm7, %%mm5     \n\t&quot; /*       B7        B6       */
-        &quot;pand          %%mm4, %%mm3     \n\t&quot; /*    G7        G6       G5 */
-        &quot;pand &quot;MANGLE(ff_M24B)&quot;, %%mm6     \n\t&quot; /* R7       R6        R5    */
-        &quot;movd 4 (%3, %0), %%mm1;&quot; /* Load 4 Cr 00 00 00 00 v3 v2 v1 v0 */
-\
-        &quot;por          %%mm5, %%mm3      \n\t&quot;
-        &quot;por          %%mm3, %%mm6      \n\t&quot;
-        MOVNTQ&quot;       %%mm6, 16(%1)     \n\t&quot;
-        &quot;movq 8 (%5, %0, 2), %%mm6;&quot; /* Load 8 Y Y7 Y6 Y5 Y4 Y3 Y2 Y1 Y0 */
-        &quot;pxor         %%mm4, %%mm4      \n\t&quot;
-
-#else
-
-        &quot;pxor      %%mm4, %%mm4     \n\t&quot;
-        &quot;movq      %%mm0, %%mm5     \n\t&quot; /* B */
-        &quot;movq      %%mm1, %%mm6     \n\t&quot; /* R */
-        &quot;punpcklbw %%mm2, %%mm0     \n\t&quot; /* GBGBGBGB 0 */
-        &quot;punpcklbw %%mm4, %%mm1     \n\t&quot; /* 0R0R0R0R 0 */
-        &quot;punpckhbw %%mm2, %%mm5     \n\t&quot; /* GBGBGBGB 2 */
-        &quot;punpckhbw %%mm4, %%mm6     \n\t&quot; /* 0R0R0R0R 2 */
-        &quot;movq      %%mm0, %%mm7     \n\t&quot; /* GBGBGBGB 0 */
-        &quot;movq      %%mm5, %%mm3     \n\t&quot; /* GBGBGBGB 2 */
-        &quot;punpcklwd %%mm1, %%mm7     \n\t&quot; /* 0RGB0RGB 0 */
-        &quot;punpckhwd %%mm1, %%mm0     \n\t&quot; /* 0RGB0RGB 1 */
-        &quot;punpcklwd %%mm6, %%mm5     \n\t&quot; /* 0RGB0RGB 2 */
-        &quot;punpckhwd %%mm6, %%mm3     \n\t&quot; /* 0RGB0RGB 3 */
-
-        &quot;movq      %%mm7, %%mm2     \n\t&quot; /* 0RGB0RGB 0 */
-        &quot;movq      %%mm0, %%mm6     \n\t&quot; /* 0RGB0RGB 1 */
-        &quot;movq      %%mm5, %%mm1     \n\t&quot; /* 0RGB0RGB 2 */
-        &quot;movq      %%mm3, %%mm4     \n\t&quot; /* 0RGB0RGB 3 */
-
-        &quot;psllq       $40, %%mm7     \n\t&quot; /* RGB00000 0 */
-        &quot;psllq       $40, %%mm0     \n\t&quot; /* RGB00000 1 */
-        &quot;psllq       $40, %%mm5     \n\t&quot; /* RGB00000 2 */
-        &quot;psllq       $40, %%mm3     \n\t&quot; /* RGB00000 3 */
-
-        &quot;punpckhdq %%mm2, %%mm7     \n\t&quot; /* 0RGBRGB0 0 */
-        &quot;punpckhdq %%mm6, %%mm0     \n\t&quot; /* 0RGBRGB0 1 */
-        &quot;punpckhdq %%mm1, %%mm5     \n\t&quot; /* 0RGBRGB0 2 */
-        &quot;punpckhdq %%mm4, %%mm3     \n\t&quot; /* 0RGBRGB0 3 */
-
-        &quot;psrlq        $8, %%mm7     \n\t&quot; /* 00RGBRGB 0 */
-        &quot;movq      %%mm0, %%mm6     \n\t&quot; /* 0RGBRGB0 1 */
-        &quot;psllq       $40, %%mm0     \n\t&quot; /* GB000000 1 */
-        &quot;por       %%mm0, %%mm7     \n\t&quot; /* GBRGBRGB 0 */
-        MOVNTQ&quot;    %%mm7, (%1)      \n\t&quot;
-
-        &quot;movd 4 (%2, %0), %%mm0;&quot; /* Load 4 Cb 00 00 00 00 u3 u2 u1 u0 */
-
-        &quot;psrlq       $24, %%mm6     \n\t&quot; /* 0000RGBR 1 */
-        &quot;movq      %%mm5, %%mm1     \n\t&quot; /* 0RGBRGB0 2 */
-        &quot;psllq       $24, %%mm5     \n\t&quot; /* BRGB0000 2 */
-        &quot;por       %%mm5, %%mm6     \n\t&quot; /* BRGBRGBR 1 */
-        MOVNTQ&quot;    %%mm6, 8(%1)     \n\t&quot;
-
-        &quot;movq 8 (%5, %0, 2), %%mm6;&quot; /* Load 8 Y Y7 Y6 Y5 Y4 Y3 Y2 Y1 Y0 */
-
-        &quot;psrlq       $40, %%mm1     \n\t&quot; /* 000000RG 2 */
-        &quot;psllq        $8, %%mm3     \n\t&quot; /* RGBRGB00 3 */
-        &quot;por       %%mm3, %%mm1     \n\t&quot; /* RGBRGBRG 2 */
-        MOVNTQ&quot;    %%mm1, 16(%1)    \n\t&quot;
-
-        &quot;movd 4 (%3, %0), %%mm1;&quot; /* Load 4 Cr 00 00 00 00 v3 v2 v1 v0 */
-        &quot;pxor      %%mm4, %%mm4     \n\t&quot;
-#endif
-
     YUV2RGB_ENDLOOP(3)
     YUV2RGB_OPERANDS
 }
@@ -472,7 +491,7 @@
     &quot;pxor         %%mm4, %%mm4;&quot; /* zero mm4 */                         \
     &quot;movq 8 (%5, %0, 2), %%mm6;&quot; /* Load 8 Y Y7 Y6 Y5 Y4 Y3 Y2 Y1 Y0 */ \
 
-static inline int RENAME(yuv420_rgb32)(SwsContext *c, uint8_t* src[], int srcStride[], int srcSliceY,
+static inline int RENAME(yuv420_rgb32)(SwsContext *c, const uint8_t* src[], int srcStride[], int srcSliceY,
                                        int srcSliceH, uint8_t* dst[], int dstStride[])
 {
     int y, h_size;
@@ -489,7 +508,7 @@
     YUV2RGB_OPERANDS
 }
 
-static inline int RENAME(yuva420_rgb32)(SwsContext *c, uint8_t* src[], int srcStride[], int srcSliceY,
+static inline int RENAME(yuva420_rgb32)(SwsContext *c, const uint8_t* src[], int srcStride[], int srcSliceY,
                                         int srcSliceH, uint8_t* dst[], int dstStride[])
 {
 #if HAVE_7REGS
@@ -497,7 +516,7 @@
 
     YUV2RGB_LOOP(4)
 
-        uint8_t *pa = src[3] + y*srcStride[3];
+        const uint8_t *pa = src[3] + y*srcStride[3];
         YUV2RGB_INIT
         YUV2RGB
         &quot;movq     (%6, %0, 2), %%mm3;&quot;            /* Load 8 A A7 A6 A5 A4 A3 A2 A1 A0 */
@@ -533,7 +552,7 @@
 
     YUV2RGB_LOOP(4)
 
-        uint8_t *pa = src[3] + y*srcStride[3];
+        const uint8_t *pa = src[3] + y*srcStride[3];
         YUV2RGB_INIT
         YUV2RGB
         &quot;movq     (%6, %0, 2), %%mm3;&quot;            /* Load 8 A A7 A6 A5 A4 A3 A2 A1 A0 */

Modified: branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/yuv2rgb.c
===================================================================
--- branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/yuv2rgb.c	2010-05-26 05:26:42 UTC (rev 6237)
+++ branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/libswscale/yuv2rgb.c	2010-05-26 05:26:46 UTC (rev 6238)
@@ -49,6 +49,13 @@
     {117579, 136230, 16907, 35559}  /* SMPTE 240M (1987) */
 };
 
+const int * sws_getCoefficients(int colorspace)
+{
+    if (colorspace &gt; 7 || colorspace &lt; 0)
+        colorspace = SWS_CS_DEFAULT;
+    return ff_yuv2rgb_coeffs[colorspace];
+}
+
 #define LOADCHROMA(i)                               \
     U = pu[i];                                      \
     V = pv[i];                                      \
@@ -91,7 +98,7 @@
     dst[12*i+10] = dst[12*i+11] = b[Y];
 
 #define YUV2RGBFUNC(func_name, dst_type, alpha) \
-static int func_name(SwsContext *c, uint8_t* src[], int srcStride[], int srcSliceY, \
+static int func_name(SwsContext *c, const uint8_t* src[], int srcStride[], int srcSliceY, \
                      int srcSliceH, uint8_t* dst[], int dstStride[]) \
 {\
     int y;\
@@ -105,11 +112,11 @@
         dst_type *dst_2 = (dst_type*)(dst[0] + (y+srcSliceY+1)*dstStride[0]);\
         dst_type av_unused *r, *b;\
         dst_type *g;\
-        uint8_t *py_1 = src[0] + y*srcStride[0];\
-        uint8_t *py_2 = py_1 + srcStride[0];\
-        uint8_t *pu = src[1] + (y&gt;&gt;1)*srcStride[1];\
-        uint8_t *pv = src[2] + (y&gt;&gt;1)*srcStride[2];\
-        uint8_t av_unused *pa_1, *pa_2;\
+        const uint8_t *py_1 = src[0] + y*srcStride[0];\
+        const uint8_t *py_2 = py_1 + srcStride[0];\
+        const uint8_t *pu = src[1] + (y&gt;&gt;1)*srcStride[1];\
+        const uint8_t *pv = src[2] + (y&gt;&gt;1)*srcStride[2];\
+        const uint8_t av_unused *pa_1, *pa_2;\
         unsigned int h_size = c-&gt;dstW&gt;&gt;3;\
         if (alpha) {\
             pa_1 = src[3] + y*srcStride[3];\
@@ -321,6 +328,7 @@
     PUTRGB(dst_1,py_1,3);
 CLOSEYUV2RGBFUNC(8)
 
+#if 0 // Currently unused
 // This is exactly the same code as yuv2rgb_c_32 except for the types of
 // r, g, b, dst_1, dst_2
 YUV2RGBFUNC(yuv2rgb_c_8, uint8_t, 0)
@@ -340,6 +348,7 @@
     PUTRGB(dst_2,py_2,3);
     PUTRGB(dst_1,py_1,3);
 CLOSEYUV2RGBFUNC(8)
+#endif
 
 // r, g, b, dst_1, dst_2
 YUV2RGBFUNC(yuv2rgb_c_8_ordered_dither, uint8_t, 0)
@@ -368,7 +377,7 @@
     PUTRGB8(dst_1,py_1,3,6);
 CLOSEYUV2RGBFUNC(8)
 
-
+#if 0 // Currently unused
 // This is exactly the same code as yuv2rgb_c_32 except for the types of
 // r, g, b, dst_1, dst_2
 YUV2RGBFUNC(yuv2rgb_c_4, uint8_t, 0)
@@ -396,6 +405,7 @@
     PUTRGB4(dst_2,py_2,3);
     PUTRGB4(dst_1,py_1,3);
 CLOSEYUV2RGBFUNC(4)
+#endif
 
 YUV2RGBFUNC(yuv2rgb_c_4_ordered_dither, uint8_t, 0)
     const uint8_t *d64 =  dither_8x8_73[y&amp;7];
@@ -426,6 +436,7 @@
     PUTRGB4D(dst_1,py_1,3,6);
 CLOSEYUV2RGBFUNC(4)
 
+#if 0 // Currently unused
 // This is exactly the same code as yuv2rgb_c_32 except for the types of
 // r, g, b, dst_1, dst_2
 YUV2RGBFUNC(yuv2rgb_c_4b, uint8_t, 0)
@@ -445,6 +456,7 @@
     PUTRGB(dst_2,py_2,3);
     PUTRGB(dst_1,py_1,3);
 CLOSEYUV2RGBFUNC(8)
+#endif
 
 YUV2RGBFUNC(yuv2rgb_c_4b_ordered_dither, uint8_t, 0)
     const uint8_t *d64 =  dither_8x8_73[y&amp;7];
@@ -525,7 +537,7 @@
     if (t)
         return t;
 
-    av_log(c, AV_LOG_WARNING, &quot;No accelerated colorspace conversion found.\n&quot;);
+    av_log(c, AV_LOG_WARNING, &quot;No accelerated colorspace conversion found from %s to %s.\n&quot;, sws_format_name(c-&gt;srcFormat), sws_format_name(c-&gt;dstFormat));
 
     switch (c-&gt;dstFormat) {
     case PIX_FMT_RGB48BE:
@@ -590,7 +602,7 @@
                         || c-&gt;dstFormat==PIX_FMT_RGB4
                         || c-&gt;dstFormat==PIX_FMT_RGB4_BYTE
                         || c-&gt;dstFormat==PIX_FMT_MONOBLACK;
-    const int bpp = fmt_depth(c-&gt;dstFormat);
+    const int bpp = c-&gt;dstFormatBpp;
     uint8_t *y_table;
     uint16_t *y_table16;
     uint32_t *y_table32;


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="003433.html">[Avidemux-svn-commit] r6237 -	branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg/patches
</A></li>
	<LI>Next message: <A HREF="003435.html">[Avidemux-svn-commit] r6239 - in	branches/avidemux_2.6_branch_mean/avidemux_core/ADM_ffmpeg: .	ffmpeg_config
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#3434">[ date ]</a>
              <a href="thread.html#3434">[ thread ]</a>
              <a href="subject.html#3434">[ subject ]</a>
              <a href="author.html#3434">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/avidemux-svn-commit">More information about the Avidemux-svn-commit
mailing list</a><br>
</body></html>
